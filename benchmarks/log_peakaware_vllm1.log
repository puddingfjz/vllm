Namespace(backend='vllm', dataset='ShareGPT_V3_unfiltered_cleaned_split.json', model='huggyllama/llama-7b', tokenizer='huggyllama/llama-7b', quantization=None, tensor_parallel_size=1, n=1, use_beam_search=False, num_prompts=1000, seed=0, hf_max_batch_size=None, trust_remote_code=False, dtype='auto')
INFO 11-21 20:28:04 tokenizer.py:31] For some LLaMA V1 models, initializing the fast tokenizer may take a long time. To reduce the initialization time, consider using 'hf-internal-testing/llama-tokenizer' instead of the original tokenizer.
len(filtered_dataset): 82780
len(sampled_requests): 1000
len(sampled_requests): 1000
INFO 11-21 20:28:22 llm_engine.py:76] Initializing an LLM engine with config: model='huggyllama/llama-7b', tokenizer='huggyllama/llama-7b', tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=2048, download_dir=None, load_format=auto, tensor_parallel_size=1, quantization=None, seed=0)
INFO 11-21 20:28:22 tokenizer.py:31] For some LLaMA V1 models, initializing the fast tokenizer may take a long time. To reduce the initialization time, consider using 'hf-internal-testing/llama-tokenizer' instead of the original tokenizer.
INFO 11-21 20:28:26 llm_engine.py:218] # GPU blocks: 1370, # CPU blocks: 7424
self.use_our_method: False
iter_num: 1, on_card_num: 2, preempted blk num: 0
iter_num: 2, on_card_num: 3, preempted blk num: 0
iter_num: 3, on_card_num: 6, preempted blk num: 0
iter_num: 4, on_card_num: 7, preempted blk num: 0
iter_num: 5, on_card_num: 8, preempted blk num: 0
iter_num: 6, on_card_num: 10, preempted blk num: 0
iter_num: 7, on_card_num: 11, preempted blk num: 0
iter_num: 8, on_card_num: 17, preempted blk num: 0
iter_num: 9, on_card_num: 20, preempted blk num: 0
iter_num: 10, on_card_num: 21, preempted blk num: 0
iter_num: 11, on_card_num: 24, preempted blk num: 0
iter_num: 12, on_card_num: 27, preempted blk num: 0
iter_num: 13, on_card_num: 28, preempted blk num: 0
iter_num: 14, on_card_num: 29, preempted blk num: 0
iter_num: 15, on_card_num: 31, preempted blk num: 0
iter_num: 16, on_card_num: 33, preempted blk num: 0
iter_num: 17, on_card_num: 34, preempted blk num: 0
iter_num: 18, on_card_num: 37, preempted blk num: 0
iter_num: 19, on_card_num: 38, preempted blk num: 0
iter_num: 20, on_card_num: 39, preempted blk num: 0
iter_num: 21, on_card_num: 41, preempted blk num: 0
iter_num: 22, on_card_num: 42, preempted blk num: 0
iter_num: 23, on_card_num: 44, preempted blk num: 0
iter_num: 24, on_card_num: 45, preempted blk num: 0
iter_num: 25, on_card_num: 47, preempted blk num: 0
iter_num: 26, on_card_num: 48, preempted blk num: 0
iter_num: 27, on_card_num: 50, preempted blk num: 0
iter_num: 28, on_card_num: 55, preempted blk num: 0
iter_num: 29, on_card_num: 56, preempted blk num: 0
iter_num: 30, on_card_num: 57, preempted blk num: 0
iter_num: 31, on_card_num: 58, preempted blk num: 0
iter_num: 32, on_card_num: 59, preempted blk num: 0
iter_num: 33, on_card_num: 60, preempted blk num: 0
iter_num: 34, on_card_num: 61, preempted blk num: 0
iter_num: 35, on_card_num: 63, preempted blk num: 0
iter_num: 36, on_card_num: 65, preempted blk num: 0
iter_num: 37, on_card_num: 66, preempted blk num: 0
iter_num: 38, on_card_num: 67, preempted blk num: 0
iter_num: 39, on_card_num: 68, preempted blk num: 0
iter_num: 40, on_card_num: 69, preempted blk num: 0
iter_num: 41, on_card_num: 70, preempted blk num: 0
iter_num: 42, on_card_num: 72, preempted blk num: 0
iter_num: 43, on_card_num: 74, preempted blk num: 0
iter_num: 44, on_card_num: 76, preempted blk num: 0
iter_num: 45, on_card_num: 77, preempted blk num: 0
iter_num: 46, on_card_num: 78, preempted blk num: 0
iter_num: 47, on_card_num: 81, preempted blk num: 0
iter_num: 48, on_card_num: 82, preempted blk num: 0
iter_num: 49, on_card_num: 84, preempted blk num: 0
iter_num: 50, on_card_num: 85, preempted blk num: 0
iter_num: 51, on_card_num: 85, preempted blk num: 0
iter_num: 52, on_card_num: 85, preempted blk num: 0
iter_num: 53, on_card_num: 85, preempted blk num: 0
iter_num: 54, on_card_num: 84, preempted blk num: 0
iter_num: 55, on_card_num: 85, preempted blk num: 0
iter_num: 56, on_card_num: 84, preempted blk num: 0
iter_num: 57, on_card_num: 87, preempted blk num: 0
iter_num: 58, on_card_num: 86, preempted blk num: 0
iter_num: 59, on_card_num: 84, preempted blk num: 0
iter_num: 60, on_card_num: 85, preempted blk num: 0
iter_num: 61, on_card_num: 87, preempted blk num: 0
iter_num: 62, on_card_num: 84, preempted blk num: 0
iter_num: 63, on_card_num: 85, preempted blk num: 0
iter_num: 64, on_card_num: 87, preempted blk num: 0
iter_num: 65, on_card_num: 88, preempted blk num: 0
iter_num: 66, on_card_num: 88, preempted blk num: 0
iter_num: 67, on_card_num: 88, preempted blk num: 0
iter_num: 68, on_card_num: 87, preempted blk num: 0
iter_num: 69, on_card_num: 85, preempted blk num: 0
iter_num: 70, on_card_num: 86, preempted blk num: 0
iter_num: 71, on_card_num: 89, preempted blk num: 0
iter_num: 72, on_card_num: 90, preempted blk num: 0
iter_num: 73, on_card_num: 89, preempted blk num: 0
iter_num: 74, on_card_num: 91, preempted blk num: 0
iter_num: 75, on_card_num: 89, preempted blk num: 0
iter_num: 76, on_card_num: 87, preempted blk num: 0
iter_num: 77, on_card_num: 88, preempted blk num: 0
iter_num: 78, on_card_num: 89, preempted blk num: 0
iter_num: 79, on_card_num: 85, preempted blk num: 0
iter_num: 80, on_card_num: 87, preempted blk num: 0
iter_num: 81, on_card_num: 88, preempted blk num: 0
iter_num: 82, on_card_num: 89, preempted blk num: 0
iter_num: 83, on_card_num: 90, preempted blk num: 0
iter_num: 84, on_card_num: 92, preempted blk num: 0
iter_num: 85, on_card_num: 92, preempted blk num: 0
iter_num: 86, on_card_num: 91, preempted blk num: 0
iter_num: 87, on_card_num: 90, preempted blk num: 0
iter_num: 88, on_card_num: 91, preempted blk num: 0
iter_num: 89, on_card_num: 91, preempted blk num: 0
iter_num: 90, on_card_num: 90, preempted blk num: 0
iter_num: 91, on_card_num: 89, preempted blk num: 0
iter_num: 92, on_card_num: 90, preempted blk num: 0
iter_num: 93, on_card_num: 90, preempted blk num: 0
iter_num: 94, on_card_num: 89, preempted blk num: 0
iter_num: 95, on_card_num: 90, preempted blk num: 0
iter_num: 96, on_card_num: 91, preempted blk num: 0
iter_num: 97, on_card_num: 89, preempted blk num: 0
iter_num: 98, on_card_num: 90, preempted blk num: 0
iter_num: 99, on_card_num: 90, preempted blk num: 0
iter_num: 100, on_card_num: 88, preempted blk num: 0
iter_num: 101, on_card_num: 90, preempted blk num: 0
iter_num: 102, on_card_num: 92, preempted blk num: 0
iter_num: 103, on_card_num: 93, preempted blk num: 0
iter_num: 104, on_card_num: 93, preempted blk num: 0
to recompute 1: ('121', 412)
iter_num: 105, on_card_num: 91, preempted blk num: 52
iter_num: 106, on_card_num: 92, preempted blk num: 52
iter_num: 107, on_card_num: 90, preempted blk num: 52
iter_num: 108, on_card_num: 91, preempted blk num: 52
iter_num: 109, on_card_num: 93, preempted blk num: 52
iter_num: 110, on_card_num: 94, preempted blk num: 52
iter_num: 111, on_card_num: 97, preempted blk num: 52
iter_num: 112, on_card_num: 97, preempted blk num: 52
iter_num: 113, on_card_num: 95, preempted blk num: 52
iter_num: 114, on_card_num: 96, preempted blk num: 52
iter_num: 115, on_card_num: 95, preempted blk num: 52
iter_num: 116, on_card_num: 96, preempted blk num: 52
iter_num: 117, on_card_num: 95, preempted blk num: 52
iter_num: 118, on_card_num: 96, preempted blk num: 52
iter_num: 119, on_card_num: 96, preempted blk num: 52
iter_num: 120, on_card_num: 94, preempted blk num: 52
iter_num: 121, on_card_num: 92, preempted blk num: 52
iter_num: 122, on_card_num: 93, preempted blk num: 52
iter_num: 123, on_card_num: 97, preempted blk num: 52
iter_num: 124, on_card_num: 98, preempted blk num: 52
iter_num: 125, on_card_num: 98, preempted blk num: 52
iter_num: 126, on_card_num: 96, preempted blk num: 52
iter_num: 127, on_card_num: 97, preempted blk num: 52
iter_num: 128, on_card_num: 102, preempted blk num: 52
iter_num: 129, on_card_num: 103, preempted blk num: 52
iter_num: 130, on_card_num: 102, preempted blk num: 52
iter_num: 131, on_card_num: 100, preempted blk num: 52
iter_num: 132, on_card_num: 101, preempted blk num: 52
iter_num: 133, on_card_num: 103, preempted blk num: 52
iter_num: 134, on_card_num: 102, preempted blk num: 52
iter_num: 135, on_card_num: 104, preempted blk num: 52
iter_num: 136, on_card_num: 103, preempted blk num: 52
iter_num: 137, on_card_num: 104, preempted blk num: 52
iter_num: 138, on_card_num: 106, preempted blk num: 52
iter_num: 139, on_card_num: 105, preempted blk num: 52
iter_num: 140, on_card_num: 107, preempted blk num: 52
iter_num: 141, on_card_num: 107, preempted blk num: 52
iter_num: 142, on_card_num: 106, preempted blk num: 52
iter_num: 143, on_card_num: 106, preempted blk num: 52
iter_num: 144, on_card_num: 104, preempted blk num: 52
iter_num: 145, on_card_num: 105, preempted blk num: 52
iter_num: 146, on_card_num: 106, preempted blk num: 52
iter_num: 147, on_card_num: 106, preempted blk num: 52
iter_num: 148, on_card_num: 106, preempted blk num: 52
iter_num: 149, on_card_num: 106, preempted blk num: 52
iter_num: 150, on_card_num: 104, preempted blk num: 52
load 157: ('157', 1017)
seq_id: 157, layer_i: 2, token_i: 0, prompt
tensor([[[-0.1669, -0.9507,  1.9873,  ...,  0.4370,  0.7729, -0.0464],
         [-1.8008,  0.1331, -0.2065,  ..., -0.1104,  0.8110, -0.0563],
         [ 0.0283,  0.8105, -1.3291,  ..., -0.7559,  0.5020,  0.0510],
         ...,
         [-1.5840, -0.5664, -0.9688,  ...,  0.4062,  0.8135, -0.3752],
         [-1.1680, -0.4246,  0.2227,  ..., -0.5864,  0.8379, -0.1377],
         [ 0.2935, -0.0394,  1.0195,  ..., -1.3311,  1.4189, -0.4414]],

        [[-0.3848,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.4282,  0.8569, -1.7480,  ...,  1.0312, -0.5908,  1.9150],
         [-0.1975,  1.4102, -1.9346,  ...,  1.0186, -1.0479,  1.2441],
         ...,
         [ 0.2634, -1.0039,  2.2559,  ..., -1.3242, -2.3379, -1.2881],
         [ 0.2466, -0.4292,  1.8418,  ..., -1.4727, -1.2422, -1.2354],
         [-0.1680, -0.3413,  2.8906,  ..., -1.7158, -1.9600, -1.7090]],

        [[ 1.0068, -0.1941, -1.0938,  ..., -0.5791,  1.1074, -0.1776],
         [ 1.6641, -1.1426, -1.5928,  ..., -1.5625,  0.4661,  0.0200],
         [ 1.3057, -1.2178, -1.5078,  ..., -1.3672,  0.3333, -1.3486],
         ...,
         [-0.6646, -2.8164, -0.5127,  ..., -2.5508, -0.0947, -0.1223],
         [-0.9951, -2.0820, -0.1396,  ..., -2.1445,  0.7930,  0.9307],
         [-1.1260, -2.7539, -0.1875,  ..., -2.1406,  0.0098,  0.0571]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6235, -0.6846],
         [-0.5210,  0.0217, -0.2482,  ..., -0.3701,  4.3047, -0.5439],
         [ 0.5034, -0.4531, -0.5459,  ..., -0.6284,  3.3672, -0.3303],
         ...,
         [ 0.0854,  0.5928, -0.2949,  ..., -0.6514,  5.0898, -0.1449],
         [ 0.7979, -0.3420, -0.7217,  ..., -0.7178,  4.1250, -0.5527],
         [ 0.4976, -0.0469, -0.2703,  ...,  0.3193,  6.1953, -0.3062]],

        [[-0.3994,  0.2396, -0.1693,  ...,  0.4902, -0.4697,  0.0252],
         [ 0.2041, -0.3528, -0.2201,  ...,  0.5054, -1.4922,  0.1339],
         [-1.2490, -0.2302, -0.6865,  ...,  0.3486, -1.0703, -0.0121],
         ...,
         [-0.2159, -0.6851, -0.5078,  ..., -0.0331, -1.8975,  0.3301],
         [-1.6816, -0.0674, -0.0417,  ...,  0.5078, -1.3438, -0.5566],
         [-0.5459, -0.6147, -0.5518,  ...,  0.4475, -1.3496, -0.0589]],

        [[-1.1104, -0.0304,  0.0469,  ..., -0.0857,  0.4358, -0.4883],
         [-1.3672,  1.1348,  1.1084,  ..., -1.0723, -0.1835, -1.4414],
         [-1.1162, -0.8491,  0.5537,  ..., -0.1890,  0.6602, -2.0352],
         ...,
         [-1.5117,  0.6938,  1.4287,  ..., -0.8618, -0.6372, -0.9932],
         [-1.6494, -0.6460,  0.9937,  ..., -0.2546,  0.3984, -0.7808],
         [-1.5518,  0.3489,  1.7334,  ..., -0.8188, -0.5103, -1.3047]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, prompt
tensor([[[ 0.0703,  0.1636,  0.2434,  ..., -2.2656,  0.0540, -0.6182],
         [ 2.9297, -0.0810, -0.4807,  ..., -1.9551, -0.5986,  0.1614],
         [ 1.1729,  0.1647, -0.5938,  ..., -1.0312, -0.5596, -0.0933],
         ...,
         [ 1.9082,  0.5854, -0.2905,  ..., -2.3535,  0.5264, -0.1508],
         [ 1.5859,  0.4673,  0.1401,  ..., -2.3223,  0.7656, -0.1317],
         [ 1.5791,  0.0347,  0.8047,  ..., -0.7764, -0.0701, -0.3762]],

        [[ 0.0688,  1.6270, -3.2090,  ...,  1.0615, -3.1797,  3.1289],
         [ 0.7266,  1.7734, -2.3340,  ...,  1.3848, -2.6113,  2.8281],
         [ 0.2839,  1.0381, -1.8154,  ...,  1.3613, -2.2363,  2.5156],
         ...,
         [-0.5854, -1.8281,  3.2480,  ...,  1.1162,  1.0889,  1.0479],
         [-0.7578, -0.9644,  3.3633,  ...,  0.7109,  0.8682,  1.9365],
         [-1.1416, -0.8857,  2.2285,  ...,  0.4287,  2.1348,  0.2764]],

        [[ 0.0742,  3.1270, -0.8965,  ...,  2.9902, -0.8799, -1.8916],
         [ 0.5771,  2.9609, -1.6182,  ...,  2.5117, -0.3911, -1.0068],
         [ 0.4912,  2.4219, -1.1182,  ...,  1.9473, -1.2139, -1.9346],
         ...,
         [ 3.1914,  1.6660, -2.6113,  ...,  1.9844, -0.6211, -3.2969],
         [ 3.4844,  2.4141, -2.6270,  ...,  1.4707, -2.1367, -2.2422],
         [ 3.3770,  1.3711, -3.0605,  ...,  1.6875, -1.1787, -2.4141]],

        ...,

        [[-0.2390, -0.1890,  0.2554,  ..., -0.3608,  5.4062, -1.0234],
         [-0.5928, -0.0882,  0.3601,  ...,  0.6265,  5.0547, -0.5127],
         [ 0.3630,  0.1170,  0.2407,  ..., -0.1925,  2.8145, -0.8706],
         ...,
         [-0.9297,  0.4441,  1.0332,  ..., -1.4668,  6.7070, -2.3457],
         [ 0.2622, -0.1299,  0.1003,  ...,  0.0376,  6.6602, -0.8667],
         [-0.9067, -0.0067,  0.4829,  ..., -0.9780,  6.0938, -2.1055]],

        [[-0.5278, -0.5962, -0.3564,  ...,  0.1648, -2.3105,  0.0532],
         [-1.6094,  0.4285,  0.0400,  ..., -0.4497, -2.1836, -0.4800],
         [-0.7168, -0.0978, -0.1595,  ...,  0.3667, -1.8535,  0.3450],
         ...,
         [-0.8262,  0.1411, -0.5967,  ..., -0.0645, -2.1582, -0.0642],
         [-1.0322, -0.4968, -0.1655,  ...,  0.1357, -2.4668,  0.4458],
         [-1.1670,  0.1687, -0.6128,  ...,  0.2485, -1.8477, -0.0803]],

        [[-0.8564,  0.4001,  1.3486,  ..., -0.6597, -0.3765, -1.2207],
         [-0.9644,  0.2349,  0.4993,  ..., -1.2168, -0.6294, -1.8213],
         [-1.0957,  0.6802,  0.7959,  ..., -0.4351, -0.0143, -0.5259],
         ...,
         [-1.6289,  0.8691,  1.6709,  ..., -0.5435, -0.8359, -0.9932],
         [-1.5303,  0.9551,  1.6152,  ..., -0.3298, -0.1736, -1.2256],
         [-1.8730,  0.8125,  1.3408,  ..., -0.4128, -0.6748, -1.5107]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 151, on_card_num: 105, preempted blk num: 52
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 5.7715e-01,  1.1877e-01,  2.1362e-02,  ..., -1.6621e+00,
          -6.9629e-01, -2.3425e-01],
         [ 2.0059e+00,  5.8057e-01, -2.6367e-01,  ..., -2.5000e+00,
          -4.4043e-01, -4.2822e-01],
         [ 1.7871e+00,  5.2246e-01, -5.0684e-01,  ..., -2.5996e+00,
           8.1445e-01, -1.1536e-01],
         ...,
         [-8.4668e-01,  4.4556e-03, -4.3213e-01,  ..., -9.8682e-01,
           1.0620e-01, -9.3140e-02],
         [-3.7061e-01, -8.6572e-01, -3.6963e-01,  ..., -1.8926e+00,
           6.3916e-01, -1.9019e-01],
         [ 1.7637e+00, -2.5977e-01, -1.4624e-01,  ..., -1.9961e+00,
           9.9951e-01, -2.4219e-01]],

        [[-2.5879e-01,  1.8027e+00, -3.2910e+00,  ...,  2.2900e-01,
          -9.4043e-01, -2.5098e+00],
         [-8.1055e-01,  1.9248e+00, -3.9102e+00,  ...,  1.4404e-01,
          -3.1836e-01, -2.3438e+00],
         [-1.0371e+00,  1.3887e+00, -3.4141e+00,  ...,  5.1416e-01,
           3.0371e-01, -1.7754e+00],
         ...,
         [-1.0215e+00, -4.2920e-01, -4.8730e-01,  ..., -2.1113e+00,
           2.5488e+00,  2.3359e+00],
         [-5.9229e-01, -1.3037e-01,  5.5078e-01,  ..., -2.5586e+00,
           2.9414e+00,  1.5059e+00],
         [-7.0068e-01,  4.5166e-01,  2.0137e+00,  ..., -2.5996e+00,
           2.7070e+00,  5.5078e-01]],

        [[ 2.0645e+00,  5.5957e-01, -2.1875e+00,  ...,  1.0938e+00,
           1.1055e+00, -1.6133e+00],
         [ 2.0742e+00,  1.5234e-01, -2.5059e+00,  ...,  1.5420e+00,
           4.7900e-01, -1.6875e+00],
         [ 1.5186e+00, -1.6992e-01, -1.4053e+00,  ...,  1.3555e+00,
           3.6743e-01, -1.7480e+00],
         ...,
         [-2.5723e+00, -1.8340e+00,  1.2197e+00,  ...,  2.5508e+00,
          -2.0977e+00,  1.4717e+00],
         [-2.0391e+00, -2.3164e+00,  3.3008e-01,  ...,  3.2812e+00,
          -1.2158e+00,  1.3125e+00],
         [-1.5215e+00, -2.4980e+00, -3.7988e-01,  ...,  2.5449e+00,
          -3.0811e-01,  1.5371e+00]],

        ...,

        [[ 2.6440e-01,  1.3184e-01, -5.8496e-01,  ...,  2.2668e-01,
           1.6729e+00, -2.4238e+00],
         [ 2.0642e-01,  4.2261e-01, -4.8950e-01,  ...,  1.1157e-01,
           2.6836e+00, -1.2314e+00],
         [-6.5283e-01, -3.6682e-02,  4.3823e-01,  ...,  2.2083e-01,
           2.2988e+00, -2.4097e-01],
         ...,
         [ 4.5898e-01, -6.8359e-01, -3.8525e-01,  ..., -1.4834e+00,
           6.6602e+00, -7.5781e-01],
         [ 1.7188e+00, -8.3008e-01,  8.6328e-01,  ..., -8.2910e-01,
           7.9219e+00, -1.3320e+00],
         [-1.6211e-01, -6.8896e-01, -7.7930e-01,  ..., -3.1006e-01,
           5.9297e+00, -9.2822e-01]],

        [[-1.9031e-01, -1.4038e-01, -1.8408e-01,  ..., -1.2109e-01,
          -2.3379e+00, -1.9800e-01],
         [-2.1631e-01, -9.2285e-02,  3.1348e-01,  ..., -6.1328e-01,
          -2.5820e+00, -2.7686e-01],
         [-5.6348e-01,  2.0361e-01,  2.8955e-01,  ..., -1.0791e+00,
          -2.7812e+00, -8.6182e-02],
         ...,
         [-8.2471e-01, -4.4287e-01, -4.5508e-01,  ...,  7.1045e-01,
          -2.9863e+00,  8.4131e-01],
         [-1.2671e-01, -1.2383e+00, -1.1299e+00,  ...,  5.6201e-01,
          -2.0273e+00, -4.6606e-01],
         [-1.0049e+00, -7.0898e-01, -1.1045e+00,  ..., -8.9453e-01,
          -2.3652e+00, -4.8706e-02]],

        [[-1.2051e+00,  1.2227e+00,  7.6807e-01,  ..., -6.8652e-01,
           4.1748e-02, -1.1729e+00],
         [-1.1133e+00,  7.7881e-01,  1.6416e+00,  ..., -2.9370e-01,
          -1.7285e-01, -1.4707e+00],
         [-5.9277e-01,  1.1572e+00,  2.1328e+00,  ..., -3.3228e-01,
          -1.3066e+00, -1.5732e+00],
         ...,
         [-1.3896e+00, -5.2124e-02,  1.5615e+00,  ..., -8.2959e-01,
          -2.6001e-01, -7.9590e-01],
         [-1.5791e+00, -8.6426e-01,  1.1553e+00,  ..., -3.5400e-01,
          -5.5225e-01, -1.2266e+00],
         [-1.0566e+00,  4.0967e-01,  2.3477e+00,  ..., -8.5742e-01,
           4.0588e-02, -2.0820e+00]]], device='cuda:0', dtype=torch.float16)
iter_num: 152, on_card_num: 105, preempted blk num: 52
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 5.7715e-01,  1.1877e-01,  2.1362e-02,  ..., -1.6621e+00,
          -6.9629e-01, -2.3425e-01],
         [ 2.0059e+00,  5.8057e-01, -2.6367e-01,  ..., -2.5000e+00,
          -4.4043e-01, -4.2822e-01],
         [ 1.7871e+00,  5.2246e-01, -5.0684e-01,  ..., -2.5996e+00,
           8.1445e-01, -1.1536e-01],
         ...,
         [-8.4668e-01,  4.4556e-03, -4.3213e-01,  ..., -9.8682e-01,
           1.0620e-01, -9.3140e-02],
         [-3.7061e-01, -8.6572e-01, -3.6963e-01,  ..., -1.8926e+00,
           6.3916e-01, -1.9019e-01],
         [ 1.7637e+00, -2.5977e-01, -1.4624e-01,  ..., -1.9961e+00,
           9.9951e-01, -2.4219e-01]],

        [[-2.5879e-01,  1.8027e+00, -3.2910e+00,  ...,  2.2900e-01,
          -9.4043e-01, -2.5098e+00],
         [-8.1055e-01,  1.9248e+00, -3.9102e+00,  ...,  1.4404e-01,
          -3.1836e-01, -2.3438e+00],
         [-1.0371e+00,  1.3887e+00, -3.4141e+00,  ...,  5.1416e-01,
           3.0371e-01, -1.7754e+00],
         ...,
         [-1.0215e+00, -4.2920e-01, -4.8730e-01,  ..., -2.1113e+00,
           2.5488e+00,  2.3359e+00],
         [-5.9229e-01, -1.3037e-01,  5.5078e-01,  ..., -2.5586e+00,
           2.9414e+00,  1.5059e+00],
         [-7.0068e-01,  4.5166e-01,  2.0137e+00,  ..., -2.5996e+00,
           2.7070e+00,  5.5078e-01]],

        [[ 2.0645e+00,  5.5957e-01, -2.1875e+00,  ...,  1.0938e+00,
           1.1055e+00, -1.6133e+00],
         [ 2.0742e+00,  1.5234e-01, -2.5059e+00,  ...,  1.5420e+00,
           4.7900e-01, -1.6875e+00],
         [ 1.5186e+00, -1.6992e-01, -1.4053e+00,  ...,  1.3555e+00,
           3.6743e-01, -1.7480e+00],
         ...,
         [-2.5723e+00, -1.8340e+00,  1.2197e+00,  ...,  2.5508e+00,
          -2.0977e+00,  1.4717e+00],
         [-2.0391e+00, -2.3164e+00,  3.3008e-01,  ...,  3.2812e+00,
          -1.2158e+00,  1.3125e+00],
         [-1.5215e+00, -2.4980e+00, -3.7988e-01,  ...,  2.5449e+00,
          -3.0811e-01,  1.5371e+00]],

        ...,

        [[ 2.6440e-01,  1.3184e-01, -5.8496e-01,  ...,  2.2668e-01,
           1.6729e+00, -2.4238e+00],
         [ 2.0642e-01,  4.2261e-01, -4.8950e-01,  ...,  1.1157e-01,
           2.6836e+00, -1.2314e+00],
         [-6.5283e-01, -3.6682e-02,  4.3823e-01,  ...,  2.2083e-01,
           2.2988e+00, -2.4097e-01],
         ...,
         [ 4.5898e-01, -6.8359e-01, -3.8525e-01,  ..., -1.4834e+00,
           6.6602e+00, -7.5781e-01],
         [ 1.7188e+00, -8.3008e-01,  8.6328e-01,  ..., -8.2910e-01,
           7.9219e+00, -1.3320e+00],
         [-1.6211e-01, -6.8896e-01, -7.7930e-01,  ..., -3.1006e-01,
           5.9297e+00, -9.2822e-01]],

        [[-1.9031e-01, -1.4038e-01, -1.8408e-01,  ..., -1.2109e-01,
          -2.3379e+00, -1.9800e-01],
         [-2.1631e-01, -9.2285e-02,  3.1348e-01,  ..., -6.1328e-01,
          -2.5820e+00, -2.7686e-01],
         [-5.6348e-01,  2.0361e-01,  2.8955e-01,  ..., -1.0791e+00,
          -2.7812e+00, -8.6182e-02],
         ...,
         [-8.2471e-01, -4.4287e-01, -4.5508e-01,  ...,  7.1045e-01,
          -2.9863e+00,  8.4131e-01],
         [-1.2671e-01, -1.2383e+00, -1.1299e+00,  ...,  5.6201e-01,
          -2.0273e+00, -4.6606e-01],
         [-1.0049e+00, -7.0898e-01, -1.1045e+00,  ..., -8.9453e-01,
          -2.3652e+00, -4.8706e-02]],

        [[-1.2051e+00,  1.2227e+00,  7.6807e-01,  ..., -6.8652e-01,
           4.1748e-02, -1.1729e+00],
         [-1.1133e+00,  7.7881e-01,  1.6416e+00,  ..., -2.9370e-01,
          -1.7285e-01, -1.4707e+00],
         [-5.9277e-01,  1.1572e+00,  2.1328e+00,  ..., -3.3228e-01,
          -1.3066e+00, -1.5732e+00],
         ...,
         [-1.3896e+00, -5.2124e-02,  1.5615e+00,  ..., -8.2959e-01,
          -2.6001e-01, -7.9590e-01],
         [-1.5791e+00, -8.6426e-01,  1.1553e+00,  ..., -3.5400e-01,
          -5.5225e-01, -1.2266e+00],
         [-1.0566e+00,  4.0967e-01,  2.3477e+00,  ..., -8.5742e-01,
           4.0588e-02, -2.0820e+00]]], device='cuda:0', dtype=torch.float16)
iter_num: 153, on_card_num: 105, preempted blk num: 52
to recompute 1: ('157', 1020)
iter_num: 154, on_card_num: 103, preempted blk num: 180
load 157: ('157', 1020)
seq_id: 157, layer_i: 2, token_i: 0, prompt
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4373,  0.7729, -0.0464],
         [-0.7432,  0.1255,  0.0718,  ...,  0.1421,  0.7480, -0.1464],
         [ 0.0410,  0.9263, -1.2236,  ..., -0.9854,  0.1758, -0.1234],
         ...,
         [-3.1211, -0.1107, -0.4358,  ..., -0.8164,  0.6758,  0.0752],
         [-2.3340, -0.2576,  0.5376,  ..., -1.2197,  1.0283, -0.3032],
         [ 0.6387, -0.1621,  1.0049,  ..., -1.8066,  1.0430, -0.1069]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0996],
         [-0.3667,  1.0752, -0.8784,  ...,  1.0381, -0.1482,  1.1748],
         [-0.6162,  1.2188, -2.0215,  ...,  1.0469, -1.1934,  1.4111],
         ...,
         [ 0.6431, -1.4395,  2.2754,  ..., -1.1445, -1.2812, -1.2578],
         [-0.0632, -0.9058,  2.6094,  ..., -1.2959, -1.4629, -1.6143],
         [-0.5142, -0.1367,  2.3457,  ..., -1.8848, -1.1523, -1.5361]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.1582, -0.6328, -1.0547,  ..., -1.1035,  0.4080, -0.2991],
         [ 1.3496, -1.3311, -1.7031,  ..., -1.8662,  0.1705, -0.3428],
         ...,
         [-1.0137, -1.8984,  0.4082,  ..., -1.8652, -0.1718, -1.0205],
         [-1.2275, -2.3652,  0.3975,  ..., -1.9277, -0.4614, -0.7256],
         [-1.3711, -1.7119,  0.4800,  ..., -2.0762, -0.2769, -1.2598]],

        ...,

        [[-0.1335, -0.0346, -1.2900,  ..., -0.3794,  0.6245, -0.6846],
         [-0.3284, -0.2009, -0.4094,  ..., -0.4412,  1.5449, -0.4714],
         [ 0.7495, -0.2976, -0.4626,  ..., -1.1367,  3.5879, -0.7510],
         ...,
         [ 0.6372,  0.0623, -0.0352,  ..., -0.7075,  5.5859, -0.3162],
         [ 0.8120,  0.4810, -0.4890,  ...,  0.4458,  5.6289, -0.1757],
         [ 0.2583,  0.8940,  0.1592,  ..., -1.3340,  4.6758, -1.0127]],

        [[-0.3999,  0.2395, -0.1694,  ...,  0.4902, -0.4700,  0.0253],
         [ 0.0145, -0.1904, -0.5562,  ...,  0.0724, -1.3135,  0.5684],
         [-0.3899, -0.4587, -0.5801,  ...,  0.3335, -1.0273, -0.4199],
         ...,
         [-0.8110, -0.1897, -0.9150,  ...,  0.4417, -1.3965, -0.0883],
         [-1.7705, -0.5747, -1.1611,  ...,  1.2207, -1.1797, -0.1079],
         [-1.5967,  0.1060, -0.6582,  ...,  1.0186, -2.0332, -0.0741]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0859,  0.4355, -0.4885],
         [-0.9844,  0.3347,  0.1134,  ..., -0.2430,  0.2603, -0.1544],
         [-0.6548, -1.0459,  0.9092,  ..., -0.6089,  0.3101, -2.6719],
         ...,
         [-1.0508, -0.4790,  1.6562,  ..., -0.2734, -0.9751, -1.5234],
         [-0.6543,  0.7959,  1.1836,  ..., -1.5029, -0.8794, -1.8457],
         [-1.2041, -0.0306,  1.6377,  ..., -0.2292, -1.0596, -2.1875]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, prompt
tensor([[[-5.2051e-01, -1.3232e-01,  4.0356e-01,  ..., -5.8496e-01,
           6.2842e-01, -6.1035e-03],
         [-1.4551e+00, -2.0386e-02, -3.2617e-01,  ..., -2.1328e+00,
           7.2510e-01,  3.5034e-01],
         [ 9.4336e-01,  1.9751e-01,  1.7700e-01,  ..., -1.4072e+00,
           5.1660e-01, -8.5815e-02],
         ...,
         [-1.7773e+00, -8.3618e-03, -1.6077e-01,  ..., -1.8477e+00,
           4.5020e-01, -7.7441e-01],
         [-1.1853e-01, -4.2664e-02, -8.7988e-01,  ..., -9.8584e-01,
           5.6445e-01, -1.9385e-01],
         [ 1.5576e+00, -4.0356e-01, -1.7664e-01,  ..., -1.9912e+00,
           8.1055e-01, -8.3618e-03]],

        [[ 4.4775e-01,  7.4268e-01, -8.6426e-02,  ...,  7.2217e-01,
          -1.2646e-01,  1.1289e+00],
         [ 5.1758e-01,  5.0830e-01, -1.5293e+00,  ...,  1.6846e-02,
           4.1357e-01,  2.6523e+00],
         [ 2.4268e-01,  5.2246e-02, -1.9668e+00,  ...,  4.2139e-01,
           1.0732e+00,  1.8984e+00],
         ...,
         [-4.9292e-01, -4.0088e-01,  9.7656e-04,  ..., -2.2363e+00,
           3.4961e+00,  2.3789e+00],
         [-1.7065e-01, -2.0020e-02,  3.2080e-01,  ..., -1.2852e+00,
           1.4531e+00,  9.1211e-01],
         [-7.6538e-02,  5.1367e-01,  1.7041e+00,  ..., -1.7744e+00,
           2.4102e+00,  8.9355e-01]],

        [[-1.2676e+00,  3.6572e-01,  1.1709e+00,  ...,  1.5918e+00,
          -9.0527e-01,  8.3105e-01],
         [-2.5977e+00,  2.3242e-01,  1.9131e+00,  ...,  2.3711e+00,
          -2.4805e-01,  5.0244e-01],
         [-2.3516e+00, -2.9639e-01,  1.8721e+00,  ...,  2.7090e+00,
          -1.9397e-01, -1.4612e-01],
         ...,
         [-2.5977e+00, -2.4121e+00,  9.6826e-01,  ...,  2.7344e+00,
          -1.6885e+00,  2.2285e+00],
         [-1.3027e+00, -1.3379e+00,  2.8174e-01,  ...,  1.5459e+00,
          -5.5859e-01,  1.0820e+00],
         [-1.3613e+00, -2.4199e+00,  4.8828e-03,  ...,  2.1426e+00,
           3.5571e-01,  9.3457e-01]],

        ...,

        [[ 2.0752e-01, -1.1469e-01, -8.4045e-02,  ..., -1.4758e-01,
           6.2402e-01, -4.5483e-01],
         [-3.7891e-01, -2.7905e-01,  8.1201e-01,  ..., -9.4922e-01,
           5.4766e+00, -9.9414e-01],
         [ 1.2480e+00, -5.0049e-01,  1.4629e+00,  ..., -4.0381e-01,
           3.2637e+00, -1.1553e+00],
         ...,
         [-8.9478e-02, -4.7388e-01,  4.5898e-01,  ..., -1.0459e+00,
           7.7227e+00, -2.9541e-02],
         [ 2.2424e-01, -2.2510e-01,  2.7588e-02,  ..., -2.5684e-01,
           1.4824e+00, -4.7168e-01],
         [ 1.2134e-01, -6.1523e-01, -2.0435e-01,  ...,  1.0547e+00,
           5.8398e+00, -2.8589e-01]],

        [[-2.0337e-01, -1.6101e-01, -2.1423e-01,  ..., -3.8940e-02,
          -1.3291e+00,  5.3125e-01],
         [-1.3281e+00, -1.1963e+00,  5.3613e-01,  ...,  6.0938e-01,
          -1.4727e+00,  9.9219e-01],
         [-1.1250e+00, -1.4961e+00, -7.5195e-01,  ..., -9.4971e-01,
          -2.2539e+00, -1.1104e+00],
         ...,
         [-4.7144e-01, -5.0439e-01, -2.2217e-01,  ..., -3.0273e-02,
          -2.6484e+00,  4.9927e-01],
         [-2.7856e-01, -1.6418e-01, -4.2651e-01,  ...,  5.6915e-02,
          -1.4775e+00,  5.3174e-01],
         [ 8.0664e-01,  1.2494e-01,  1.4111e-01,  ...,  5.9912e-01,
          -1.6270e+00, -6.7078e-02]],

        [[-6.5771e-01,  5.1416e-01, -7.0374e-02,  ..., -2.0605e-01,
           2.3669e-01, -1.4319e-01],
         [-5.2295e-01,  3.5156e-01,  2.4355e+00,  ..., -1.0703e+00,
           1.2334e+00, -8.6963e-01],
         [-1.1680e+00, -3.2764e-01,  1.5049e+00,  ..., -1.2266e+00,
          -5.4785e-01, -2.1602e+00],
         ...,
         [-9.6436e-01,  7.0361e-01,  1.5459e+00,  ..., -5.3857e-01,
          -4.9268e-01, -1.3818e+00],
         [-6.9873e-01,  4.7656e-01,  1.3965e-01,  ..., -3.7646e-01,
           1.8530e-01, -3.3325e-01],
         [-1.1299e+00,  1.4482e+00,  2.3379e+00,  ..., -9.3799e-01,
          -4.7388e-01, -1.2891e+00]]], device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, prompt
tensor([[[ 1.9238e+00, -6.2842e-01,  3.1055e-01,  ...,  2.2148e+00,
          -7.9834e-01,  8.7769e-02],
         [ 2.2969e+00, -4.9463e-01,  4.0918e-01,  ...,  2.5000e+00,
          -1.0967e+00, -1.8884e-01],
         [ 3.6621e-01, -3.1250e-02, -3.2544e-01,  ...,  2.4883e+00,
          -1.5674e+00, -4.3237e-01],
         ...,
         [ 2.0840e+00, -4.8096e-02, -6.2061e-01,  ...,  2.5098e+00,
          -1.8018e-01,  9.6558e-02],
         [ 2.3340e+00, -5.8105e-01, -5.3174e-01,  ...,  2.6230e+00,
          -8.6230e-01, -4.1992e-02],
         [-2.6465e-01, -2.7661e-01, -5.3772e-02,  ...,  1.1982e+00,
          -1.1201e+00,  5.8496e-01]],

        [[-1.1133e+00, -1.6670e+00,  1.6406e-01,  ..., -2.0957e+00,
           7.3730e-01, -3.1367e+00],
         [-9.1113e-01, -2.0762e+00,  5.8691e-01,  ..., -1.7754e+00,
           9.2480e-01, -3.7695e+00],
         [-1.0400e+00, -1.8096e+00,  1.1182e+00,  ..., -1.3086e+00,
           9.4043e-01, -4.1797e+00],
         ...,
         [ 7.2754e-01,  2.0469e+00,  6.8066e-01,  ...,  1.7529e+00,
          -3.4961e+00, -3.1934e-01],
         [ 1.1689e+00,  1.8545e+00, -7.8613e-01,  ...,  2.0996e+00,
          -3.2598e+00,  5.4102e-01],
         [ 7.5879e-01,  1.3447e+00, -2.1133e+00,  ...,  2.3535e+00,
          -2.8828e+00,  1.2441e+00]],

        [[-1.6797e-01, -2.4766e+00, -6.1230e-01,  ..., -7.2461e-01,
          -1.7004e-01, -1.6445e+00],
         [-3.6816e-01, -2.7734e+00, -6.6895e-01,  ..., -8.0957e-01,
          -3.8135e-01, -1.5977e+00],
         [-2.8516e-01, -3.0977e+00, -1.1807e+00,  ..., -1.3652e+00,
          -1.7812e+00, -1.0801e+00],
         ...,
         [-3.5273e+00, -3.4648e+00,  1.4717e+00,  ..., -2.2500e+00,
          -1.3926e+00, -1.0684e+00],
         [-3.1816e+00, -2.7285e+00,  1.9893e+00,  ..., -1.8809e+00,
           3.4821e-02, -1.3525e+00],
         [-2.9785e+00, -2.1328e+00,  1.3594e+00,  ..., -2.3809e+00,
          -2.0728e-01, -1.4814e+00]],

        ...,

        [[-4.3716e-03, -2.1436e-01, -1.1162e+00,  ..., -5.8936e-01,
           5.1328e+00, -1.5703e+00],
         [-6.1584e-02,  4.8193e-01, -5.2441e-01,  ...,  3.7842e-01,
           6.6914e+00, -1.7490e+00],
         [ 9.6558e-02, -1.4478e-01,  3.5797e-02,  ..., -3.8965e-01,
           6.3594e+00, -7.8418e-01],
         ...,
         [-1.4954e-01, -2.0325e-02, -2.0837e-01,  ...,  1.3794e-01,
           6.6055e+00, -9.4775e-01],
         [-3.3691e-01,  4.0222e-02, -4.1840e-02,  ..., -2.3486e-01,
           6.4258e+00, -3.9453e-01],
         [-7.2510e-01,  2.8778e-02, -1.1969e-01,  ...,  3.6133e-01,
           4.9141e+00, -1.4414e+00]],

        [[-7.4609e-01,  3.6475e-01,  1.8811e-01,  ..., -4.8267e-01,
          -2.1035e+00, -2.9907e-02],
         [-8.5986e-01, -9.0918e-01, -6.1426e-01,  ..., -3.3276e-01,
          -2.1660e+00,  1.8774e-01],
         [-5.4590e-01, -5.7031e-01, -5.2246e-01,  ...,  2.6318e-01,
          -2.5312e+00,  2.2839e-01],
         ...,
         [-1.8481e-01, -2.4023e-01, -8.8721e-01,  ...,  3.9429e-01,
          -2.3145e+00,  5.0586e-01],
         [-9.5068e-01, -1.0205e+00, -8.5986e-01,  ..., -2.2363e-01,
          -3.0273e+00,  5.7129e-01],
         [-1.0029e+00,  3.9038e-01,  2.8564e-02,  ..., -5.9277e-01,
          -3.1211e+00,  2.3193e-02]],

        [[-1.6133e+00,  2.5781e-01,  8.4863e-01,  ..., -6.2012e-01,
          -3.6133e-01, -1.2129e+00],
         [-1.5215e+00,  1.1875e+00,  1.7568e+00,  ..., -4.2725e-01,
          -1.1172e+00, -1.3848e+00],
         [-9.0820e-01,  9.3848e-01,  1.2852e+00,  ..., -2.9053e-01,
          -4.9341e-01, -1.3350e+00],
         ...,
         [-1.4785e+00,  1.2422e+00,  1.3350e+00,  ..., -5.2051e-01,
          -1.0244e+00, -1.6670e+00],
         [-1.1875e+00,  9.5801e-01,  1.6465e+00,  ...,  3.3252e-01,
          -1.5918e+00, -1.6699e+00],
         [-5.5811e-01,  9.7070e-01,  1.6885e+00,  ..., -1.0400e+00,
          -1.7891e+00, -2.2656e+00]]], device='cuda:0', dtype=torch.float16)
iter_num: 155, on_card_num: 104, preempted blk num: 180
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 2.0840, -0.0481, -0.6206,  ...,  2.5098, -0.1802,  0.0966],
         [ 2.3340, -0.5811, -0.5317,  ...,  2.6230, -0.8623, -0.0420],
         [-0.2646, -0.2766, -0.0538,  ...,  1.1982, -1.1201,  0.5850]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.7275,  2.0469,  0.6807,  ...,  1.7529, -3.4961, -0.3193],
         [ 1.1689,  1.8545, -0.7861,  ...,  2.0996, -3.2598,  0.5410],
         [ 0.7588,  1.3447, -2.1133,  ...,  2.3535, -2.8828,  1.2441]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-3.5273, -3.4648,  1.4717,  ..., -2.2500, -1.3926, -1.0684],
         [-3.1816, -2.7285,  1.9893,  ..., -1.8809,  0.0348, -1.3525],
         [-2.9785, -2.1328,  1.3594,  ..., -2.3809, -0.2073, -1.4814]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.1495, -0.0203, -0.2084,  ...,  0.1379,  6.6055, -0.9478],
         [-0.3369,  0.0402, -0.0418,  ..., -0.2349,  6.4258, -0.3945],
         [-0.7251,  0.0288, -0.1197,  ...,  0.3613,  4.9141, -1.4414]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.1848, -0.2402, -0.8872,  ...,  0.3943, -2.3145,  0.5059],
         [-0.9507, -1.0205, -0.8599,  ..., -0.2236, -3.0273,  0.5713],
         [-1.0029,  0.3904,  0.0286,  ..., -0.5928, -3.1211,  0.0232]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-1.4785,  1.2422,  1.3350,  ..., -0.5205, -1.0244, -1.6670],
         [-1.1875,  0.9580,  1.6465,  ...,  0.3325, -1.5918, -1.6699],
         [-0.5581,  0.9707,  1.6885,  ..., -1.0400, -1.7891, -2.2656]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 156, on_card_num: 102, preempted blk num: 180
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 2.0840, -0.0481, -0.6206,  ...,  2.5098, -0.1802,  0.0966],
         [ 2.3340, -0.5811, -0.5317,  ...,  2.6230, -0.8623, -0.0420],
         [-0.2646, -0.2766, -0.0538,  ...,  1.1982, -1.1201,  0.5850]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.7275,  2.0469,  0.6807,  ...,  1.7529, -3.4961, -0.3193],
         [ 1.1689,  1.8545, -0.7861,  ...,  2.0996, -3.2598,  0.5410],
         [ 0.7588,  1.3447, -2.1133,  ...,  2.3535, -2.8828,  1.2441]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-3.5273, -3.4648,  1.4717,  ..., -2.2500, -1.3926, -1.0684],
         [-3.1816, -2.7285,  1.9893,  ..., -1.8809,  0.0348, -1.3525],
         [-2.9785, -2.1328,  1.3594,  ..., -2.3809, -0.2073, -1.4814]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.1495, -0.0203, -0.2084,  ...,  0.1379,  6.6055, -0.9478],
         [-0.3369,  0.0402, -0.0418,  ..., -0.2349,  6.4258, -0.3945],
         [-0.7251,  0.0288, -0.1197,  ...,  0.3613,  4.9141, -1.4414]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.1848, -0.2402, -0.8872,  ...,  0.3943, -2.3145,  0.5059],
         [-0.9507, -1.0205, -0.8599,  ..., -0.2236, -3.0273,  0.5713],
         [-1.0029,  0.3904,  0.0286,  ..., -0.5928, -3.1211,  0.0232]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-1.4785,  1.2422,  1.3350,  ..., -0.5205, -1.0244, -1.6670],
         [-1.1875,  0.9580,  1.6465,  ...,  0.3325, -1.5918, -1.6699],
         [-0.5581,  0.9707,  1.6885,  ..., -1.0400, -1.7891, -2.2656]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 157, on_card_num: 101, preempted blk num: 180
iter_num: 158, on_card_num: 102, preempted blk num: 180
iter_num: 159, on_card_num: 106, preempted blk num: 180
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 2.3340, -0.5811, -0.5317,  ...,  2.6230, -0.8623, -0.0420],
         [-0.2646, -0.2766, -0.0538,  ...,  1.1982, -1.1201,  0.5850]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 1.1689,  1.8545, -0.7861,  ...,  2.0996, -3.2598,  0.5410],
         [ 0.7588,  1.3447, -2.1133,  ...,  2.3535, -2.8828,  1.2441]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-3.1816, -2.7285,  1.9893,  ..., -1.8809,  0.0348, -1.3525],
         [-2.9785, -2.1328,  1.3594,  ..., -2.3809, -0.2073, -1.4814]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.3369,  0.0402, -0.0418,  ..., -0.2349,  6.4258, -0.3945],
         [-0.7251,  0.0288, -0.1197,  ...,  0.3613,  4.9141, -1.4414]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.9507, -1.0205, -0.8599,  ..., -0.2236, -3.0273,  0.5713],
         [-1.0029,  0.3904,  0.0286,  ..., -0.5928, -3.1211,  0.0232]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-1.1875,  0.9580,  1.6465,  ...,  0.3325, -1.5918, -1.6699],
         [-0.5581,  0.9707,  1.6885,  ..., -1.0400, -1.7891, -2.2656]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 160, on_card_num: 105, preempted blk num: 180
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [-0.2646, -0.2766, -0.0538,  ...,  1.1982, -1.1201,  0.5850]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.7588,  1.3447, -2.1133,  ...,  2.3535, -2.8828,  1.2441]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-2.9785, -2.1328,  1.3594,  ..., -2.3809, -0.2073, -1.4814]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.7251,  0.0288, -0.1197,  ...,  0.3613,  4.9141, -1.4414]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-1.0029,  0.3904,  0.0286,  ..., -0.5928, -3.1211,  0.0232]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-0.5581,  0.9707,  1.6885,  ..., -1.0400, -1.7891, -2.2656]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 161, on_card_num: 105, preempted blk num: 180
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 162, on_card_num: 105, preempted blk num: 180
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 163, on_card_num: 105, preempted blk num: 180
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 164, on_card_num: 103, preempted blk num: 180
iter_num: 165, on_card_num: 104, preempted blk num: 180
iter_num: 166, on_card_num: 106, preempted blk num: 180
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 167, on_card_num: 106, preempted blk num: 180
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 168, on_card_num: 105, preempted blk num: 180
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 169, on_card_num: 105, preempted blk num: 180
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 170, on_card_num: 105, preempted blk num: 180
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 171, on_card_num: 104, preempted blk num: 180
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 172, on_card_num: 104, preempted blk num: 180
to recompute 1: ('165', 21)
to recompute 1: ('164', 12)
to recompute 1: ('163', 450)
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 173, on_card_num: 100, preempted blk num: 244
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 174, on_card_num: 100, preempted blk num: 244
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 175, on_card_num: 99, preempted blk num: 244
iter_num: 176, on_card_num: 100, preempted blk num: 244
iter_num: 177, on_card_num: 101, preempted blk num: 244
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 178, on_card_num: 101, preempted blk num: 244
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 179, on_card_num: 99, preempted blk num: 244
iter_num: 180, on_card_num: 100, preempted blk num: 244
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 181, on_card_num: 100, preempted blk num: 244
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 182, on_card_num: 99, preempted blk num: 244
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 183, on_card_num: 99, preempted blk num: 244
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 184, on_card_num: 98, preempted blk num: 244
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 185, on_card_num: 98, preempted blk num: 244
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 186, on_card_num: 98, preempted blk num: 244
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 187, on_card_num: 98, preempted blk num: 244
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 188, on_card_num: 98, preempted blk num: 244
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 189, on_card_num: 97, preempted blk num: 244
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 190, on_card_num: 97, preempted blk num: 244
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 191, on_card_num: 96, preempted blk num: 244
iter_num: 192, on_card_num: 97, preempted blk num: 244
iter_num: 193, on_card_num: 99, preempted blk num: 244
iter_num: 194, on_card_num: 100, preempted blk num: 244
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 195, on_card_num: 99, preempted blk num: 244
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 196, on_card_num: 97, preempted blk num: 244
iter_num: 197, on_card_num: 99, preempted blk num: 244
iter_num: 198, on_card_num: 100, preempted blk num: 244
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 199, on_card_num: 100, preempted blk num: 244
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 200, on_card_num: 100, preempted blk num: 244
to recompute 1: ('172', 11)
to recompute 1: ('171', 409)
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 201, on_card_num: 98, preempted blk num: 298
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 202, on_card_num: 98, preempted blk num: 298
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 203, on_card_num: 98, preempted blk num: 298
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 204, on_card_num: 98, preempted blk num: 298
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 205, on_card_num: 98, preempted blk num: 298
to recompute 1: ('170', 256)
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 206, on_card_num: 97, preempted blk num: 330
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 207, on_card_num: 97, preempted blk num: 330
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 208, on_card_num: 97, preempted blk num: 330
to recompute 1: ('169', 27)
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 209, on_card_num: 95, preempted blk num: 334
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 210, on_card_num: 95, preempted blk num: 334
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 211, on_card_num: 95, preempted blk num: 334
to recompute 1: ('168', 198)
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 212, on_card_num: 94, preempted blk num: 360
to recompute 1: ('167', 84)
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 213, on_card_num: 93, preempted blk num: 372
to recompute 1: ('166', 479)
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 214, on_card_num: 92, preempted blk num: 432
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 215, on_card_num: 91, preempted blk num: 432
iter_num: 216, on_card_num: 92, preempted blk num: 432
iter_num: 217, on_card_num: 94, preempted blk num: 432
iter_num: 218, on_card_num: 95, preempted blk num: 432
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 219, on_card_num: 95, preempted blk num: 432
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 220, on_card_num: 95, preempted blk num: 432
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 221, on_card_num: 95, preempted blk num: 432
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 222, on_card_num: 95, preempted blk num: 432
to recompute 1: ('169', 32)
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 223, on_card_num: 94, preempted blk num: 436
to recompute 1: ('168', 204)
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 224, on_card_num: 92, preempted blk num: 462
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 225, on_card_num: 92, preempted blk num: 462
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 226, on_card_num: 92, preempted blk num: 462
to recompute 1: ('166', 488)
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 227, on_card_num: 91, preempted blk num: 524
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 228, on_card_num: 90, preempted blk num: 524
iter_num: 229, on_card_num: 91, preempted blk num: 524
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 230, on_card_num: 91, preempted blk num: 524
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 231, on_card_num: 91, preempted blk num: 524
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 232, on_card_num: 91, preempted blk num: 524
to recompute 1: ('166', 492)
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 233, on_card_num: 90, preempted blk num: 586
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 234, on_card_num: 89, preempted blk num: 586
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 235, on_card_num: 89, preempted blk num: 586
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 236, on_card_num: 88, preempted blk num: 586
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 237, on_card_num: 88, preempted blk num: 586
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 238, on_card_num: 88, preempted blk num: 586
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 239, on_card_num: 88, preempted blk num: 586
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 240, on_card_num: 88, preempted blk num: 586
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 241, on_card_num: 86, preempted blk num: 586
iter_num: 242, on_card_num: 87, preempted blk num: 586
iter_num: 243, on_card_num: 89, preempted blk num: 586
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 244, on_card_num: 89, preempted blk num: 586
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 245, on_card_num: 88, preempted blk num: 586
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 246, on_card_num: 88, preempted blk num: 586
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 247, on_card_num: 88, preempted blk num: 586
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 248, on_card_num: 88, preempted blk num: 586
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 249, on_card_num: 88, preempted blk num: 586
to recompute 1: ('169', 39)
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 250, on_card_num: 87, preempted blk num: 592
to recompute 1: ('168', 212)
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 251, on_card_num: 86, preempted blk num: 620
to recompute 1: ('166', 501)
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 252, on_card_num: 85, preempted blk num: 684
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 253, on_card_num: 85, preempted blk num: 684
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 254, on_card_num: 85, preempted blk num: 684
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 255, on_card_num: 85, preempted blk num: 684
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 256, on_card_num: 85, preempted blk num: 684
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 257, on_card_num: 85, preempted blk num: 684
to recompute 1: ('165', 88)
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 258, on_card_num: 84, preempted blk num: 696
to recompute 1: ('164', 82)
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 259, on_card_num: 83, preempted blk num: 708
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 260, on_card_num: 83, preempted blk num: 708
to recompute 1: ('162', 104)
to recompute 2: ('161', 123)
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 261, on_card_num: 80, preempted blk num: 738
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 262, on_card_num: 80, preempted blk num: 738
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 263, on_card_num: 80, preempted blk num: 738
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 264, on_card_num: 80, preempted blk num: 738
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 265, on_card_num: 80, preempted blk num: 738
to recompute 1: ('160', 102)
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 266, on_card_num: 78, preempted blk num: 752
iter_num: 267, on_card_num: 83, preempted blk num: 752
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 268, on_card_num: 83, preempted blk num: 752
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 269, on_card_num: 83, preempted blk num: 752
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 270, on_card_num: 83, preempted blk num: 752
to recompute 1: ('165', 92)
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 271, on_card_num: 81, preempted blk num: 764
iter_num: 272, on_card_num: 82, preempted blk num: 764
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 273, on_card_num: 82, preempted blk num: 764
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 274, on_card_num: 82, preempted blk num: 764
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 275, on_card_num: 82, preempted blk num: 764
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 276, on_card_num: 81, preempted blk num: 764
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 277, on_card_num: 81, preempted blk num: 764
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 278, on_card_num: 81, preempted blk num: 764
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 279, on_card_num: 81, preempted blk num: 764
to recompute 1: ('165', 100)
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 280, on_card_num: 78, preempted blk num: 778
iter_num: 281, on_card_num: 79, preempted blk num: 778
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 282, on_card_num: 79, preempted blk num: 778
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 283, on_card_num: 78, preempted blk num: 778
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 284, on_card_num: 78, preempted blk num: 778
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 285, on_card_num: 77, preempted blk num: 778
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 286, on_card_num: 77, preempted blk num: 778
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 287, on_card_num: 77, preempted blk num: 778
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 288, on_card_num: 77, preempted blk num: 778
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 289, on_card_num: 77, preempted blk num: 778
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 290, on_card_num: 77, preempted blk num: 778
to recompute 1: ('165', 110)
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 291, on_card_num: 76, preempted blk num: 792
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 292, on_card_num: 76, preempted blk num: 792
to recompute 1: ('164', 106)
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 293, on_card_num: 75, preempted blk num: 806
to recompute 1: ('161', 148)
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 294, on_card_num: 73, preempted blk num: 826
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 295, on_card_num: 73, preempted blk num: 826
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 296, on_card_num: 73, preempted blk num: 826
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 297, on_card_num: 73, preempted blk num: 826
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1671, -0.9507,  1.9863,  ...,  0.4375,  0.7729, -0.0466],
         [-1.1338,  0.3530,  0.2764,  ...,  0.1489,  0.9785, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0836],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1470,  0.4536, -0.4084],
         [-1.4668, -0.8447, -0.1113,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3242,  0.6699,  ..., -1.4590,  1.4727, -0.3813]],

        [[-0.3848,  0.7886, -0.4648,  ...,  1.0430,  0.0971,  1.0986],
         [-0.9297,  1.4551, -1.2783,  ...,  1.3848, -0.1026,  1.7480],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9473,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5835, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1780],
         [ 1.6641, -0.6743, -1.7197,  ..., -0.9727,  1.2607,  0.1265],
         [ 1.6152, -1.3662, -1.5547,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5186, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4624]],

        ...,

        [[-0.1334, -0.0347, -1.2891,  ..., -0.3796,  0.6245, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7168, -0.1787],
         [ 0.1635, -0.0851, -0.7012,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0748, -0.0519, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3237, -0.1798, -0.0242,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2747,  ..., -0.5986,  4.6914, -0.6880]],

        [[-0.3997,  0.2394, -0.1694,  ...,  0.4900, -0.4705,  0.0252],
         [-0.7324, -0.0698, -0.5942,  ...,  0.3823, -1.8477,  0.1545],
         [-0.6265, -0.6313, -0.2905,  ...,  0.3015, -1.7881,  0.3872],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5771, -0.5044, -0.2837,  ...,  0.8633, -1.7334,  0.3528],
         [-0.2327, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3567]],

        [[-1.1104, -0.0304,  0.0474,  ..., -0.0858,  0.4355, -0.4888],
         [-1.6035, -0.5098,  0.7588,  ..., -0.5518, -0.1561, -1.1191],
         [-1.5732,  0.2025,  0.5737,  ...,  0.0506,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0764,  0.8442,  ..., -0.2257, -0.1467, -0.6816],
         [-1.2900,  0.3640,  0.4602,  ..., -0.2382, -0.1344, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1458, -0.4700, -0.4331]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7842, -0.0734,  0.3818,  ...,  1.6562,  1.0225,  0.1001],
         [ 1.9453, -0.0798,  0.2979,  ..., -0.0464,  0.8032,  0.0563],
         [-0.4248, -0.3284,  0.6934,  ..., -0.9209,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9219,  ...,  2.3145, -0.2498, -0.8286],
         [ 0.3506, -0.2386, -0.7573,  ...,  1.6367,  0.3865, -0.5459],
         [-0.4912, -0.3579, -0.1056,  ...,  0.0620,  0.8677, -0.4414]],

        [[-0.0212, -1.9199, -1.7705,  ...,  0.3589, -2.6680, -2.6738],
         [-0.6641, -1.8809, -0.2554,  ...,  0.6597, -2.6641, -1.4824],
         [-0.7739, -1.8809,  0.0977,  ...,  0.5396, -2.9883, -1.4023],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5352, -1.9854,  2.2129],
         [ 0.7603,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3477],
         [ 1.0166,  1.4023,  1.2422,  ...,  1.6543, -1.3789,  2.7617]],

        [[ 1.8164,  3.3281,  1.5908,  ...,  1.6035, -0.9692,  0.6626],
         [ 1.0742,  2.8242,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1445,  2.0586,  ...,  1.0117, -0.3235, -0.2749],
         ...,
         [-1.8896,  1.9961,  2.4531,  ...,  2.2266, -0.1482,  0.7578],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3350],
         [-2.3594,  1.7773,  3.1504,  ...,  2.4648, -1.1621,  1.2393]],

        ...,

        [[-0.1951, -0.6079, -0.8174,  ..., -0.5234,  7.4141, -0.6045],
         [ 1.5615, -0.4302,  0.2249,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4600, -0.8550,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2903, -0.2458, -0.2297,  ..., -0.8770,  7.6562, -0.7441],
         [-0.3147, -0.1313, -0.2203,  ..., -0.0824,  7.2539, -0.0266],
         [-0.0676, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4692, -0.9956, -0.7144,  ...,  0.2810, -3.6777, -0.2322],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1207, -2.4414, -0.1289],
         [-0.6343, -1.9473, -0.3604,  ..., -0.1587, -2.8535,  0.0410],
         ...,
         [-0.8667, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1476],
         [-0.3354, -0.6460, -0.3403,  ...,  0.2084, -3.3516, -0.0214],
         [ 0.2830, -0.5381, -0.0674,  ...,  0.2715, -2.4785,  0.1084]],

        [[-0.9683,  1.1445,  1.5566,  ..., -0.2437, -0.3677, -1.1309],
         [-0.3479, -1.2949,  1.4189,  ..., -0.1599,  0.1750, -2.9648],
         [-0.5776,  0.1425,  2.4707,  ...,  0.2317, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7563, -1.3379],
         [-0.4487,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0088,  0.8267,  1.5342,  ..., -0.5103, -0.5513, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0059,  0.5806, -0.2637,  ..., -2.5000, -0.4404, -0.4282],
         [ 1.7871,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1154],
         ...,
         [ 0.8667, -0.6387, -0.1823,  ..., -1.3408, -0.9951,  0.3567],
         [ 1.0273, -0.4844,  0.3325,  ..., -1.7822, -0.7188,  0.1542],
         [ 0.3232,  0.2074,  0.0818,  ..., -1.4043, -0.2942,  0.0706]],

        [[-0.2588,  1.8027, -3.2910,  ...,  0.2290, -0.9404, -2.5098],
         [-0.8105,  1.9248, -3.9102,  ...,  0.1440, -0.3184, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6729, -1.4072,  2.6934,  ...,  1.6289,  2.4746,  1.5723],
         [ 0.5073, -1.0527,  2.9004,  ...,  1.5547,  2.6797,  1.8682],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5059,  ...,  1.5420,  0.4790, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0391, -0.2778,  ...,  0.0107,  2.0117, -0.9023],
         [-1.4971, -2.2715, -0.2666,  ..., -0.0371,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8604, -1.1494]],

        ...,

        [[ 0.2644,  0.1318, -0.5850,  ...,  0.2267,  1.6729, -2.4238],
         [ 0.2064,  0.4226, -0.4895,  ...,  0.1116,  2.6836, -1.2314],
         [-0.6528, -0.0367,  0.4382,  ...,  0.2208,  2.2988, -0.2410],
         ...,
         [-0.0066,  0.1272,  1.0898,  ...,  0.7935,  1.3750, -1.3516],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4336,  0.9863, -2.4785]],

        [[-0.1903, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1980],
         [-0.2163, -0.0923,  0.3135,  ..., -0.6133, -2.5820, -0.2769],
         [-0.5635,  0.2036,  0.2896,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3132, -0.0393,  0.2903,  ..., -0.1802, -1.8330,  0.0391],
         [-0.3625, -0.2229,  0.1912,  ..., -0.1831, -1.9082, -0.2207],
         [-0.4683, -0.9668,  0.0669,  ..., -0.5103, -1.7354, -1.0459]],

        [[-1.2051,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7788,  1.6416,  ..., -0.2937, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3323, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8145,  ..., -0.0765, -0.0717, -0.3169],
         [-2.3008,  0.9004,  0.9629,  ..., -0.3069, -0.1312, -0.4475],
         [-1.4385, -0.2603,  0.3064,  ..., -1.0811, -0.3313, -1.7773]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 298, on_card_num: 73, preempted blk num: 826
to recompute 1: ('157', 1143)
iter_num: 299, on_card_num: 72, preempted blk num: 970
iter_num: 300, on_card_num: 72, preempted blk num: 970
iter_num: 301, on_card_num: 72, preempted blk num: 970
iter_num: 302, on_card_num: 72, preempted blk num: 970
iter_num: 303, on_card_num: 72, preempted blk num: 970
iter_num: 304, on_card_num: 72, preempted blk num: 970
iter_num: 305, on_card_num: 72, preempted blk num: 970
iter_num: 306, on_card_num: 72, preempted blk num: 970
iter_num: 307, on_card_num: 72, preempted blk num: 970
iter_num: 308, on_card_num: 72, preempted blk num: 970
iter_num: 309, on_card_num: 71, preempted blk num: 970
iter_num: 310, on_card_num: 71, preempted blk num: 970
iter_num: 311, on_card_num: 71, preempted blk num: 970
iter_num: 312, on_card_num: 71, preempted blk num: 970
iter_num: 313, on_card_num: 71, preempted blk num: 970
iter_num: 314, on_card_num: 70, preempted blk num: 970
iter_num: 315, on_card_num: 70, preempted blk num: 970
iter_num: 316, on_card_num: 69, preempted blk num: 970
iter_num: 317, on_card_num: 68, preempted blk num: 970
iter_num: 318, on_card_num: 68, preempted blk num: 970
iter_num: 319, on_card_num: 68, preempted blk num: 970
iter_num: 320, on_card_num: 68, preempted blk num: 970
iter_num: 321, on_card_num: 68, preempted blk num: 970
iter_num: 322, on_card_num: 68, preempted blk num: 970
iter_num: 323, on_card_num: 68, preempted blk num: 970
iter_num: 324, on_card_num: 68, preempted blk num: 970
iter_num: 325, on_card_num: 68, preempted blk num: 970
iter_num: 326, on_card_num: 68, preempted blk num: 970
iter_num: 327, on_card_num: 68, preempted blk num: 970
to recompute 1: ('155', 523)
iter_num: 328, on_card_num: 67, preempted blk num: 1036
iter_num: 329, on_card_num: 67, preempted blk num: 1036
iter_num: 330, on_card_num: 67, preempted blk num: 1036
iter_num: 331, on_card_num: 67, preempted blk num: 1036
iter_num: 332, on_card_num: 67, preempted blk num: 1036
iter_num: 333, on_card_num: 67, preempted blk num: 1036
iter_num: 334, on_card_num: 67, preempted blk num: 1036
to recompute 1: ('154', 242)
iter_num: 335, on_card_num: 66, preempted blk num: 1068
iter_num: 336, on_card_num: 65, preempted blk num: 1068
iter_num: 337, on_card_num: 65, preempted blk num: 1068
iter_num: 338, on_card_num: 65, preempted blk num: 1068
iter_num: 339, on_card_num: 65, preempted blk num: 1068
iter_num: 340, on_card_num: 65, preempted blk num: 1068
iter_num: 341, on_card_num: 65, preempted blk num: 1068
iter_num: 342, on_card_num: 65, preempted blk num: 1068
iter_num: 343, on_card_num: 64, preempted blk num: 1068
iter_num: 344, on_card_num: 63, preempted blk num: 1068
iter_num: 345, on_card_num: 63, preempted blk num: 1068
iter_num: 346, on_card_num: 63, preempted blk num: 1068
iter_num: 347, on_card_num: 63, preempted blk num: 1068
iter_num: 348, on_card_num: 63, preempted blk num: 1068
iter_num: 349, on_card_num: 63, preempted blk num: 1068
iter_num: 350, on_card_num: 63, preempted blk num: 1068
to recompute 1: ('152', 432)
iter_num: 351, on_card_num: 62, preempted blk num: 1122
iter_num: 352, on_card_num: 62, preempted blk num: 1122
iter_num: 353, on_card_num: 62, preempted blk num: 1122
iter_num: 354, on_card_num: 62, preempted blk num: 1122
iter_num: 355, on_card_num: 62, preempted blk num: 1122
iter_num: 356, on_card_num: 62, preempted blk num: 1122
iter_num: 357, on_card_num: 61, preempted blk num: 1122
iter_num: 358, on_card_num: 60, preempted blk num: 1122
iter_num: 359, on_card_num: 60, preempted blk num: 1122
iter_num: 360, on_card_num: 60, preempted blk num: 1122
iter_num: 361, on_card_num: 59, preempted blk num: 1122
iter_num: 362, on_card_num: 59, preempted blk num: 1122
iter_num: 363, on_card_num: 59, preempted blk num: 1122
iter_num: 364, on_card_num: 59, preempted blk num: 1122
iter_num: 365, on_card_num: 59, preempted blk num: 1122
iter_num: 366, on_card_num: 59, preempted blk num: 1122
iter_num: 367, on_card_num: 59, preempted blk num: 1122
iter_num: 368, on_card_num: 58, preempted blk num: 1122
iter_num: 369, on_card_num: 58, preempted blk num: 1122
iter_num: 370, on_card_num: 58, preempted blk num: 1122
iter_num: 371, on_card_num: 58, preempted blk num: 1122
iter_num: 372, on_card_num: 58, preempted blk num: 1122
iter_num: 373, on_card_num: 58, preempted blk num: 1122
iter_num: 374, on_card_num: 58, preempted blk num: 1122
iter_num: 375, on_card_num: 58, preempted blk num: 1122
to recompute 1: ('149', 388)
iter_num: 376, on_card_num: 54, preempted blk num: 1172
iter_num: 377, on_card_num: 56, preempted blk num: 1172
iter_num: 378, on_card_num: 55, preempted blk num: 1172
iter_num: 379, on_card_num: 56, preempted blk num: 1172
iter_num: 380, on_card_num: 56, preempted blk num: 1172
iter_num: 381, on_card_num: 55, preempted blk num: 1172
iter_num: 382, on_card_num: 55, preempted blk num: 1172
iter_num: 383, on_card_num: 55, preempted blk num: 1172
iter_num: 384, on_card_num: 55, preempted blk num: 1172
iter_num: 385, on_card_num: 55, preempted blk num: 1172
iter_num: 386, on_card_num: 55, preempted blk num: 1172
iter_num: 387, on_card_num: 55, preempted blk num: 1172
iter_num: 388, on_card_num: 55, preempted blk num: 1172
iter_num: 389, on_card_num: 55, preempted blk num: 1172
iter_num: 390, on_card_num: 55, preempted blk num: 1172
iter_num: 391, on_card_num: 55, preempted blk num: 1172
to recompute 1: ('154', 255)
iter_num: 392, on_card_num: 54, preempted blk num: 1204
iter_num: 393, on_card_num: 54, preempted blk num: 1204
iter_num: 394, on_card_num: 54, preempted blk num: 1204
iter_num: 395, on_card_num: 54, preempted blk num: 1204
to recompute 1: ('152', 450)
iter_num: 396, on_card_num: 53, preempted blk num: 1262
iter_num: 397, on_card_num: 53, preempted blk num: 1262
iter_num: 398, on_card_num: 53, preempted blk num: 1262
iter_num: 399, on_card_num: 53, preempted blk num: 1262
iter_num: 400, on_card_num: 53, preempted blk num: 1262
iter_num: 401, on_card_num: 53, preempted blk num: 1262
iter_num: 402, on_card_num: 53, preempted blk num: 1262
iter_num: 403, on_card_num: 53, preempted blk num: 1262
iter_num: 404, on_card_num: 53, preempted blk num: 1262
to recompute 1: ('149', 415)
iter_num: 405, on_card_num: 52, preempted blk num: 1314
iter_num: 406, on_card_num: 52, preempted blk num: 1314
iter_num: 407, on_card_num: 52, preempted blk num: 1314
iter_num: 408, on_card_num: 52, preempted blk num: 1314
iter_num: 409, on_card_num: 52, preempted blk num: 1314
iter_num: 410, on_card_num: 52, preempted blk num: 1314
iter_num: 411, on_card_num: 52, preempted blk num: 1314
iter_num: 412, on_card_num: 52, preempted blk num: 1314
to recompute 1: ('147', 279)
iter_num: 413, on_card_num: 51, preempted blk num: 1350
iter_num: 414, on_card_num: 51, preempted blk num: 1350
iter_num: 415, on_card_num: 50, preempted blk num: 1350
iter_num: 416, on_card_num: 51, preempted blk num: 1350
iter_num: 417, on_card_num: 51, preempted blk num: 1350
iter_num: 418, on_card_num: 51, preempted blk num: 1350
to recompute 1: ('147', 282)
iter_num: 419, on_card_num: 50, preempted blk num: 1386
iter_num: 420, on_card_num: 50, preempted blk num: 1386
iter_num: 421, on_card_num: 50, preempted blk num: 1386
iter_num: 422, on_card_num: 50, preempted blk num: 1386
iter_num: 423, on_card_num: 50, preempted blk num: 1386
iter_num: 424, on_card_num: 49, preempted blk num: 1386
iter_num: 425, on_card_num: 49, preempted blk num: 1386
iter_num: 426, on_card_num: 48, preempted blk num: 1386
iter_num: 427, on_card_num: 49, preempted blk num: 1386
iter_num: 428, on_card_num: 48, preempted blk num: 1386
iter_num: 429, on_card_num: 49, preempted blk num: 1386
iter_num: 430, on_card_num: 49, preempted blk num: 1386
iter_num: 431, on_card_num: 49, preempted blk num: 1386
iter_num: 432, on_card_num: 47, preempted blk num: 1386
iter_num: 433, on_card_num: 49, preempted blk num: 1386
iter_num: 434, on_card_num: 49, preempted blk num: 1386
iter_num: 435, on_card_num: 49, preempted blk num: 1386
iter_num: 436, on_card_num: 49, preempted blk num: 1386
to recompute 1: ('154', 259)
iter_num: 437, on_card_num: 48, preempted blk num: 1420
iter_num: 438, on_card_num: 48, preempted blk num: 1420
iter_num: 439, on_card_num: 48, preempted blk num: 1420
iter_num: 440, on_card_num: 48, preempted blk num: 1420
iter_num: 441, on_card_num: 48, preempted blk num: 1420
iter_num: 442, on_card_num: 48, preempted blk num: 1420
iter_num: 443, on_card_num: 48, preempted blk num: 1420
to recompute 1: ('152', 461)
iter_num: 444, on_card_num: 47, preempted blk num: 1478
iter_num: 445, on_card_num: 47, preempted blk num: 1478
iter_num: 446, on_card_num: 45, preempted blk num: 1478
iter_num: 447, on_card_num: 47, preempted blk num: 1478
iter_num: 448, on_card_num: 47, preempted blk num: 1478
iter_num: 449, on_card_num: 47, preempted blk num: 1478
iter_num: 450, on_card_num: 47, preempted blk num: 1478
iter_num: 451, on_card_num: 47, preempted blk num: 1478
iter_num: 452, on_card_num: 47, preempted blk num: 1478
iter_num: 453, on_card_num: 47, preempted blk num: 1478
iter_num: 454, on_card_num: 47, preempted blk num: 1478
iter_num: 455, on_card_num: 47, preempted blk num: 1478
iter_num: 456, on_card_num: 47, preempted blk num: 1478
iter_num: 457, on_card_num: 47, preempted blk num: 1478
to recompute 1: ('154', 270)
iter_num: 458, on_card_num: 46, preempted blk num: 1512
iter_num: 459, on_card_num: 46, preempted blk num: 1512
iter_num: 460, on_card_num: 46, preempted blk num: 1512
iter_num: 461, on_card_num: 46, preempted blk num: 1512
iter_num: 462, on_card_num: 46, preempted blk num: 1512
iter_num: 463, on_card_num: 46, preempted blk num: 1512
iter_num: 464, on_card_num: 45, preempted blk num: 1512
iter_num: 465, on_card_num: 45, preempted blk num: 1512
iter_num: 466, on_card_num: 45, preempted blk num: 1512
iter_num: 467, on_card_num: 44, preempted blk num: 1512
iter_num: 468, on_card_num: 45, preempted blk num: 1512
iter_num: 469, on_card_num: 45, preempted blk num: 1512
iter_num: 470, on_card_num: 45, preempted blk num: 1512
iter_num: 471, on_card_num: 45, preempted blk num: 1512
iter_num: 472, on_card_num: 45, preempted blk num: 1512
to recompute 1: ('154', 275)
iter_num: 473, on_card_num: 44, preempted blk num: 1548
iter_num: 474, on_card_num: 43, preempted blk num: 1548
iter_num: 475, on_card_num: 44, preempted blk num: 1548
iter_num: 476, on_card_num: 43, preempted blk num: 1548
iter_num: 477, on_card_num: 44, preempted blk num: 1548
iter_num: 478, on_card_num: 44, preempted blk num: 1548
iter_num: 479, on_card_num: 44, preempted blk num: 1548
iter_num: 480, on_card_num: 44, preempted blk num: 1548
iter_num: 481, on_card_num: 44, preempted blk num: 1548
iter_num: 482, on_card_num: 44, preempted blk num: 1548
iter_num: 483, on_card_num: 44, preempted blk num: 1548
iter_num: 484, on_card_num: 44, preempted blk num: 1548
iter_num: 485, on_card_num: 44, preempted blk num: 1548
iter_num: 486, on_card_num: 44, preempted blk num: 1548
iter_num: 487, on_card_num: 44, preempted blk num: 1548
iter_num: 488, on_card_num: 44, preempted blk num: 1548
to recompute 1: ('155', 535)
iter_num: 489, on_card_num: 43, preempted blk num: 1616
iter_num: 490, on_card_num: 43, preempted blk num: 1616
iter_num: 491, on_card_num: 43, preempted blk num: 1616
iter_num: 492, on_card_num: 43, preempted blk num: 1616
iter_num: 493, on_card_num: 43, preempted blk num: 1616
iter_num: 494, on_card_num: 43, preempted blk num: 1616
iter_num: 495, on_card_num: 43, preempted blk num: 1616
iter_num: 496, on_card_num: 43, preempted blk num: 1616
iter_num: 497, on_card_num: 43, preempted blk num: 1616
iter_num: 498, on_card_num: 42, preempted blk num: 1616
iter_num: 499, on_card_num: 42, preempted blk num: 1616
iter_num: 500, on_card_num: 41, preempted blk num: 1616
iter_num: 501, on_card_num: 42, preempted blk num: 1616
iter_num: 502, on_card_num: 41, preempted blk num: 1616
iter_num: 503, on_card_num: 41, preempted blk num: 1616
iter_num: 504, on_card_num: 41, preempted blk num: 1616
iter_num: 505, on_card_num: 41, preempted blk num: 1616
iter_num: 506, on_card_num: 41, preempted blk num: 1616
iter_num: 507, on_card_num: 41, preempted blk num: 1616
iter_num: 508, on_card_num: 40, preempted blk num: 1616
iter_num: 509, on_card_num: 40, preempted blk num: 1616
iter_num: 510, on_card_num: 40, preempted blk num: 1616
iter_num: 511, on_card_num: 40, preempted blk num: 1616
iter_num: 512, on_card_num: 40, preempted blk num: 1616
iter_num: 513, on_card_num: 40, preempted blk num: 1616
iter_num: 514, on_card_num: 40, preempted blk num: 1616
iter_num: 515, on_card_num: 40, preempted blk num: 1616
iter_num: 516, on_card_num: 40, preempted blk num: 1616
iter_num: 517, on_card_num: 40, preempted blk num: 1616
iter_num: 518, on_card_num: 40, preempted blk num: 1616
iter_num: 519, on_card_num: 40, preempted blk num: 1616
iter_num: 520, on_card_num: 40, preempted blk num: 1616
iter_num: 521, on_card_num: 40, preempted blk num: 1616
iter_num: 522, on_card_num: 40, preempted blk num: 1616
iter_num: 523, on_card_num: 40, preempted blk num: 1616
iter_num: 524, on_card_num: 40, preempted blk num: 1616
iter_num: 525, on_card_num: 40, preempted blk num: 1616
iter_num: 526, on_card_num: 40, preempted blk num: 1616
iter_num: 527, on_card_num: 40, preempted blk num: 1616
iter_num: 528, on_card_num: 40, preempted blk num: 1616
to recompute 1: ('155', 563)
iter_num: 529, on_card_num: 39, preempted blk num: 1688
iter_num: 530, on_card_num: 39, preempted blk num: 1688
iter_num: 531, on_card_num: 39, preempted blk num: 1688
iter_num: 532, on_card_num: 39, preempted blk num: 1688
iter_num: 533, on_card_num: 39, preempted blk num: 1688
iter_num: 534, on_card_num: 39, preempted blk num: 1688
iter_num: 535, on_card_num: 39, preempted blk num: 1688
iter_num: 536, on_card_num: 39, preempted blk num: 1688
iter_num: 537, on_card_num: 39, preempted blk num: 1688
iter_num: 538, on_card_num: 39, preempted blk num: 1688
iter_num: 539, on_card_num: 39, preempted blk num: 1688
iter_num: 540, on_card_num: 39, preempted blk num: 1688
iter_num: 541, on_card_num: 39, preempted blk num: 1688
to recompute 1: ('154', 340)
iter_num: 542, on_card_num: 38, preempted blk num: 1732
iter_num: 543, on_card_num: 38, preempted blk num: 1732
iter_num: 544, on_card_num: 38, preempted blk num: 1732
iter_num: 545, on_card_num: 38, preempted blk num: 1732
iter_num: 546, on_card_num: 38, preempted blk num: 1732
iter_num: 547, on_card_num: 37, preempted blk num: 1732
iter_num: 548, on_card_num: 38, preempted blk num: 1732
iter_num: 549, on_card_num: 38, preempted blk num: 1732
iter_num: 550, on_card_num: 37, preempted blk num: 1732
iter_num: 551, on_card_num: 37, preempted blk num: 1732
iter_num: 552, on_card_num: 37, preempted blk num: 1732
iter_num: 553, on_card_num: 37, preempted blk num: 1732
iter_num: 554, on_card_num: 37, preempted blk num: 1732
iter_num: 555, on_card_num: 36, preempted blk num: 1732
iter_num: 556, on_card_num: 37, preempted blk num: 1732
iter_num: 557, on_card_num: 37, preempted blk num: 1732
iter_num: 558, on_card_num: 37, preempted blk num: 1732
iter_num: 559, on_card_num: 37, preempted blk num: 1732
iter_num: 560, on_card_num: 37, preempted blk num: 1732
iter_num: 561, on_card_num: 37, preempted blk num: 1732
iter_num: 562, on_card_num: 37, preempted blk num: 1732
iter_num: 563, on_card_num: 37, preempted blk num: 1732
iter_num: 564, on_card_num: 37, preempted blk num: 1732
iter_num: 565, on_card_num: 36, preempted blk num: 1732
iter_num: 566, on_card_num: 36, preempted blk num: 1732
iter_num: 567, on_card_num: 36, preempted blk num: 1732
iter_num: 568, on_card_num: 36, preempted blk num: 1732
iter_num: 569, on_card_num: 36, preempted blk num: 1732
iter_num: 570, on_card_num: 36, preempted blk num: 1732
iter_num: 571, on_card_num: 35, preempted blk num: 1732
iter_num: 572, on_card_num: 35, preempted blk num: 1732
iter_num: 573, on_card_num: 34, preempted blk num: 1732
iter_num: 574, on_card_num: 34, preempted blk num: 1732
iter_num: 575, on_card_num: 33, preempted blk num: 1732
load 157: ('157', 1143)
seq_id: 157, layer_i: 2, token_i: 0, prompt
tensor([[[ 0.8657,  0.2473,  0.0215,  ...,  0.0615,  0.5996,  0.2017],
         [ 0.2847,  0.4971,  0.4968,  ..., -0.8213,  1.1934,  0.4580],
         [-0.7690, -0.0076,  0.6284,  ..., -1.8330,  1.1357,  0.3296],
         ...,
         [ 1.2373, -0.0115,  0.2681,  ..., -0.2959, -0.1388, -0.0187],
         [-0.4165,  0.3079, -0.2004,  ..., -0.8228,  0.3972, -0.1448],
         [-2.3809,  0.7129, -0.1034,  ..., -2.0508,  0.5972, -0.2350]],

        [[-0.5317, -1.5986, -2.6641,  ...,  1.1582,  0.4976, -2.5352],
         [-0.0845, -1.5654, -3.7734,  ...,  1.7285,  1.0967, -3.7891],
         [ 0.0366, -0.9395, -3.2656,  ...,  1.7227,  1.7969, -3.7578],
         ...,
         [-0.6470,  1.8809,  3.3223,  ...,  1.1016,  2.4355, -1.1406],
         [-0.1338,  1.2910,  2.1387,  ...,  0.2471,  1.3389, -0.3945],
         [-0.5220,  0.8325,  2.7109,  ...,  0.3945,  2.0117, -0.1768]],

        [[-2.6367,  1.2109, -1.1865,  ..., -2.0859,  0.3169,  1.8330],
         [-3.6172,  1.9902, -1.5879,  ..., -2.7422,  0.6250,  2.3086],
         [-3.7422,  2.2539, -1.9492,  ..., -2.7344,  0.7617,  2.1504],
         ...,
         [-1.4805,  2.7832, -2.8809,  ..., -2.8828,  1.4004,  1.6426],
         [-0.5957,  2.0234, -2.3359,  ..., -2.1211,  0.3232,  1.3877],
         [-0.6191,  2.7207, -1.9873,  ..., -2.2773,  0.4812,  2.3379]],

        ...,

        [[ 0.2976, -0.0488, -0.0321,  ..., -0.3433,  3.1074, -0.7559],
         [ 0.2485, -0.0894,  0.6431,  ..., -0.9443,  6.6289, -1.1758],
         [ 0.1503, -0.4172,  0.2463,  ...,  0.1334,  7.0742, -0.9961],
         ...,
         [ 0.0563, -0.3577,  0.1384,  ..., -1.0195,  5.7188, -0.6655],
         [ 1.4795, -0.9160,  1.3584,  ...,  0.4688,  2.9785, -1.9365],
         [-0.5034, -0.0146,  0.5845,  ...,  0.0415,  5.5977, -2.4688]],

        [[-0.7412, -0.0360, -0.1693,  ...,  0.4187, -1.7305,  0.5596],
         [-0.4697, -0.5972, -0.7930,  ...,  0.6172, -2.2285,  0.2505],
         [-0.1464, -0.2020, -0.4448,  ...,  0.8281, -3.2207, -0.6860],
         ...,
         [-0.8477, -0.0999, -0.6587,  ...,  0.0000, -2.9512, -0.0955],
         [-1.6348, -1.8701, -0.6567,  ..., -0.3940, -1.9668, -0.8081],
         [-1.1201, -1.5088, -0.4841,  ...,  0.3147, -2.0801, -0.8389]],

        [[-1.2852,  0.7866,  1.0811,  ..., -0.2559, -0.4106, -0.6421],
         [-1.4980,  0.4604,  1.6123,  ..., -0.4519, -0.3669, -1.2598],
         [-1.0918,  0.9429,  1.1465,  ..., -0.8931, -0.0181, -1.6289],
         ...,
         [-1.5293,  0.1365,  1.3594,  ..., -0.4670, -1.0498, -1.6445],
         [-1.7666,  0.2600,  0.6357,  ..., -0.9482, -0.4622, -2.0703],
         [-1.5586,  1.2266,  1.8975,  ..., -0.2109, -1.2012, -2.2070]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, prompt
tensor([[[ 1.8408e+00,  3.5889e-01, -1.9849e-01,  ..., -2.0801e-01,
           2.8613e-01,  4.9854e-01],
         [ 1.8848e+00,  4.5850e-01,  1.0901e-01,  ..., -2.8198e-01,
           4.1187e-01,  3.5010e-01],
         [ 1.2568e+00,  3.5962e-01, -9.1431e-02,  ...,  9.1943e-01,
           9.2920e-01,  1.2512e-01],
         ...,
         [ 1.5088e+00, -1.2061e-01, -3.6206e-01,  ..., -1.6133e+00,
          -1.0547e+00, -1.7810e-01],
         [ 4.2798e-01, -2.2668e-01,  1.4258e-01,  ..., -2.7002e-01,
          -5.0879e-01, -3.1525e-02],
         [ 7.5684e-02,  4.8828e-01,  4.1797e-01,  ...,  6.1523e-01,
          -1.6125e-01,  5.1367e-01]],

        [[-1.1553e+00,  1.7607e+00, -3.3086e+00,  ...,  2.5879e+00,
          -2.4023e-01,  2.5176e+00],
         [-6.2500e-01,  1.4170e+00, -3.6094e+00,  ...,  2.1426e+00,
          -5.2930e-01,  3.4883e+00],
         [-4.0234e-01,  1.3242e+00, -3.6914e+00,  ...,  2.0020e+00,
           1.7773e-01,  3.5020e+00],
         ...,
         [-3.9111e-01, -1.3037e+00,  3.6328e+00,  ..., -6.9434e-01,
           3.5273e+00, -4.8438e-01],
         [-1.8250e-01, -7.2559e-01,  1.3555e+00,  ..., -3.4888e-01,
           1.1768e+00, -2.3730e-01],
         [-6.0840e-01, -7.7734e-01,  3.2734e+00,  ..., -6.6943e-01,
           2.7480e+00, -1.2900e+00]],

        [[-1.4365e+00, -2.5645e+00, -1.8086e+00,  ..., -2.7324e+00,
           9.2676e-01, -2.3906e+00],
         [-1.7324e+00, -3.2441e+00, -2.7188e+00,  ..., -2.2383e+00,
           7.1973e-01, -1.8555e+00],
         [-1.7373e+00, -3.5098e+00, -3.1250e+00,  ..., -1.8232e+00,
           2.4756e-01, -1.9609e+00],
         ...,
         [ 2.1289e+00, -8.8574e-01, -1.7402e+00,  ..., -8.8232e-01,
           5.3857e-01, -6.4600e-01],
         [ 9.8975e-01, -1.5039e-01, -7.0947e-01,  ..., -2.6221e-01,
          -5.3613e-01, -9.5825e-02],
         [ 2.2422e+00, -1.0742e-02, -1.1250e+00,  ..., -1.1992e+00,
          -2.5806e-01, -8.4717e-01]],

        ...,

        [[-5.1025e-01, -4.8401e-02, -6.8018e-01,  ..., -7.6904e-01,
           6.5664e+00, -1.4521e+00],
         [ 1.4026e-01, -3.8672e-01, -7.4585e-02,  ..., -8.7598e-01,
           6.8711e+00, -6.2988e-01],
         [-4.2261e-01, -3.7158e-01,  5.2783e-01,  ..., -8.5791e-01,
           7.8789e+00, -3.6499e-01],
         ...,
         [-1.9067e-01, -6.7871e-01, -6.4014e-01,  ..., -4.9390e-01,
           7.1914e+00, -6.9287e-01],
         [ 1.5515e-01, -2.1729e-01, -9.1187e-02,  ..., -1.4673e-01,
           8.0518e-01, -4.9658e-01],
         [ 5.6152e-02,  2.5049e-01, -3.6548e-01,  ..., -5.7520e-01,
           5.8242e+00, -1.0684e+00]],

        [[-5.3125e-01, -1.2607e+00, -4.0015e-01,  ..., -1.4514e-01,
          -3.0547e+00,  9.6094e-01],
         [-6.6406e-01, -6.5381e-01, -7.0215e-01,  ...,  4.0356e-01,
          -2.1973e+00,  5.8203e-01],
         [-5.8301e-01, -1.3594e+00, -1.2197e+00,  ...,  8.7451e-01,
          -2.1699e+00, -1.5564e-02],
         ...,
         [-4.3164e-01, -8.5596e-01, -4.4995e-01,  ...,  3.6841e-01,
          -3.6309e+00, -3.6035e-01],
         [-2.0679e-01, -1.6602e-01, -2.4487e-01,  ..., -1.2970e-03,
          -1.3203e+00,  5.6250e-01],
         [-2.2441e+00, -8.2373e-01, -7.4756e-01,  ..., -4.9585e-01,
          -2.2910e+00, -4.0894e-01]],

        [[-1.0791e+00,  1.7090e+00,  3.4199e+00,  ..., -1.4590e+00,
          -8.9600e-01, -1.8643e+00],
         [-9.7656e-01,  6.8018e-01,  1.5654e+00,  ..., -5.1514e-01,
          -6.2891e-01, -1.1846e+00],
         [-9.9609e-01, -2.1948e-01,  1.6592e+00,  ..., -4.2432e-01,
          -1.4736e+00, -7.7344e-01],
         ...,
         [-1.0732e+00,  1.0713e+00,  1.4014e+00,  ..., -2.5195e-01,
          -1.0950e-01, -1.1758e+00],
         [-6.6650e-01,  3.6084e-01, -4.1199e-02,  ..., -1.9421e-01,
           3.5986e-01, -1.2292e-01],
         [-1.2683e-01,  2.7881e-01,  1.5391e+00,  ..., -5.8740e-01,
          -1.5254e+00, -1.9258e+00]]], device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, prompt
tensor([[[-4.4702e-01, -3.3398e-01, -6.0693e-01,  ...,  1.9023e+00,
           1.1504e+00, -2.7905e-01],
         [ 1.0430e+00,  2.1558e-01,  1.0602e-01,  ...,  1.5439e+00,
           5.6055e-01,  4.5386e-01],
         [ 1.4268e+00,  1.6638e-01, -1.2109e-01,  ...,  1.4346e+00,
           4.9365e-01,  2.5024e-02],
         ...,
         [-9.4238e-02, -2.1265e-01,  5.8496e-01,  ...,  1.9453e+00,
           7.3730e-01, -4.2236e-01],
         [ 1.8623e+00, -1.7798e-01,  3.1934e-01,  ...,  1.0332e+00,
           4.4019e-01,  6.3867e-01],
         [ 1.4883e+00, -4.9170e-01, -3.4821e-02,  ...,  9.7168e-01,
           8.2422e-01, -1.2646e-01]],

        [[ 7.8516e-01, -1.2285e+00, -1.1094e+00,  ...,  1.9111e+00,
           8.8379e-01, -1.3457e+00],
         [ 8.8257e-02, -1.1533e+00, -1.9238e+00,  ...,  1.0596e+00,
           1.7656e+00, -1.6611e+00],
         [ 5.8984e-01, -5.8545e-01, -2.3047e+00,  ...,  1.7109e+00,
           1.5391e+00, -1.8564e+00],
         ...,
         [-6.5918e-03,  4.9414e-01,  1.3184e+00,  ..., -1.1055e+00,
           2.3496e+00, -3.0762e+00],
         [ 5.0439e-01,  3.6865e-01,  2.1641e+00,  ..., -1.5605e+00,
           1.2705e+00, -1.9580e+00],
         [ 4.1382e-01, -3.0127e-01,  2.3047e+00,  ..., -1.7100e+00,
           1.8047e+00, -2.3691e+00]],

        [[ 8.4180e-01, -3.2812e+00,  2.1133e+00,  ...,  8.0322e-01,
           1.5107e+00, -3.4985e-01],
         [-2.0508e-02, -2.4707e+00,  2.2910e+00,  ...,  1.0947e+00,
          -4.1797e-01,  6.1377e-01],
         [-1.1035e-01, -2.7891e+00,  2.2148e+00,  ...,  9.2578e-01,
           1.5703e+00,  5.9570e-02],
         ...,
         [-2.8945e+00, -1.3594e+00,  2.5352e+00,  ...,  2.6484e+00,
           8.4131e-01, -9.8193e-01],
         [-2.6270e+00, -2.9004e-01,  2.0469e+00,  ...,  1.6348e+00,
           3.0957e-01, -6.8848e-01],
         [-2.9531e+00, -7.0557e-01,  2.0801e+00,  ...,  2.2109e+00,
           4.5117e-01, -9.1406e-01]],

        ...,

        [[-3.0542e-01, -1.1738e+00, -7.0312e-02,  ..., -8.8965e-01,
           6.3711e+00, -1.0986e+00],
         [-1.7959e+00,  8.8184e-01,  2.9712e-01,  ..., -3.2642e-01,
           4.5586e+00, -1.2598e+00],
         [ 5.1855e-01, -6.1157e-02,  3.8867e-01,  ..., -8.1201e-01,
           4.3320e+00, -1.2480e+00],
         ...,
         [-2.6904e-01, -1.0977e+00, -2.3071e-02,  ..., -7.1484e-01,
           6.3438e+00, -1.1680e+00],
         [-1.3806e-01, -1.0260e-01, -1.6162e-01,  ..., -3.5303e-01,
           5.0547e+00, -2.0527e+00],
         [ 5.7520e-01,  4.0527e-02,  5.7568e-01,  ..., -6.9580e-01,
           4.1445e+00, -1.1758e+00]],

        [[-7.9883e-01, -3.0420e-01, -4.8291e-01,  ...,  3.6719e-01,
          -2.0293e+00,  2.8076e-02],
         [-6.8701e-01, -7.9346e-01,  2.7148e-01,  ...,  6.9580e-01,
          -1.3926e+00, -5.7471e-01],
         [-8.8623e-01, -5.3406e-03,  3.1616e-02,  ...,  2.2339e-01,
          -2.0352e+00,  1.5991e-01],
         ...,
         [-8.2031e-01, -4.1406e-01, -5.2783e-01,  ...,  1.5308e-01,
          -2.1543e+00, -1.4526e-02],
         [-5.9082e-01,  9.5032e-02, -1.2476e-01,  ...,  1.9165e-01,
          -2.8174e-01, -9.7754e-01],
         [-7.9004e-01, -6.9122e-03,  5.6885e-02,  ...,  2.3950e-01,
          -2.1074e+00,  2.1436e-01]],

        [[-1.4492e+00,  3.3130e-01,  1.1895e+00,  ..., -1.1260e+00,
          -3.8770e-01, -1.7021e+00],
         [-1.5557e+00,  3.2812e-01,  8.6475e-01,  ..., -7.2021e-01,
          -3.4277e-01, -1.1885e+00],
         [-1.3672e+00,  5.2832e-01,  7.4463e-01,  ..., -3.8696e-01,
           2.6489e-01, -8.3594e-01],
         ...,
         [-1.3740e+00,  1.8884e-01,  1.2178e+00,  ..., -1.1406e+00,
          -4.9634e-01, -1.9473e+00],
         [-2.2207e+00,  5.2368e-02,  1.1172e+00,  ..., -1.8140e-01,
          -1.5430e-01, -1.9424e+00],
         [-1.5127e+00,  5.0879e-01,  8.1641e-01,  ..., -3.8062e-01,
           2.6270e-01, -8.3496e-01]]], device='cuda:0', dtype=torch.float16)
iter_num: 576, on_card_num: 34, preempted blk num: 1732
iter_num: 577, on_card_num: 35, preempted blk num: 1732
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 578, on_card_num: 35, preempted blk num: 1732
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 579, on_card_num: 35, preempted blk num: 1732
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 580, on_card_num: 35, preempted blk num: 1732
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 581, on_card_num: 35, preempted blk num: 1732
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 582, on_card_num: 35, preempted blk num: 1732
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 583, on_card_num: 34, preempted blk num: 1732
iter_num: 584, on_card_num: 36, preempted blk num: 1732
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 585, on_card_num: 36, preempted blk num: 1732
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 586, on_card_num: 36, preempted blk num: 1732
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 587, on_card_num: 35, preempted blk num: 1732
iter_num: 588, on_card_num: 36, preempted blk num: 1732
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 589, on_card_num: 35, preempted blk num: 1732
iter_num: 590, on_card_num: 37, preempted blk num: 1732
iter_num: 591, on_card_num: 39, preempted blk num: 1732
iter_num: 592, on_card_num: 42, preempted blk num: 1732
iter_num: 593, on_card_num: 49, preempted blk num: 1732
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 594, on_card_num: 49, preempted blk num: 1732
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 595, on_card_num: 49, preempted blk num: 1732
to recompute 1: ('181', 20)
to recompute 1: ('180', 20)
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 596, on_card_num: 47, preempted blk num: 1740
to recompute 1: ('179', 14)
to recompute 1: ('178', 18)
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 597, on_card_num: 44, preempted blk num: 1746
iter_num: 598, on_card_num: 49, preempted blk num: 1746
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 599, on_card_num: 49, preempted blk num: 1746
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 600, on_card_num: 49, preempted blk num: 1746
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 601, on_card_num: 48, preempted blk num: 1746
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 602, on_card_num: 47, preempted blk num: 1746
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 603, on_card_num: 47, preempted blk num: 1746
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 604, on_card_num: 47, preempted blk num: 1746
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 605, on_card_num: 47, preempted blk num: 1746
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 606, on_card_num: 47, preempted blk num: 1746
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 607, on_card_num: 47, preempted blk num: 1746
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 608, on_card_num: 47, preempted blk num: 1746
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 609, on_card_num: 47, preempted blk num: 1746
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 610, on_card_num: 46, preempted blk num: 1746
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 611, on_card_num: 45, preempted blk num: 1746
iter_num: 612, on_card_num: 46, preempted blk num: 1746
iter_num: 613, on_card_num: 48, preempted blk num: 1746
iter_num: 614, on_card_num: 50, preempted blk num: 1746
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 615, on_card_num: 50, preempted blk num: 1746
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 616, on_card_num: 50, preempted blk num: 1746
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 617, on_card_num: 50, preempted blk num: 1746
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 618, on_card_num: 50, preempted blk num: 1746
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 619, on_card_num: 50, preempted blk num: 1746
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 620, on_card_num: 48, preempted blk num: 1746
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 621, on_card_num: 48, preempted blk num: 1746
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 622, on_card_num: 48, preempted blk num: 1746
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 623, on_card_num: 48, preempted blk num: 1746
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 624, on_card_num: 48, preempted blk num: 1746
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 625, on_card_num: 48, preempted blk num: 1746
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 626, on_card_num: 48, preempted blk num: 1746
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 627, on_card_num: 48, preempted blk num: 1746
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 628, on_card_num: 48, preempted blk num: 1746
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 629, on_card_num: 48, preempted blk num: 1746
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 630, on_card_num: 48, preempted blk num: 1746
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 631, on_card_num: 48, preempted blk num: 1746
to recompute 1: ('187', 23)
to recompute 1: ('186', 229)
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 632, on_card_num: 46, preempted blk num: 1780
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 633, on_card_num: 46, preempted blk num: 1780
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 634, on_card_num: 46, preempted blk num: 1780
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 635, on_card_num: 45, preempted blk num: 1780
iter_num: 636, on_card_num: 47, preempted blk num: 1780
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 637, on_card_num: 47, preempted blk num: 1780
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 638, on_card_num: 47, preempted blk num: 1780
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 639, on_card_num: 47, preempted blk num: 1780
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 640, on_card_num: 47, preempted blk num: 1780
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 641, on_card_num: 47, preempted blk num: 1780
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 642, on_card_num: 47, preempted blk num: 1780
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 643, on_card_num: 47, preempted blk num: 1780
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 644, on_card_num: 47, preempted blk num: 1780
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 645, on_card_num: 46, preempted blk num: 1780
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 646, on_card_num: 46, preempted blk num: 1780
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 647, on_card_num: 44, preempted blk num: 1780
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 648, on_card_num: 44, preempted blk num: 1780
to recompute 1: ('186', 242)
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 649, on_card_num: 43, preempted blk num: 1812
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 650, on_card_num: 43, preempted blk num: 1812
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 651, on_card_num: 43, preempted blk num: 1812
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 652, on_card_num: 42, preempted blk num: 1812
iter_num: 653, on_card_num: 43, preempted blk num: 1812
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 654, on_card_num: 42, preempted blk num: 1812
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 655, on_card_num: 42, preempted blk num: 1812
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 656, on_card_num: 42, preempted blk num: 1812
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 657, on_card_num: 41, preempted blk num: 1812
iter_num: 658, on_card_num: 42, preempted blk num: 1812
iter_num: 659, on_card_num: 43, preempted blk num: 1812
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 660, on_card_num: 43, preempted blk num: 1812
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 661, on_card_num: 43, preempted blk num: 1812
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 662, on_card_num: 43, preempted blk num: 1812
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 663, on_card_num: 43, preempted blk num: 1812
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 664, on_card_num: 43, preempted blk num: 1812
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 665, on_card_num: 43, preempted blk num: 1812
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 666, on_card_num: 43, preempted blk num: 1812
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 667, on_card_num: 43, preempted blk num: 1812
to recompute 1: ('189', 17)
to recompute 1: ('188', 610)
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 668, on_card_num: 40, preempted blk num: 1892
iter_num: 669, on_card_num: 41, preempted blk num: 1892
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 670, on_card_num: 41, preempted blk num: 1892
seq_id: 157, layer_i: 2, token_i: 0, generate
tensor([[[-0.1669, -0.9507,  1.9863,  ...,  0.4375,  0.7734, -0.0466],
         [-1.1328,  0.3530,  0.2759,  ...,  0.1494,  0.9780, -0.2781],
         [-0.3428,  0.7803, -0.9746,  ..., -0.9395,  1.0859, -0.0833],
         ...,
         [-2.1094, -0.5474, -0.5771,  ..., -0.1467,  0.4534, -0.4089],
         [-1.4668, -0.8447, -0.1108,  ..., -0.6104,  0.7988, -0.2109],
         [ 0.0420, -0.3237,  0.6699,  ..., -1.4600,  1.4727, -0.3816]],

        [[-0.3850,  0.7886, -0.4646,  ...,  1.0430,  0.0972,  1.0986],
         [-0.9297,  1.4541, -1.2773,  ...,  1.3838, -0.1018,  1.7471],
         [-0.6724,  1.1123, -2.2188,  ...,  1.1338, -0.9468,  1.9004],
         ...,
         [ 0.4919, -1.1611,  2.2734,  ..., -1.0508, -2.1699, -1.1924],
         [ 0.5830, -0.5605,  2.3047,  ..., -1.3711, -2.0234, -1.2871],
         [ 0.1946, -0.2275,  2.7773,  ..., -1.3516, -1.8389, -1.7100]],

        [[ 1.0068, -0.1942, -1.0938,  ..., -0.5791,  1.1074, -0.1779],
         [ 1.6631, -0.6729, -1.7188,  ..., -0.9722,  1.2598,  0.1273],
         [ 1.6152, -1.3662, -1.5566,  ..., -1.5078,  0.9883, -0.8901],
         ...,
         [-0.9058, -2.6035, -0.0156,  ..., -2.6680,  0.5195, -0.7490],
         [-0.9224, -2.4531, -0.3950,  ..., -2.0684,  0.6748,  0.2246],
         [-1.2656, -2.8008,  0.0806,  ..., -2.8867,  0.5498, -0.4626]],

        ...,

        [[-0.1335, -0.0348, -1.2891,  ..., -0.3796,  0.6240, -0.6846],
         [ 0.3384, -0.5820, -0.7378,  ..., -1.2832,  3.7148, -0.1785],
         [ 0.1633, -0.0854, -0.7007,  ..., -0.7378,  3.8945, -0.4949],
         ...,
         [ 0.0749, -0.0523, -0.7549,  ..., -1.0332,  5.4961, -0.6675],
         [ 0.3240, -0.1797, -0.0240,  ..., -0.9941,  5.1562, -0.3940],
         [ 0.4763,  0.0945, -0.2749,  ..., -0.5981,  4.6914, -0.6880]],

        [[-0.3997,  0.2396, -0.1693,  ...,  0.4900, -0.4702,  0.0252],
         [-0.7319, -0.0696, -0.5942,  ...,  0.3821, -1.8467,  0.1542],
         [-0.6260, -0.6309, -0.2905,  ...,  0.3015, -1.7881,  0.3875],
         ...,
         [-0.7734, -0.7598, -0.4224,  ...,  0.3359, -2.1367,  0.4558],
         [-0.5767, -0.5044, -0.2834,  ...,  0.8628, -1.7334,  0.3528],
         [-0.2328, -1.0723, -0.8423,  ...,  0.9111, -2.2344,  0.3569]],

        [[-1.1104, -0.0304,  0.0473,  ..., -0.0857,  0.4355, -0.4885],
         [-1.6035, -0.5103,  0.7578,  ..., -0.5513, -0.1561, -1.1182],
         [-1.5723,  0.2028,  0.5737,  ...,  0.0505,  0.2581, -0.5337],
         ...,
         [-1.4229,  0.0759,  0.8442,  ..., -0.2253, -0.1469, -0.6816],
         [-1.2900,  0.3645,  0.4600,  ..., -0.2382, -0.1343, -0.6133],
         [-1.4346, -0.4060,  0.6768,  ..., -0.1456, -0.4700, -0.4333]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 200, generate
tensor([[[ 1.7832, -0.0729,  0.3818,  ...,  1.6562,  1.0225,  0.0999],
         [ 1.9453, -0.0801,  0.2979,  ..., -0.0454,  0.8037,  0.0565],
         [-0.4268, -0.3286,  0.6943,  ..., -0.9194,  1.4502,  0.5112],
         ...,
         [ 2.0215,  0.7632, -0.9224,  ...,  2.3145, -0.2505, -0.8286],
         [ 0.3501, -0.2386, -0.7578,  ...,  1.6367,  0.3860, -0.5459],
         [-0.4905, -0.3589, -0.1056,  ...,  0.0635,  0.8682, -0.4414]],

        [[-0.0208, -1.9199, -1.7695,  ...,  0.3586, -2.6660, -2.6719],
         [-0.6641, -1.8809, -0.2559,  ...,  0.6597, -2.6680, -1.4824],
         [-0.7744, -1.8818,  0.0957,  ...,  0.5391, -2.9883, -1.4043],
         ...,
         [ 0.2474,  2.1562,  2.6016,  ...,  2.5371, -1.9854,  2.2129],
         [ 0.7607,  1.7930,  2.3086,  ...,  2.0742, -2.0195,  2.3457],
         [ 1.0176,  1.4033,  1.2441,  ...,  1.6553, -1.3789,  2.7598]],

        [[ 1.8145,  3.3242,  1.5898,  ...,  1.6025, -0.9688,  0.6636],
         [ 1.0742,  2.8223,  1.8867,  ...,  1.5088, -0.0693, -0.8438],
         [ 1.2031,  3.1426,  2.0586,  ...,  1.0117, -0.3232, -0.2749],
         ...,
         [-1.8887,  1.9961,  2.4531,  ...,  2.2266, -0.1483,  0.7588],
         [-2.2227,  2.2773,  2.8496,  ...,  2.5938, -1.6621,  1.3340],
         [-2.3574,  1.7773,  3.1504,  ...,  2.4629, -1.1621,  1.2393]],

        ...,

        [[-0.1953, -0.6079, -0.8174,  ..., -0.5234,  7.4102, -0.6040],
         [ 1.5615, -0.4302,  0.2250,  ..., -0.7661,  5.8359, -0.5786],
         [ 0.5146,  0.4597, -0.8555,  ..., -0.6440,  7.3164, -1.0508],
         ...,
         [-0.2905, -0.2457, -0.2297,  ..., -0.8774,  7.6562, -0.7441],
         [-0.3149, -0.1313, -0.2205,  ..., -0.0821,  7.2539, -0.0269],
         [-0.0678, -0.3965,  0.4199,  ..., -0.7324,  6.7461, -0.1963]],

        [[-0.4683, -0.9946, -0.7139,  ...,  0.2808, -3.6777, -0.2323],
         [-0.5410, -1.3271, -0.4807,  ..., -0.1208, -2.4414, -0.1287],
         [-0.6343, -1.9473, -0.3608,  ..., -0.1587, -2.8535,  0.0415],
         ...,
         [-0.8677, -1.4570, -0.7305,  ..., -0.7861, -2.1836, -0.1477],
         [-0.3354, -0.6455, -0.3403,  ...,  0.2084, -3.3516, -0.0213],
         [ 0.2827, -0.5381, -0.0674,  ...,  0.2717, -2.4785,  0.1084]],

        [[-0.9678,  1.1445,  1.5557,  ..., -0.2432, -0.3677, -1.1299],
         [-0.3481, -1.2939,  1.4189,  ..., -0.1599,  0.1753, -2.9648],
         [-0.5776,  0.1422,  2.4688,  ...,  0.2319, -1.1904, -1.6973],
         ...,
         [-1.2676,  0.4426,  2.3320,  ..., -0.5220, -0.7568, -1.3389],
         [-0.4492,  1.3916,  1.4746,  ..., -1.1729, -0.4216, -1.4141],
         [-1.0098,  0.8267,  1.5352,  ..., -0.5103, -0.5508, -1.3857]]],
       device='cuda:0', dtype=torch.float16)
seq_id: 157, layer_i: 2, token_i: 1019, generate
tensor([[[ 0.5771,  0.1188,  0.0214,  ..., -1.6621, -0.6963, -0.2343],
         [ 2.0078,  0.5801, -0.2637,  ..., -2.5000, -0.4399, -0.4277],
         [ 1.7852,  0.5225, -0.5068,  ..., -2.5996,  0.8145, -0.1153],
         ...,
         [ 0.8667, -0.6387, -0.1821,  ..., -1.3398, -0.9961,  0.3569],
         [ 1.0283, -0.4846,  0.3323,  ..., -1.7822, -0.7188,  0.1543],
         [ 0.3232,  0.2072,  0.0818,  ..., -1.4043, -0.2939,  0.0707]],

        [[-0.2585,  1.8027, -3.2910,  ...,  0.2290, -0.9409, -2.5078],
         [-0.8115,  1.9238, -3.9102,  ...,  0.1445, -0.3174, -2.3438],
         [-1.0371,  1.3887, -3.4141,  ...,  0.5142,  0.3037, -1.7754],
         ...,
         [ 0.6733, -1.4072,  2.6934,  ...,  1.6299,  2.4766,  1.5723],
         [ 0.5078, -1.0527,  2.9004,  ...,  1.5537,  2.6797,  1.8691],
         [ 0.1343, -1.0449,  2.5254,  ...,  0.9424,  2.2109,  1.8027]],

        [[ 2.0645,  0.5596, -2.1875,  ...,  1.0938,  1.1055, -1.6133],
         [ 2.0742,  0.1523, -2.5039,  ...,  1.5420,  0.4788, -1.6875],
         [ 1.5186, -0.1699, -1.4053,  ...,  1.3555,  0.3674, -1.7480],
         ...,
         [-1.2783, -2.0410, -0.2778,  ...,  0.0117,  2.0137, -0.9023],
         [-1.4980, -2.2715, -0.2666,  ..., -0.0381,  2.1582, -0.7676],
         [-1.9844, -2.2676,  0.3906,  ..., -0.6714,  0.8613, -1.1484]],

        ...,

        [[ 0.2642,  0.1321, -0.5850,  ...,  0.2269,  1.6719, -2.4238],
         [ 0.2064,  0.4221, -0.4890,  ...,  0.1116,  2.6836, -1.2305],
         [-0.6533, -0.0369,  0.4380,  ...,  0.2208,  2.2969, -0.2407],
         ...,
         [-0.0063,  0.1274,  1.0898,  ...,  0.7935,  1.3770, -1.3525],
         [-0.0085,  0.5205,  1.4336,  ...,  0.7969,  1.7490, -1.7949],
         [-0.4912,  0.5439,  0.3633,  ...,  1.4326,  0.9863, -2.4785]],

        [[-0.1904, -0.1404, -0.1841,  ..., -0.1211, -2.3379, -0.1982],
         [-0.2163, -0.0923,  0.3140,  ..., -0.6143, -2.5820, -0.2773],
         [-0.5635,  0.2036,  0.2900,  ..., -1.0791, -2.7812, -0.0862],
         ...,
         [-0.3137, -0.0391,  0.2900,  ..., -0.1797, -1.8350,  0.0391],
         [-0.3628, -0.2234,  0.1912,  ..., -0.1831, -1.9082, -0.2205],
         [-0.4683, -0.9668,  0.0659,  ..., -0.5107, -1.7334, -1.0459]],

        [[-1.2061,  1.2227,  0.7681,  ..., -0.6865,  0.0417, -1.1729],
         [-1.1133,  0.7793,  1.6416,  ..., -0.2932, -0.1729, -1.4707],
         [-0.5928,  1.1572,  2.1328,  ..., -0.3325, -1.3066, -1.5732],
         ...,
         [-2.0977,  0.8193,  0.8140,  ..., -0.0773, -0.0718, -0.3159],
         [-2.3008,  0.8994,  0.9629,  ..., -0.3066, -0.1311, -0.4475],
         [-1.4385, -0.2600,  0.3059,  ..., -1.0801, -0.3311, -1.7764]]],
       device='cuda:0', dtype=torch.float16)
iter_num: 671, on_card_num: 40, preempted blk num: 1892
iter_num: 672, on_card_num: 41, preempted blk num: 1892
iter_num: 673, on_card_num: 43, preempted blk num: 1892
iter_num: 674, on_card_num: 45, preempted blk num: 1892
iter_num: 675, on_card_num: 45, preempted blk num: 1892
iter_num: 676, on_card_num: 44, preempted blk num: 1892
iter_num: 677, on_card_num: 45, preempted blk num: 1892
iter_num: 678, on_card_num: 44, preempted blk num: 1892
iter_num: 679, on_card_num: 44, preempted blk num: 1892
iter_num: 680, on_card_num: 44, preempted blk num: 1892
iter_num: 681, on_card_num: 44, preempted blk num: 1892
iter_num: 682, on_card_num: 44, preempted blk num: 1892
iter_num: 683, on_card_num: 44, preempted blk num: 1892
iter_num: 684, on_card_num: 44, preempted blk num: 1892
iter_num: 685, on_card_num: 44, preempted blk num: 1892
iter_num: 686, on_card_num: 44, preempted blk num: 1892
iter_num: 687, on_card_num: 44, preempted blk num: 1892
iter_num: 688, on_card_num: 44, preempted blk num: 1892
to recompute 1: ('194', 779)
iter_num: 689, on_card_num: 42, preempted blk num: 1990
iter_num: 690, on_card_num: 42, preempted blk num: 1990
iter_num: 691, on_card_num: 41, preempted blk num: 1990
iter_num: 692, on_card_num: 42, preempted blk num: 1990
iter_num: 693, on_card_num: 42, preempted blk num: 1990
iter_num: 694, on_card_num: 42, preempted blk num: 1990
iter_num: 695, on_card_num: 42, preempted blk num: 1990
iter_num: 696, on_card_num: 41, preempted blk num: 1990
iter_num: 697, on_card_num: 41, preempted blk num: 1990
iter_num: 698, on_card_num: 41, preempted blk num: 1990
iter_num: 699, on_card_num: 41, preempted blk num: 1990
iter_num: 700, on_card_num: 41, preempted blk num: 1990
iter_num: 701, on_card_num: 41, preempted blk num: 1990
iter_num: 702, on_card_num: 41, preempted blk num: 1990
iter_num: 703, on_card_num: 41, preempted blk num: 1990
iter_num: 704, on_card_num: 41, preempted blk num: 1990
iter_num: 705, on_card_num: 41, preempted blk num: 1990
to recompute 1: ('194', 793)
iter_num: 706, on_card_num: 40, preempted blk num: 2090
iter_num: 707, on_card_num: 39, preempted blk num: 2090
iter_num: 708, on_card_num: 40, preempted blk num: 2090
iter_num: 709, on_card_num: 39, preempted blk num: 2090
iter_num: 710, on_card_num: 39, preempted blk num: 2090
iter_num: 711, on_card_num: 39, preempted blk num: 2090
iter_num: 712, on_card_num: 39, preempted blk num: 2090
iter_num: 713, on_card_num: 39, preempted blk num: 2090
iter_num: 714, on_card_num: 38, preempted blk num: 2090
iter_num: 715, on_card_num: 39, preempted blk num: 2090
iter_num: 716, on_card_num: 41, preempted blk num: 2090
iter_num: 717, on_card_num: 41, preempted blk num: 2090
iter_num: 718, on_card_num: 41, preempted blk num: 2090
iter_num: 719, on_card_num: 41, preempted blk num: 2090
iter_num: 720, on_card_num: 41, preempted blk num: 2090
iter_num: 721, on_card_num: 41, preempted blk num: 2090
iter_num: 722, on_card_num: 41, preempted blk num: 2090
iter_num: 723, on_card_num: 41, preempted blk num: 2090
iter_num: 724, on_card_num: 40, preempted blk num: 2090
iter_num: 725, on_card_num: 41, preempted blk num: 2090
iter_num: 726, on_card_num: 43, preempted blk num: 2090
iter_num: 727, on_card_num: 43, preempted blk num: 2090
iter_num: 728, on_card_num: 43, preempted blk num: 2090
to recompute 1: ('200', 178)
iter_num: 729, on_card_num: 42, preempted blk num: 2114
iter_num: 730, on_card_num: 42, preempted blk num: 2114
iter_num: 731, on_card_num: 41, preempted blk num: 2114
iter_num: 732, on_card_num: 43, preempted blk num: 2114
iter_num: 733, on_card_num: 43, preempted blk num: 2114
iter_num: 734, on_card_num: 43, preempted blk num: 2114
iter_num: 735, on_card_num: 43, preempted blk num: 2114
iter_num: 736, on_card_num: 42, preempted blk num: 2114
iter_num: 737, on_card_num: 42, preempted blk num: 2114
iter_num: 738, on_card_num: 41, preempted blk num: 2114
iter_num: 739, on_card_num: 41, preempted blk num: 2114
iter_num: 740, on_card_num: 41, preempted blk num: 2114
iter_num: 741, on_card_num: 41, preempted blk num: 2114
iter_num: 742, on_card_num: 41, preempted blk num: 2114
iter_num: 743, on_card_num: 41, preempted blk num: 2114
iter_num: 744, on_card_num: 41, preempted blk num: 2114
iter_num: 745, on_card_num: 41, preempted blk num: 2114
iter_num: 746, on_card_num: 41, preempted blk num: 2114
iter_num: 747, on_card_num: 40, preempted blk num: 2114
iter_num: 748, on_card_num: 40, preempted blk num: 2114
iter_num: 749, on_card_num: 40, preempted blk num: 2114
iter_num: 750, on_card_num: 40, preempted blk num: 2114
iter_num: 751, on_card_num: 40, preempted blk num: 2114
iter_num: 752, on_card_num: 40, preempted blk num: 2114
iter_num: 753, on_card_num: 40, preempted blk num: 2114
iter_num: 754, on_card_num: 40, preempted blk num: 2114
iter_num: 755, on_card_num: 40, preempted blk num: 2114
iter_num: 756, on_card_num: 39, preempted blk num: 2114
iter_num: 757, on_card_num: 39, preempted blk num: 2114
iter_num: 758, on_card_num: 39, preempted blk num: 2114
iter_num: 759, on_card_num: 39, preempted blk num: 2114
iter_num: 760, on_card_num: 39, preempted blk num: 2114
iter_num: 761, on_card_num: 39, preempted blk num: 2114
iter_num: 762, on_card_num: 39, preempted blk num: 2114
iter_num: 763, on_card_num: 38, preempted blk num: 2114
iter_num: 764, on_card_num: 38, preempted blk num: 2114
iter_num: 765, on_card_num: 38, preempted blk num: 2114
iter_num: 766, on_card_num: 38, preempted blk num: 2114
iter_num: 767, on_card_num: 38, preempted blk num: 2114
iter_num: 768, on_card_num: 38, preempted blk num: 2114
iter_num: 769, on_card_num: 38, preempted blk num: 2114
iter_num: 770, on_card_num: 37, preempted blk num: 2114
iter_num: 771, on_card_num: 38, preempted blk num: 2114
iter_num: 772, on_card_num: 41, preempted blk num: 2114
iter_num: 773, on_card_num: 44, preempted blk num: 2114
iter_num: 774, on_card_num: 43, preempted blk num: 2114
iter_num: 775, on_card_num: 43, preempted blk num: 2114
iter_num: 776, on_card_num: 43, preempted blk num: 2114
iter_num: 777, on_card_num: 43, preempted blk num: 2114
iter_num: 778, on_card_num: 43, preempted blk num: 2114
iter_num: 779, on_card_num: 43, preempted blk num: 2114
iter_num: 780, on_card_num: 43, preempted blk num: 2114
iter_num: 781, on_card_num: 43, preempted blk num: 2114
iter_num: 782, on_card_num: 43, preempted blk num: 2114
iter_num: 783, on_card_num: 43, preempted blk num: 2114
iter_num: 784, on_card_num: 43, preempted blk num: 2114
iter_num: 785, on_card_num: 43, preempted blk num: 2114
iter_num: 786, on_card_num: 43, preempted blk num: 2114
iter_num: 787, on_card_num: 42, preempted blk num: 2114
iter_num: 788, on_card_num: 42, preempted blk num: 2114
iter_num: 789, on_card_num: 42, preempted blk num: 2114
iter_num: 790, on_card_num: 42, preempted blk num: 2114
iter_num: 791, on_card_num: 42, preempted blk num: 2114
iter_num: 792, on_card_num: 41, preempted blk num: 2114
iter_num: 793, on_card_num: 42, preempted blk num: 2114
iter_num: 794, on_card_num: 45, preempted blk num: 2114
iter_num: 795, on_card_num: 46, preempted blk num: 2114
iter_num: 796, on_card_num: 48, preempted blk num: 2114
iter_num: 797, on_card_num: 49, preempted blk num: 2114
iter_num: 798, on_card_num: 49, preempted blk num: 2114
iter_num: 799, on_card_num: 49, preempted blk num: 2114
iter_num: 800, on_card_num: 49, preempted blk num: 2114
to recompute 1: ('216', 32)
to recompute 1: ('215', 281)
iter_num: 801, on_card_num: 46, preempted blk num: 2154
iter_num: 802, on_card_num: 48, preempted blk num: 2154
iter_num: 803, on_card_num: 50, preempted blk num: 2154
iter_num: 804, on_card_num: 51, preempted blk num: 2154
iter_num: 805, on_card_num: 51, preempted blk num: 2154
iter_num: 806, on_card_num: 51, preempted blk num: 2154
iter_num: 807, on_card_num: 51, preempted blk num: 2154
to recompute 1: ('219', 9)
iter_num: 808, on_card_num: 50, preempted blk num: 2156
to recompute 1: ('218', 238)
iter_num: 809, on_card_num: 49, preempted blk num: 2186
iter_num: 810, on_card_num: 49, preempted blk num: 2186
iter_num: 811, on_card_num: 48, preempted blk num: 2186
iter_num: 812, on_card_num: 47, preempted blk num: 2186
iter_num: 813, on_card_num: 46, preempted blk num: 2186
iter_num: 814, on_card_num: 48, preempted blk num: 2186
iter_num: 815, on_card_num: 49, preempted blk num: 2186
iter_num: 816, on_card_num: 49, preempted blk num: 2186
iter_num: 817, on_card_num: 49, preempted blk num: 2186
iter_num: 818, on_card_num: 47, preempted blk num: 2186
iter_num: 819, on_card_num: 47, preempted blk num: 2186
iter_num: 820, on_card_num: 47, preempted blk num: 2186
iter_num: 821, on_card_num: 47, preempted blk num: 2186
iter_num: 822, on_card_num: 47, preempted blk num: 2186
iter_num: 823, on_card_num: 47, preempted blk num: 2186
iter_num: 824, on_card_num: 47, preempted blk num: 2186
iter_num: 825, on_card_num: 47, preempted blk num: 2186
iter_num: 826, on_card_num: 47, preempted blk num: 2186
iter_num: 827, on_card_num: 47, preempted blk num: 2186
iter_num: 828, on_card_num: 47, preempted blk num: 2186
iter_num: 829, on_card_num: 47, preempted blk num: 2186
iter_num: 830, on_card_num: 47, preempted blk num: 2186
iter_num: 831, on_card_num: 47, preempted blk num: 2186
iter_num: 832, on_card_num: 47, preempted blk num: 2186
iter_num: 833, on_card_num: 47, preempted blk num: 2186
iter_num: 834, on_card_num: 47, preempted blk num: 2186
to recompute 1: ('220', 348)
iter_num: 835, on_card_num: 46, preempted blk num: 2230
iter_num: 836, on_card_num: 46, preempted blk num: 2230
iter_num: 837, on_card_num: 46, preempted blk num: 2230
iter_num: 838, on_card_num: 46, preempted blk num: 2230
iter_num: 839, on_card_num: 46, preempted blk num: 2230
to recompute 1: ('219', 34)
iter_num: 840, on_card_num: 45, preempted blk num: 2236
iter_num: 841, on_card_num: 45, preempted blk num: 2236
to recompute 1: ('218', 265)
iter_num: 842, on_card_num: 44, preempted blk num: 2270
iter_num: 843, on_card_num: 44, preempted blk num: 2270
iter_num: 844, on_card_num: 44, preempted blk num: 2270
iter_num: 845, on_card_num: 44, preempted blk num: 2270
iter_num: 846, on_card_num: 44, preempted blk num: 2270
iter_num: 847, on_card_num: 44, preempted blk num: 2270
iter_num: 848, on_card_num: 44, preempted blk num: 2270
iter_num: 849, on_card_num: 44, preempted blk num: 2270
to recompute 1: ('217', 51)
iter_num: 850, on_card_num: 43, preempted blk num: 2278
iter_num: 851, on_card_num: 42, preempted blk num: 2278
iter_num: 852, on_card_num: 42, preempted blk num: 2278
iter_num: 853, on_card_num: 42, preempted blk num: 2278
iter_num: 854, on_card_num: 42, preempted blk num: 2278
to recompute 1: ('216', 81)
iter_num: 855, on_card_num: 41, preempted blk num: 2288
to recompute 1: ('213', 71)
iter_num: 856, on_card_num: 40, preempted blk num: 2298
iter_num: 857, on_card_num: 39, preempted blk num: 2298
iter_num: 858, on_card_num: 41, preempted blk num: 2298
iter_num: 859, on_card_num: 41, preempted blk num: 2298
iter_num: 860, on_card_num: 41, preempted blk num: 2298
iter_num: 861, on_card_num: 41, preempted blk num: 2298
iter_num: 862, on_card_num: 41, preempted blk num: 2298
iter_num: 863, on_card_num: 41, preempted blk num: 2298
iter_num: 864, on_card_num: 41, preempted blk num: 2298
to recompute 1: ('216', 88)
iter_num: 865, on_card_num: 39, preempted blk num: 2310
iter_num: 866, on_card_num: 41, preempted blk num: 2310
iter_num: 867, on_card_num: 43, preempted blk num: 2310
iter_num: 868, on_card_num: 43, preempted blk num: 2310
iter_num: 869, on_card_num: 43, preempted blk num: 2310
iter_num: 870, on_card_num: 43, preempted blk num: 2310
iter_num: 871, on_card_num: 43, preempted blk num: 2310
iter_num: 872, on_card_num: 43, preempted blk num: 2310
iter_num: 873, on_card_num: 43, preempted blk num: 2310
iter_num: 874, on_card_num: 43, preempted blk num: 2310
to recompute 1: ('219', 42)
iter_num: 875, on_card_num: 42, preempted blk num: 2316
to recompute 1: ('218', 274)
iter_num: 876, on_card_num: 41, preempted blk num: 2352
iter_num: 877, on_card_num: 40, preempted blk num: 2352
iter_num: 878, on_card_num: 40, preempted blk num: 2352
iter_num: 879, on_card_num: 40, preempted blk num: 2352
iter_num: 880, on_card_num: 39, preempted blk num: 2352
iter_num: 881, on_card_num: 41, preempted blk num: 2352
iter_num: 882, on_card_num: 42, preempted blk num: 2352
iter_num: 883, on_card_num: 42, preempted blk num: 2352
iter_num: 884, on_card_num: 42, preempted blk num: 2352
iter_num: 885, on_card_num: 42, preempted blk num: 2352
iter_num: 886, on_card_num: 42, preempted blk num: 2352
iter_num: 887, on_card_num: 41, preempted blk num: 2352
iter_num: 888, on_card_num: 41, preempted blk num: 2352
iter_num: 889, on_card_num: 41, preempted blk num: 2352
iter_num: 890, on_card_num: 41, preempted blk num: 2352
iter_num: 891, on_card_num: 41, preempted blk num: 2352
iter_num: 892, on_card_num: 40, preempted blk num: 2352
iter_num: 893, on_card_num: 40, preempted blk num: 2352
iter_num: 894, on_card_num: 40, preempted blk num: 2352
iter_num: 895, on_card_num: 40, preempted blk num: 2352
iter_num: 896, on_card_num: 40, preempted blk num: 2352
iter_num: 897, on_card_num: 40, preempted blk num: 2352
iter_num: 898, on_card_num: 40, preempted blk num: 2352
iter_num: 899, on_card_num: 40, preempted blk num: 2352
iter_num: 900, on_card_num: 40, preempted blk num: 2352
iter_num: 901, on_card_num: 38, preempted blk num: 2352
iter_num: 902, on_card_num: 39, preempted blk num: 2352
iter_num: 903, on_card_num: 42, preempted blk num: 2352
iter_num: 904, on_card_num: 44, preempted blk num: 2352
iter_num: 905, on_card_num: 46, preempted blk num: 2352
iter_num: 906, on_card_num: 46, preempted blk num: 2352
iter_num: 907, on_card_num: 46, preempted blk num: 2352
iter_num: 908, on_card_num: 46, preempted blk num: 2352
iter_num: 909, on_card_num: 46, preempted blk num: 2352
iter_num: 910, on_card_num: 46, preempted blk num: 2352
iter_num: 911, on_card_num: 46, preempted blk num: 2352
iter_num: 912, on_card_num: 46, preempted blk num: 2352
iter_num: 913, on_card_num: 45, preempted blk num: 2352
iter_num: 914, on_card_num: 46, preempted blk num: 2352
iter_num: 915, on_card_num: 47, preempted blk num: 2352
iter_num: 916, on_card_num: 47, preempted blk num: 2352
iter_num: 917, on_card_num: 47, preempted blk num: 2352
iter_num: 918, on_card_num: 47, preempted blk num: 2352
iter_num: 919, on_card_num: 47, preempted blk num: 2352
iter_num: 920, on_card_num: 46, preempted blk num: 2352
iter_num: 921, on_card_num: 46, preempted blk num: 2352
iter_num: 922, on_card_num: 46, preempted blk num: 2352
iter_num: 923, on_card_num: 45, preempted blk num: 2352
iter_num: 924, on_card_num: 45, preempted blk num: 2352
iter_num: 925, on_card_num: 45, preempted blk num: 2352
iter_num: 926, on_card_num: 44, preempted blk num: 2352
iter_num: 927, on_card_num: 45, preempted blk num: 2352
iter_num: 928, on_card_num: 46, preempted blk num: 2352
iter_num: 929, on_card_num: 46, preempted blk num: 2352
iter_num: 930, on_card_num: 46, preempted blk num: 2352
iter_num: 931, on_card_num: 46, preempted blk num: 2352
iter_num: 932, on_card_num: 45, preempted blk num: 2352
iter_num: 933, on_card_num: 45, preempted blk num: 2352
iter_num: 934, on_card_num: 45, preempted blk num: 2352
iter_num: 935, on_card_num: 45, preempted blk num: 2352
iter_num: 936, on_card_num: 45, preempted blk num: 2352
iter_num: 937, on_card_num: 45, preempted blk num: 2352
iter_num: 938, on_card_num: 45, preempted blk num: 2352
iter_num: 939, on_card_num: 45, preempted blk num: 2352
iter_num: 940, on_card_num: 45, preempted blk num: 2352
to recompute 1: ('232', 136)
iter_num: 941, on_card_num: 44, preempted blk num: 2370
iter_num: 942, on_card_num: 44, preempted blk num: 2370
iter_num: 943, on_card_num: 43, preempted blk num: 2370
iter_num: 944, on_card_num: 43, preempted blk num: 2370
iter_num: 945, on_card_num: 43, preempted blk num: 2370
iter_num: 946, on_card_num: 43, preempted blk num: 2370
to recompute 1: ('231', 826)
iter_num: 947, on_card_num: 42, preempted blk num: 2474
iter_num: 948, on_card_num: 42, preempted blk num: 2474
iter_num: 949, on_card_num: 42, preempted blk num: 2474
iter_num: 950, on_card_num: 42, preempted blk num: 2474
iter_num: 951, on_card_num: 42, preempted blk num: 2474
iter_num: 952, on_card_num: 42, preempted blk num: 2474
iter_num: 953, on_card_num: 42, preempted blk num: 2474
iter_num: 954, on_card_num: 42, preempted blk num: 2474
iter_num: 955, on_card_num: 41, preempted blk num: 2474
iter_num: 956, on_card_num: 42, preempted blk num: 2474
iter_num: 957, on_card_num: 43, preempted blk num: 2474
iter_num: 958, on_card_num: 43, preempted blk num: 2474
iter_num: 959, on_card_num: 43, preempted blk num: 2474
iter_num: 960, on_card_num: 43, preempted blk num: 2474
iter_num: 961, on_card_num: 43, preempted blk num: 2474
iter_num: 962, on_card_num: 43, preempted blk num: 2474
iter_num: 963, on_card_num: 43, preempted blk num: 2474
iter_num: 964, on_card_num: 43, preempted blk num: 2474
iter_num: 965, on_card_num: 43, preempted blk num: 2474
iter_num: 966, on_card_num: 43, preempted blk num: 2474
to recompute 1: ('232', 146)
iter_num: 967, on_card_num: 41, preempted blk num: 2494
iter_num: 968, on_card_num: 42, preempted blk num: 2494
iter_num: 969, on_card_num: 42, preempted blk num: 2494
iter_num: 970, on_card_num: 42, preempted blk num: 2494
iter_num: 971, on_card_num: 42, preempted blk num: 2494
iter_num: 972, on_card_num: 42, preempted blk num: 2494
iter_num: 973, on_card_num: 42, preempted blk num: 2494
iter_num: 974, on_card_num: 42, preempted blk num: 2494
iter_num: 975, on_card_num: 42, preempted blk num: 2494
iter_num: 976, on_card_num: 42, preempted blk num: 2494
iter_num: 977, on_card_num: 42, preempted blk num: 2494
to recompute 1: ('232', 156)
iter_num: 978, on_card_num: 41, preempted blk num: 2514
iter_num: 979, on_card_num: 41, preempted blk num: 2514
iter_num: 980, on_card_num: 41, preempted blk num: 2514
to recompute 1: ('231', 849)
iter_num: 981, on_card_num: 39, preempted blk num: 2620
iter_num: 982, on_card_num: 40, preempted blk num: 2620
iter_num: 983, on_card_num: 40, preempted blk num: 2620
iter_num: 984, on_card_num: 40, preempted blk num: 2620
iter_num: 985, on_card_num: 40, preempted blk num: 2620
iter_num: 986, on_card_num: 40, preempted blk num: 2620
iter_num: 987, on_card_num: 40, preempted blk num: 2620
iter_num: 988, on_card_num: 40, preempted blk num: 2620
to recompute 1: ('231', 856)
iter_num: 989, on_card_num: 39, preempted blk num: 2728
iter_num: 990, on_card_num: 39, preempted blk num: 2728
iter_num: 991, on_card_num: 38, preempted blk num: 2728
iter_num: 992, on_card_num: 38, preempted blk num: 2728
iter_num: 993, on_card_num: 38, preempted blk num: 2728
iter_num: 994, on_card_num: 38, preempted blk num: 2728
iter_num: 995, on_card_num: 38, preempted blk num: 2728
iter_num: 996, on_card_num: 38, preempted blk num: 2728
iter_num: 997, on_card_num: 38, preempted blk num: 2728
iter_num: 998, on_card_num: 38, preempted blk num: 2728
iter_num: 999, on_card_num: 38, preempted blk num: 2728
iter_num: 1000, on_card_num: 38, preempted blk num: 2728
iter_num: 1001, on_card_num: 38, preempted blk num: 2728
iter_num: 1002, on_card_num: 37, preempted blk num: 2728
iter_num: 1003, on_card_num: 38, preempted blk num: 2728
iter_num: 1004, on_card_num: 38, preempted blk num: 2728
iter_num: 1005, on_card_num: 38, preempted blk num: 2728
iter_num: 1006, on_card_num: 38, preempted blk num: 2728
iter_num: 1007, on_card_num: 38, preempted blk num: 2728
iter_num: 1008, on_card_num: 37, preempted blk num: 2728
iter_num: 1009, on_card_num: 38, preempted blk num: 2728
iter_num: 1010, on_card_num: 39, preempted blk num: 2728
iter_num: 1011, on_card_num: 39, preempted blk num: 2728
iter_num: 1012, on_card_num: 39, preempted blk num: 2728
iter_num: 1013, on_card_num: 39, preempted blk num: 2728
iter_num: 1014, on_card_num: 38, preempted blk num: 2728
iter_num: 1015, on_card_num: 41, preempted blk num: 2728
iter_num: 1016, on_card_num: 42, preempted blk num: 2728
iter_num: 1017, on_card_num: 44, preempted blk num: 2728
iter_num: 1018, on_card_num: 45, preempted blk num: 2728
iter_num: 1019, on_card_num: 45, preempted blk num: 2728
iter_num: 1020, on_card_num: 45, preempted blk num: 2728
iter_num: 1021, on_card_num: 45, preempted blk num: 2728
to recompute 1: ('241', 51)
iter_num: 1022, on_card_num: 44, preempted blk num: 2736
to recompute 1: ('240', 287)
iter_num: 1023, on_card_num: 43, preempted blk num: 2772
iter_num: 1024, on_card_num: 43, preempted blk num: 2772
iter_num: 1025, on_card_num: 43, preempted blk num: 2772
iter_num: 1026, on_card_num: 43, preempted blk num: 2772
iter_num: 1027, on_card_num: 42, preempted blk num: 2772
iter_num: 1028, on_card_num: 41, preempted blk num: 2772
iter_num: 1029, on_card_num: 43, preempted blk num: 2772
iter_num: 1030, on_card_num: 47, preempted blk num: 2772
iter_num: 1031, on_card_num: 46, preempted blk num: 2772
iter_num: 1032, on_card_num: 46, preempted blk num: 2772
iter_num: 1033, on_card_num: 46, preempted blk num: 2772
iter_num: 1034, on_card_num: 46, preempted blk num: 2772
iter_num: 1035, on_card_num: 46, preempted blk num: 2772
iter_num: 1036, on_card_num: 46, preempted blk num: 2772
iter_num: 1037, on_card_num: 46, preempted blk num: 2772
iter_num: 1038, on_card_num: 46, preempted blk num: 2772
iter_num: 1039, on_card_num: 45, preempted blk num: 2772
iter_num: 1040, on_card_num: 44, preempted blk num: 2772
iter_num: 1041, on_card_num: 44, preempted blk num: 2772
iter_num: 1042, on_card_num: 44, preempted blk num: 2772
iter_num: 1043, on_card_num: 44, preempted blk num: 2772
iter_num: 1044, on_card_num: 44, preempted blk num: 2772
iter_num: 1045, on_card_num: 44, preempted blk num: 2772
iter_num: 1046, on_card_num: 44, preempted blk num: 2772
iter_num: 1047, on_card_num: 44, preempted blk num: 2772
iter_num: 1048, on_card_num: 44, preempted blk num: 2772
iter_num: 1049, on_card_num: 44, preempted blk num: 2772
to recompute 1: ('245', 47)
iter_num: 1050, on_card_num: 43, preempted blk num: 2778
iter_num: 1051, on_card_num: 43, preempted blk num: 2778
to recompute 1: ('244', 37)
iter_num: 1052, on_card_num: 42, preempted blk num: 2784
to recompute 1: ('243', 53)
iter_num: 1053, on_card_num: 41, preempted blk num: 2792
iter_num: 1054, on_card_num: 41, preempted blk num: 2792
to recompute 1: ('241', 76)
iter_num: 1055, on_card_num: 40, preempted blk num: 2802
iter_num: 1056, on_card_num: 40, preempted blk num: 2802
to recompute 1: ('240', 314)
iter_num: 1057, on_card_num: 39, preempted blk num: 2842
iter_num: 1058, on_card_num: 39, preempted blk num: 2842
iter_num: 1059, on_card_num: 39, preempted blk num: 2842
iter_num: 1060, on_card_num: 39, preempted blk num: 2842
iter_num: 1061, on_card_num: 38, preempted blk num: 2842
iter_num: 1062, on_card_num: 40, preempted blk num: 2842
iter_num: 1063, on_card_num: 43, preempted blk num: 2842
iter_num: 1064, on_card_num: 45, preempted blk num: 2842
iter_num: 1065, on_card_num: 45, preempted blk num: 2842
iter_num: 1066, on_card_num: 45, preempted blk num: 2842
iter_num: 1067, on_card_num: 44, preempted blk num: 2842
iter_num: 1068, on_card_num: 46, preempted blk num: 2842
iter_num: 1069, on_card_num: 46, preempted blk num: 2842
iter_num: 1070, on_card_num: 46, preempted blk num: 2842
iter_num: 1071, on_card_num: 46, preempted blk num: 2842
iter_num: 1072, on_card_num: 46, preempted blk num: 2842
to recompute 1: ('249', 30)
iter_num: 1073, on_card_num: 45, preempted blk num: 2846
to recompute 1: ('248', 249)
iter_num: 1074, on_card_num: 44, preempted blk num: 2878
iter_num: 1075, on_card_num: 44, preempted blk num: 2878
iter_num: 1076, on_card_num: 44, preempted blk num: 2878
iter_num: 1077, on_card_num: 44, preempted blk num: 2878
iter_num: 1078, on_card_num: 43, preempted blk num: 2878
iter_num: 1079, on_card_num: 43, preempted blk num: 2878
iter_num: 1080, on_card_num: 43, preempted blk num: 2878
to recompute 1: ('247', 537)
iter_num: 1081, on_card_num: 42, preempted blk num: 2946
iter_num: 1082, on_card_num: 42, preempted blk num: 2946
iter_num: 1083, on_card_num: 42, preempted blk num: 2946
iter_num: 1084, on_card_num: 41, preempted blk num: 2946
iter_num: 1085, on_card_num: 42, preempted blk num: 2946
iter_num: 1086, on_card_num: 42, preempted blk num: 2946
iter_num: 1087, on_card_num: 42, preempted blk num: 2946
iter_num: 1088, on_card_num: 41, preempted blk num: 2946
iter_num: 1089, on_card_num: 43, preempted blk num: 2946
iter_num: 1090, on_card_num: 42, preempted blk num: 2946
iter_num: 1091, on_card_num: 43, preempted blk num: 2946
iter_num: 1092, on_card_num: 49, preempted blk num: 2946
iter_num: 1093, on_card_num: 49, preempted blk num: 2946
iter_num: 1094, on_card_num: 49, preempted blk num: 2946
iter_num: 1095, on_card_num: 48, preempted blk num: 2946
iter_num: 1096, on_card_num: 51, preempted blk num: 2946
iter_num: 1097, on_card_num: 52, preempted blk num: 2946
iter_num: 1098, on_card_num: 51, preempted blk num: 2946
iter_num: 1099, on_card_num: 53, preempted blk num: 2946
iter_num: 1100, on_card_num: 53, preempted blk num: 2946
iter_num: 1101, on_card_num: 53, preempted blk num: 2946
iter_num: 1102, on_card_num: 53, preempted blk num: 2946
iter_num: 1103, on_card_num: 53, preempted blk num: 2946
to recompute 1: ('262', 17)
iter_num: 1104, on_card_num: 52, preempted blk num: 2948
to recompute 1: ('261', 12)
iter_num: 1105, on_card_num: 51, preempted blk num: 2950
to recompute 1: ('260', 24)
to recompute 1: ('259', 28)
iter_num: 1106, on_card_num: 49, preempted blk num: 2958
to recompute 1: ('258', 143)
iter_num: 1107, on_card_num: 48, preempted blk num: 2976
iter_num: 1108, on_card_num: 48, preempted blk num: 2976
iter_num: 1109, on_card_num: 48, preempted blk num: 2976
iter_num: 1110, on_card_num: 48, preempted blk num: 2976
iter_num: 1111, on_card_num: 48, preempted blk num: 2976
to recompute 1: ('257', 28)
to recompute 1: ('256', 76)
iter_num: 1112, on_card_num: 46, preempted blk num: 2990
iter_num: 1113, on_card_num: 46, preempted blk num: 2990
to recompute 1: ('255', 44)
iter_num: 1114, on_card_num: 45, preempted blk num: 2996
to recompute 1: ('254', 27)
iter_num: 1115, on_card_num: 44, preempted blk num: 3000
to recompute 1: ('253', 30)
to recompute 1: ('252', 31)
to recompute 1: ('251', 32)
iter_num: 1116, on_card_num: 41, preempted blk num: 3012
to recompute 1: ('250', 467)
iter_num: 1117, on_card_num: 40, preempted blk num: 3072
iter_num: 1118, on_card_num: 40, preempted blk num: 3072
iter_num: 1119, on_card_num: 39, preempted blk num: 3072
iter_num: 1120, on_card_num: 40, preempted blk num: 3072
iter_num: 1121, on_card_num: 42, preempted blk num: 3072
iter_num: 1122, on_card_num: 41, preempted blk num: 3072
iter_num: 1123, on_card_num: 46, preempted blk num: 3072
iter_num: 1124, on_card_num: 49, preempted blk num: 3072
iter_num: 1125, on_card_num: 51, preempted blk num: 3072
iter_num: 1126, on_card_num: 53, preempted blk num: 3072
iter_num: 1127, on_card_num: 54, preempted blk num: 3072
iter_num: 1128, on_card_num: 54, preempted blk num: 3072
iter_num: 1129, on_card_num: 54, preempted blk num: 3072
iter_num: 1130, on_card_num: 53, preempted blk num: 3072
iter_num: 1131, on_card_num: 53, preempted blk num: 3072
iter_num: 1132, on_card_num: 53, preempted blk num: 3072
iter_num: 1133, on_card_num: 53, preempted blk num: 3072
iter_num: 1134, on_card_num: 53, preempted blk num: 3072
iter_num: 1135, on_card_num: 53, preempted blk num: 3072
iter_num: 1136, on_card_num: 53, preempted blk num: 3072
iter_num: 1137, on_card_num: 52, preempted blk num: 3072
iter_num: 1138, on_card_num: 52, preempted blk num: 3072
iter_num: 1139, on_card_num: 51, preempted blk num: 3072
iter_num: 1140, on_card_num: 51, preempted blk num: 3072
iter_num: 1141, on_card_num: 50, preempted blk num: 3072
iter_num: 1142, on_card_num: 51, preempted blk num: 3072
iter_num: 1143, on_card_num: 53, preempted blk num: 3072
iter_num: 1144, on_card_num: 55, preempted blk num: 3072
iter_num: 1145, on_card_num: 56, preempted blk num: 3072
iter_num: 1146, on_card_num: 60, preempted blk num: 3072
iter_num: 1147, on_card_num: 60, preempted blk num: 3072
iter_num: 1148, on_card_num: 60, preempted blk num: 3072
iter_num: 1149, on_card_num: 60, preempted blk num: 3072
iter_num: 1150, on_card_num: 60, preempted blk num: 3072
to recompute 1: ('275', 19)
to recompute 1: ('274', 17)
to recompute 1: ('273', 119)
iter_num: 1151, on_card_num: 57, preempted blk num: 3094
iter_num: 1152, on_card_num: 57, preempted blk num: 3094
to recompute 1: ('272', 86)
iter_num: 1153, on_card_num: 56, preempted blk num: 3106
iter_num: 1154, on_card_num: 56, preempted blk num: 3106
iter_num: 1155, on_card_num: 56, preempted blk num: 3106
to recompute 1: ('271', 431)
iter_num: 1156, on_card_num: 55, preempted blk num: 3160
iter_num: 1157, on_card_num: 55, preempted blk num: 3160
iter_num: 1158, on_card_num: 55, preempted blk num: 3160
iter_num: 1159, on_card_num: 55, preempted blk num: 3160
iter_num: 1160, on_card_num: 54, preempted blk num: 3160
iter_num: 1161, on_card_num: 54, preempted blk num: 3160
iter_num: 1162, on_card_num: 53, preempted blk num: 3160
iter_num: 1163, on_card_num: 53, preempted blk num: 3160
iter_num: 1164, on_card_num: 53, preempted blk num: 3160
iter_num: 1165, on_card_num: 53, preempted blk num: 3160
iter_num: 1166, on_card_num: 52, preempted blk num: 3160
iter_num: 1167, on_card_num: 52, preempted blk num: 3160
iter_num: 1168, on_card_num: 52, preempted blk num: 3160
iter_num: 1169, on_card_num: 52, preempted blk num: 3160
iter_num: 1170, on_card_num: 52, preempted blk num: 3160
iter_num: 1171, on_card_num: 51, preempted blk num: 3160
iter_num: 1172, on_card_num: 52, preempted blk num: 3160
iter_num: 1173, on_card_num: 56, preempted blk num: 3160
iter_num: 1174, on_card_num: 55, preempted blk num: 3160
iter_num: 1175, on_card_num: 55, preempted blk num: 3160
iter_num: 1176, on_card_num: 55, preempted blk num: 3160
iter_num: 1177, on_card_num: 55, preempted blk num: 3160
iter_num: 1178, on_card_num: 55, preempted blk num: 3160
iter_num: 1179, on_card_num: 55, preempted blk num: 3160
iter_num: 1180, on_card_num: 53, preempted blk num: 3160
iter_num: 1181, on_card_num: 54, preempted blk num: 3160
iter_num: 1182, on_card_num: 59, preempted blk num: 3160
iter_num: 1183, on_card_num: 60, preempted blk num: 3160
iter_num: 1184, on_card_num: 61, preempted blk num: 3160
iter_num: 1185, on_card_num: 62, preempted blk num: 3160
iter_num: 1186, on_card_num: 65, preempted blk num: 3160
iter_num: 1187, on_card_num: 65, preempted blk num: 3160
iter_num: 1188, on_card_num: 65, preempted blk num: 3160
iter_num: 1189, on_card_num: 65, preempted blk num: 3160
to recompute 1: ('287', 16)
to recompute 1: ('286', 39)
iter_num: 1190, on_card_num: 63, preempted blk num: 3168
to recompute 1: ('285', 18)
to recompute 1: ('284', 315)
iter_num: 1191, on_card_num: 61, preempted blk num: 3212
iter_num: 1192, on_card_num: 61, preempted blk num: 3212
iter_num: 1193, on_card_num: 61, preempted blk num: 3212
iter_num: 1194, on_card_num: 61, preempted blk num: 3212
iter_num: 1195, on_card_num: 61, preempted blk num: 3212
to recompute 1: ('283', 19)
to recompute 1: ('282', 455)
iter_num: 1196, on_card_num: 56, preempted blk num: 3274
iter_num: 1197, on_card_num: 57, preempted blk num: 3274
iter_num: 1198, on_card_num: 58, preempted blk num: 3274
iter_num: 1199, on_card_num: 59, preempted blk num: 3274
iter_num: 1200, on_card_num: 63, preempted blk num: 3274
iter_num: 1201, on_card_num: 62, preempted blk num: 3274
iter_num: 1202, on_card_num: 63, preempted blk num: 3274
iter_num: 1203, on_card_num: 63, preempted blk num: 3274
iter_num: 1204, on_card_num: 63, preempted blk num: 3274
iter_num: 1205, on_card_num: 63, preempted blk num: 3274
iter_num: 1206, on_card_num: 63, preempted blk num: 3274
iter_num: 1207, on_card_num: 62, preempted blk num: 3274
iter_num: 1208, on_card_num: 63, preempted blk num: 3274
iter_num: 1209, on_card_num: 64, preempted blk num: 3274
iter_num: 1210, on_card_num: 64, preempted blk num: 3274
iter_num: 1211, on_card_num: 64, preempted blk num: 3274
iter_num: 1212, on_card_num: 64, preempted blk num: 3274
iter_num: 1213, on_card_num: 63, preempted blk num: 3274
iter_num: 1214, on_card_num: 64, preempted blk num: 3274
iter_num: 1215, on_card_num: 63, preempted blk num: 3274
iter_num: 1216, on_card_num: 64, preempted blk num: 3274
iter_num: 1217, on_card_num: 65, preempted blk num: 3274
iter_num: 1218, on_card_num: 65, preempted blk num: 3274
iter_num: 1219, on_card_num: 65, preempted blk num: 3274
iter_num: 1220, on_card_num: 64, preempted blk num: 3274
iter_num: 1221, on_card_num: 64, preempted blk num: 3274
iter_num: 1222, on_card_num: 62, preempted blk num: 3274
iter_num: 1223, on_card_num: 63, preempted blk num: 3274
iter_num: 1224, on_card_num: 63, preempted blk num: 3274
iter_num: 1225, on_card_num: 63, preempted blk num: 3274
iter_num: 1226, on_card_num: 63, preempted blk num: 3274
iter_num: 1227, on_card_num: 62, preempted blk num: 3274
iter_num: 1228, on_card_num: 61, preempted blk num: 3274
iter_num: 1229, on_card_num: 61, preempted blk num: 3274
iter_num: 1230, on_card_num: 60, preempted blk num: 3274
iter_num: 1231, on_card_num: 61, preempted blk num: 3274
iter_num: 1232, on_card_num: 60, preempted blk num: 3274
iter_num: 1233, on_card_num: 61, preempted blk num: 3274
iter_num: 1234, on_card_num: 62, preempted blk num: 3274
iter_num: 1235, on_card_num: 62, preempted blk num: 3274
iter_num: 1236, on_card_num: 62, preempted blk num: 3274
iter_num: 1237, on_card_num: 62, preempted blk num: 3274
iter_num: 1238, on_card_num: 62, preempted blk num: 3274
iter_num: 1239, on_card_num: 61, preempted blk num: 3274
iter_num: 1240, on_card_num: 62, preempted blk num: 3274
iter_num: 1241, on_card_num: 64, preempted blk num: 3274
iter_num: 1242, on_card_num: 64, preempted blk num: 3274
iter_num: 1243, on_card_num: 64, preempted blk num: 3274
iter_num: 1244, on_card_num: 64, preempted blk num: 3274
iter_num: 1245, on_card_num: 64, preempted blk num: 3274
iter_num: 1246, on_card_num: 63, preempted blk num: 3274
iter_num: 1247, on_card_num: 63, preempted blk num: 3274
iter_num: 1248, on_card_num: 63, preempted blk num: 3274
iter_num: 1249, on_card_num: 63, preempted blk num: 3274
iter_num: 1250, on_card_num: 63, preempted blk num: 3274
iter_num: 1251, on_card_num: 63, preempted blk num: 3274
to recompute 1: ('301', 112)
iter_num: 1252, on_card_num: 61, preempted blk num: 3288
iter_num: 1253, on_card_num: 61, preempted blk num: 3288
to recompute 1: ('300', 101)
iter_num: 1254, on_card_num: 60, preempted blk num: 3302
iter_num: 1255, on_card_num: 60, preempted blk num: 3302
iter_num: 1256, on_card_num: 59, preempted blk num: 3302
iter_num: 1257, on_card_num: 60, preempted blk num: 3302
iter_num: 1258, on_card_num: 60, preempted blk num: 3302
iter_num: 1259, on_card_num: 60, preempted blk num: 3302
iter_num: 1260, on_card_num: 60, preempted blk num: 3302
to recompute 1: ('300', 105)
iter_num: 1261, on_card_num: 59, preempted blk num: 3316
to recompute 1: ('299', 605)
iter_num: 1262, on_card_num: 58, preempted blk num: 3392
iter_num: 1263, on_card_num: 57, preempted blk num: 3392
iter_num: 1264, on_card_num: 58, preempted blk num: 3392
iter_num: 1265, on_card_num: 60, preempted blk num: 3392
iter_num: 1266, on_card_num: 59, preempted blk num: 3392
iter_num: 1267, on_card_num: 61, preempted blk num: 3392
iter_num: 1268, on_card_num: 61, preempted blk num: 3392
iter_num: 1269, on_card_num: 60, preempted blk num: 3392
iter_num: 1270, on_card_num: 62, preempted blk num: 3392
iter_num: 1271, on_card_num: 63, preempted blk num: 3392
iter_num: 1272, on_card_num: 65, preempted blk num: 3392
iter_num: 1273, on_card_num: 66, preempted blk num: 3392
iter_num: 1274, on_card_num: 66, preempted blk num: 3392
iter_num: 1275, on_card_num: 66, preempted blk num: 3392
iter_num: 1276, on_card_num: 66, preempted blk num: 3392
to recompute 1: ('309', 168)
iter_num: 1277, on_card_num: 65, preempted blk num: 3414
iter_num: 1278, on_card_num: 64, preempted blk num: 3414
iter_num: 1279, on_card_num: 64, preempted blk num: 3414
iter_num: 1280, on_card_num: 64, preempted blk num: 3414
iter_num: 1281, on_card_num: 64, preempted blk num: 3414
to recompute 1: ('308', 26)
to recompute 1: ('307', 23)
iter_num: 1282, on_card_num: 62, preempted blk num: 3422
to recompute 1: ('306', 368)
iter_num: 1283, on_card_num: 61, preempted blk num: 3468
iter_num: 1284, on_card_num: 61, preempted blk num: 3468
iter_num: 1285, on_card_num: 61, preempted blk num: 3468
iter_num: 1286, on_card_num: 61, preempted blk num: 3468
iter_num: 1287, on_card_num: 61, preempted blk num: 3468
iter_num: 1288, on_card_num: 61, preempted blk num: 3468
iter_num: 1289, on_card_num: 61, preempted blk num: 3468
to recompute 1: ('305', 23)
to recompute 1: ('303', 118)
iter_num: 1290, on_card_num: 59, preempted blk num: 3488
iter_num: 1291, on_card_num: 59, preempted blk num: 3488
iter_num: 1292, on_card_num: 59, preempted blk num: 3488
to recompute 1: ('302', 223)
iter_num: 1293, on_card_num: 57, preempted blk num: 3516
iter_num: 1294, on_card_num: 59, preempted blk num: 3516
iter_num: 1295, on_card_num: 60, preempted blk num: 3516
iter_num: 1296, on_card_num: 60, preempted blk num: 3516
iter_num: 1297, on_card_num: 60, preempted blk num: 3516
iter_num: 1298, on_card_num: 60, preempted blk num: 3516
iter_num: 1299, on_card_num: 59, preempted blk num: 3516
iter_num: 1300, on_card_num: 60, preempted blk num: 3516
iter_num: 1301, on_card_num: 60, preempted blk num: 3516
iter_num: 1302, on_card_num: 60, preempted blk num: 3516
to recompute 1: ('306', 371)
iter_num: 1303, on_card_num: 59, preempted blk num: 3564
iter_num: 1304, on_card_num: 59, preempted blk num: 3564
iter_num: 1305, on_card_num: 59, preempted blk num: 3564
iter_num: 1306, on_card_num: 59, preempted blk num: 3564
iter_num: 1307, on_card_num: 59, preempted blk num: 3564
iter_num: 1308, on_card_num: 59, preempted blk num: 3564
iter_num: 1309, on_card_num: 59, preempted blk num: 3564
iter_num: 1310, on_card_num: 59, preempted blk num: 3564
to recompute 1: ('305', 38)
iter_num: 1311, on_card_num: 58, preempted blk num: 3570
to recompute 1: ('303', 134)
iter_num: 1312, on_card_num: 57, preempted blk num: 3588
to recompute 1: ('302', 240)
iter_num: 1313, on_card_num: 55, preempted blk num: 3618
iter_num: 1314, on_card_num: 57, preempted blk num: 3618
iter_num: 1315, on_card_num: 58, preempted blk num: 3618
iter_num: 1316, on_card_num: 58, preempted blk num: 3618
iter_num: 1317, on_card_num: 58, preempted blk num: 3618
iter_num: 1318, on_card_num: 58, preempted blk num: 3618
iter_num: 1319, on_card_num: 58, preempted blk num: 3618
iter_num: 1320, on_card_num: 58, preempted blk num: 3618
to recompute 1: ('305', 44)
iter_num: 1321, on_card_num: 56, preempted blk num: 3624
iter_num: 1322, on_card_num: 57, preempted blk num: 3624
iter_num: 1323, on_card_num: 58, preempted blk num: 3624
iter_num: 1324, on_card_num: 56, preempted blk num: 3624
iter_num: 1325, on_card_num: 58, preempted blk num: 3624
iter_num: 1326, on_card_num: 60, preempted blk num: 3624
iter_num: 1327, on_card_num: 62, preempted blk num: 3624
iter_num: 1328, on_card_num: 62, preempted blk num: 3624
iter_num: 1329, on_card_num: 62, preempted blk num: 3624
iter_num: 1330, on_card_num: 62, preempted blk num: 3624
iter_num: 1331, on_card_num: 62, preempted blk num: 3624
iter_num: 1332, on_card_num: 62, preempted blk num: 3624
iter_num: 1333, on_card_num: 62, preempted blk num: 3624
to recompute 1: ('312', 115)
iter_num: 1334, on_card_num: 61, preempted blk num: 3640
iter_num: 1335, on_card_num: 61, preempted blk num: 3640
to recompute 1: ('311', 20)
to recompute 1: ('310', 47)
to recompute 1: ('309', 177)
iter_num: 1336, on_card_num: 57, preempted blk num: 3672
iter_num: 1337, on_card_num: 59, preempted blk num: 3672
iter_num: 1338, on_card_num: 61, preempted blk num: 3672
iter_num: 1339, on_card_num: 61, preempted blk num: 3672
iter_num: 1340, on_card_num: 60, preempted blk num: 3672
iter_num: 1341, on_card_num: 61, preempted blk num: 3672
iter_num: 1342, on_card_num: 61, preempted blk num: 3672
iter_num: 1343, on_card_num: 61, preempted blk num: 3672
iter_num: 1344, on_card_num: 61, preempted blk num: 3672
to recompute 1: ('313', 866)
iter_num: 1345, on_card_num: 60, preempted blk num: 3782
iter_num: 1346, on_card_num: 60, preempted blk num: 3782
iter_num: 1347, on_card_num: 60, preempted blk num: 3782
iter_num: 1348, on_card_num: 59, preempted blk num: 3782
iter_num: 1349, on_card_num: 58, preempted blk num: 3782
iter_num: 1350, on_card_num: 58, preempted blk num: 3782
iter_num: 1351, on_card_num: 58, preempted blk num: 3782
iter_num: 1352, on_card_num: 57, preempted blk num: 3782
iter_num: 1353, on_card_num: 56, preempted blk num: 3782
iter_num: 1354, on_card_num: 57, preempted blk num: 3782
iter_num: 1355, on_card_num: 60, preempted blk num: 3782
iter_num: 1356, on_card_num: 60, preempted blk num: 3782
iter_num: 1357, on_card_num: 60, preempted blk num: 3782
iter_num: 1358, on_card_num: 60, preempted blk num: 3782
iter_num: 1359, on_card_num: 60, preempted blk num: 3782
iter_num: 1360, on_card_num: 60, preempted blk num: 3782
iter_num: 1361, on_card_num: 60, preempted blk num: 3782
iter_num: 1362, on_card_num: 59, preempted blk num: 3782
iter_num: 1363, on_card_num: 59, preempted blk num: 3782
iter_num: 1364, on_card_num: 59, preempted blk num: 3782
iter_num: 1365, on_card_num: 58, preempted blk num: 3782
iter_num: 1366, on_card_num: 58, preempted blk num: 3782
iter_num: 1367, on_card_num: 58, preempted blk num: 3782
iter_num: 1368, on_card_num: 58, preempted blk num: 3782
iter_num: 1369, on_card_num: 58, preempted blk num: 3782
iter_num: 1370, on_card_num: 58, preempted blk num: 3782
iter_num: 1371, on_card_num: 58, preempted blk num: 3782
iter_num: 1372, on_card_num: 57, preempted blk num: 3782
iter_num: 1373, on_card_num: 57, preempted blk num: 3782
iter_num: 1374, on_card_num: 56, preempted blk num: 3782
iter_num: 1375, on_card_num: 56, preempted blk num: 3782
iter_num: 1376, on_card_num: 55, preempted blk num: 3782
iter_num: 1377, on_card_num: 55, preempted blk num: 3782
iter_num: 1378, on_card_num: 55, preempted blk num: 3782
iter_num: 1379, on_card_num: 55, preempted blk num: 3782
iter_num: 1380, on_card_num: 55, preempted blk num: 3782
iter_num: 1381, on_card_num: 55, preempted blk num: 3782
iter_num: 1382, on_card_num: 55, preempted blk num: 3782
iter_num: 1383, on_card_num: 55, preempted blk num: 3782
iter_num: 1384, on_card_num: 55, preempted blk num: 3782
iter_num: 1385, on_card_num: 54, preempted blk num: 3782
iter_num: 1386, on_card_num: 54, preempted blk num: 3782
iter_num: 1387, on_card_num: 54, preempted blk num: 3782
iter_num: 1388, on_card_num: 54, preempted blk num: 3782
iter_num: 1389, on_card_num: 54, preempted blk num: 3782
iter_num: 1390, on_card_num: 54, preempted blk num: 3782
iter_num: 1391, on_card_num: 54, preempted blk num: 3782
iter_num: 1392, on_card_num: 54, preempted blk num: 3782
iter_num: 1393, on_card_num: 54, preempted blk num: 3782
iter_num: 1394, on_card_num: 54, preempted blk num: 3782
to recompute 1: ('316', 46)
iter_num: 1395, on_card_num: 53, preempted blk num: 3788
to recompute 1: ('313', 907)
iter_num: 1396, on_card_num: 52, preempted blk num: 3902
iter_num: 1397, on_card_num: 52, preempted blk num: 3902
iter_num: 1398, on_card_num: 51, preempted blk num: 3902
iter_num: 1399, on_card_num: 52, preempted blk num: 3902
iter_num: 1400, on_card_num: 53, preempted blk num: 3902
iter_num: 1401, on_card_num: 53, preempted blk num: 3902
iter_num: 1402, on_card_num: 53, preempted blk num: 3902
iter_num: 1403, on_card_num: 53, preempted blk num: 3902
iter_num: 1404, on_card_num: 53, preempted blk num: 3902
to recompute 1: ('316', 51)
iter_num: 1405, on_card_num: 52, preempted blk num: 3910
to recompute 1: ('313', 913)
iter_num: 1406, on_card_num: 51, preempted blk num: 4024
iter_num: 1407, on_card_num: 51, preempted blk num: 4024
iter_num: 1408, on_card_num: 51, preempted blk num: 4024
iter_num: 1409, on_card_num: 51, preempted blk num: 4024
iter_num: 1410, on_card_num: 51, preempted blk num: 4024
iter_num: 1411, on_card_num: 51, preempted blk num: 4024
iter_num: 1412, on_card_num: 51, preempted blk num: 4024
iter_num: 1413, on_card_num: 51, preempted blk num: 4024
iter_num: 1414, on_card_num: 50, preempted blk num: 4024
iter_num: 1415, on_card_num: 50, preempted blk num: 4024
iter_num: 1416, on_card_num: 50, preempted blk num: 4024
iter_num: 1417, on_card_num: 50, preempted blk num: 4024
iter_num: 1418, on_card_num: 50, preempted blk num: 4024
iter_num: 1419, on_card_num: 49, preempted blk num: 4024
iter_num: 1420, on_card_num: 49, preempted blk num: 4024
iter_num: 1421, on_card_num: 48, preempted blk num: 4024
iter_num: 1422, on_card_num: 49, preempted blk num: 4024
iter_num: 1423, on_card_num: 50, preempted blk num: 4024
iter_num: 1424, on_card_num: 50, preempted blk num: 4024
iter_num: 1425, on_card_num: 49, preempted blk num: 4024
iter_num: 1426, on_card_num: 49, preempted blk num: 4024
iter_num: 1427, on_card_num: 49, preempted blk num: 4024
iter_num: 1428, on_card_num: 49, preempted blk num: 4024
iter_num: 1429, on_card_num: 49, preempted blk num: 4024
iter_num: 1430, on_card_num: 49, preempted blk num: 4024
iter_num: 1431, on_card_num: 49, preempted blk num: 4024
iter_num: 1432, on_card_num: 49, preempted blk num: 4024
iter_num: 1433, on_card_num: 49, preempted blk num: 4024
iter_num: 1434, on_card_num: 48, preempted blk num: 4024
iter_num: 1435, on_card_num: 48, preempted blk num: 4024
iter_num: 1436, on_card_num: 48, preempted blk num: 4024
iter_num: 1437, on_card_num: 48, preempted blk num: 4024
iter_num: 1438, on_card_num: 48, preempted blk num: 4024
iter_num: 1439, on_card_num: 48, preempted blk num: 4024
iter_num: 1440, on_card_num: 48, preempted blk num: 4024
iter_num: 1441, on_card_num: 48, preempted blk num: 4024
iter_num: 1442, on_card_num: 48, preempted blk num: 4024
iter_num: 1443, on_card_num: 48, preempted blk num: 4024
to recompute 1: ('316', 72)
iter_num: 1444, on_card_num: 47, preempted blk num: 4034
to recompute 1: ('313', 935)
iter_num: 1445, on_card_num: 46, preempted blk num: 4152
iter_num: 1446, on_card_num: 45, preempted blk num: 4152
iter_num: 1447, on_card_num: 45, preempted blk num: 4152
iter_num: 1448, on_card_num: 45, preempted blk num: 4152
iter_num: 1449, on_card_num: 45, preempted blk num: 4152
iter_num: 1450, on_card_num: 45, preempted blk num: 4152
iter_num: 1451, on_card_num: 45, preempted blk num: 4152
iter_num: 1452, on_card_num: 44, preempted blk num: 4152
iter_num: 1453, on_card_num: 45, preempted blk num: 4152
iter_num: 1454, on_card_num: 46, preempted blk num: 4152
iter_num: 1455, on_card_num: 47, preempted blk num: 4152
iter_num: 1456, on_card_num: 52, preempted blk num: 4152
iter_num: 1457, on_card_num: 52, preempted blk num: 4152
iter_num: 1458, on_card_num: 52, preempted blk num: 4152
iter_num: 1459, on_card_num: 52, preempted blk num: 4152
iter_num: 1460, on_card_num: 52, preempted blk num: 4152
to recompute 1: ('322', 14)
to recompute 1: ('321', 62)
iter_num: 1461, on_card_num: 50, preempted blk num: 4162
to recompute 1: ('320', 18)
iter_num: 1462, on_card_num: 48, preempted blk num: 4166
iter_num: 1463, on_card_num: 51, preempted blk num: 4166
iter_num: 1464, on_card_num: 51, preempted blk num: 4166
iter_num: 1465, on_card_num: 51, preempted blk num: 4166
iter_num: 1466, on_card_num: 51, preempted blk num: 4166
iter_num: 1467, on_card_num: 50, preempted blk num: 4166
iter_num: 1468, on_card_num: 50, preempted blk num: 4166
iter_num: 1469, on_card_num: 49, preempted blk num: 4166
iter_num: 1470, on_card_num: 50, preempted blk num: 4166
iter_num: 1471, on_card_num: 50, preempted blk num: 4166
iter_num: 1472, on_card_num: 50, preempted blk num: 4166
iter_num: 1473, on_card_num: 50, preempted blk num: 4166
iter_num: 1474, on_card_num: 49, preempted blk num: 4166
iter_num: 1475, on_card_num: 49, preempted blk num: 4166
iter_num: 1476, on_card_num: 49, preempted blk num: 4166
iter_num: 1477, on_card_num: 49, preempted blk num: 4166
iter_num: 1478, on_card_num: 49, preempted blk num: 4166
iter_num: 1479, on_card_num: 49, preempted blk num: 4166
iter_num: 1480, on_card_num: 49, preempted blk num: 4166
iter_num: 1481, on_card_num: 49, preempted blk num: 4166
iter_num: 1482, on_card_num: 48, preempted blk num: 4166
iter_num: 1483, on_card_num: 48, preempted blk num: 4166
iter_num: 1484, on_card_num: 48, preempted blk num: 4166
iter_num: 1485, on_card_num: 48, preempted blk num: 4166
iter_num: 1486, on_card_num: 47, preempted blk num: 4166
iter_num: 1487, on_card_num: 48, preempted blk num: 4166
iter_num: 1488, on_card_num: 50, preempted blk num: 4166
iter_num: 1489, on_card_num: 50, preempted blk num: 4166
iter_num: 1490, on_card_num: 50, preempted blk num: 4166
iter_num: 1491, on_card_num: 49, preempted blk num: 4166
iter_num: 1492, on_card_num: 52, preempted blk num: 4166
iter_num: 1493, on_card_num: 52, preempted blk num: 4166
iter_num: 1494, on_card_num: 52, preempted blk num: 4166
iter_num: 1495, on_card_num: 52, preempted blk num: 4166
iter_num: 1496, on_card_num: 52, preempted blk num: 4166
iter_num: 1497, on_card_num: 52, preempted blk num: 4166
to recompute 1: ('329', 25)
iter_num: 1498, on_card_num: 51, preempted blk num: 4170
to recompute 1: ('328', 19)
iter_num: 1499, on_card_num: 48, preempted blk num: 4174
iter_num: 1500, on_card_num: 50, preempted blk num: 4174
iter_num: 1501, on_card_num: 51, preempted blk num: 4174
iter_num: 1502, on_card_num: 52, preempted blk num: 4174
iter_num: 1503, on_card_num: 52, preempted blk num: 4174
iter_num: 1504, on_card_num: 51, preempted blk num: 4174
iter_num: 1505, on_card_num: 51, preempted blk num: 4174
iter_num: 1506, on_card_num: 51, preempted blk num: 4174
iter_num: 1507, on_card_num: 51, preempted blk num: 4174
iter_num: 1508, on_card_num: 51, preempted blk num: 4174
iter_num: 1509, on_card_num: 51, preempted blk num: 4174
iter_num: 1510, on_card_num: 51, preempted blk num: 4174
iter_num: 1511, on_card_num: 51, preempted blk num: 4174
iter_num: 1512, on_card_num: 51, preempted blk num: 4174
iter_num: 1513, on_card_num: 50, preempted blk num: 4174
iter_num: 1514, on_card_num: 51, preempted blk num: 4174
iter_num: 1515, on_card_num: 54, preempted blk num: 4174
iter_num: 1516, on_card_num: 54, preempted blk num: 4174
iter_num: 1517, on_card_num: 53, preempted blk num: 4174
iter_num: 1518, on_card_num: 54, preempted blk num: 4174
iter_num: 1519, on_card_num: 55, preempted blk num: 4174
iter_num: 1520, on_card_num: 53, preempted blk num: 4174
iter_num: 1521, on_card_num: 57, preempted blk num: 4174
iter_num: 1522, on_card_num: 57, preempted blk num: 4174
iter_num: 1523, on_card_num: 57, preempted blk num: 4174
iter_num: 1524, on_card_num: 57, preempted blk num: 4174
iter_num: 1525, on_card_num: 57, preempted blk num: 4174
iter_num: 1526, on_card_num: 57, preempted blk num: 4174
iter_num: 1527, on_card_num: 56, preempted blk num: 4174
iter_num: 1528, on_card_num: 57, preempted blk num: 4174
iter_num: 1529, on_card_num: 56, preempted blk num: 4174
iter_num: 1530, on_card_num: 57, preempted blk num: 4174
iter_num: 1531, on_card_num: 57, preempted blk num: 4174
iter_num: 1532, on_card_num: 57, preempted blk num: 4174
iter_num: 1533, on_card_num: 57, preempted blk num: 4174
to recompute 1: ('343', 688)
iter_num: 1534, on_card_num: 56, preempted blk num: 4260
iter_num: 1535, on_card_num: 54, preempted blk num: 4260
iter_num: 1536, on_card_num: 55, preempted blk num: 4260
iter_num: 1537, on_card_num: 56, preempted blk num: 4260
iter_num: 1538, on_card_num: 57, preempted blk num: 4260
iter_num: 1539, on_card_num: 58, preempted blk num: 4260
iter_num: 1540, on_card_num: 59, preempted blk num: 4260
iter_num: 1541, on_card_num: 59, preempted blk num: 4260
iter_num: 1542, on_card_num: 59, preempted blk num: 4260
iter_num: 1543, on_card_num: 58, preempted blk num: 4260
iter_num: 1544, on_card_num: 59, preempted blk num: 4260
iter_num: 1545, on_card_num: 59, preempted blk num: 4260
iter_num: 1546, on_card_num: 59, preempted blk num: 4260
iter_num: 1547, on_card_num: 58, preempted blk num: 4260
iter_num: 1548, on_card_num: 58, preempted blk num: 4260
iter_num: 1549, on_card_num: 58, preempted blk num: 4260
iter_num: 1550, on_card_num: 58, preempted blk num: 4260
iter_num: 1551, on_card_num: 58, preempted blk num: 4260
iter_num: 1552, on_card_num: 56, preempted blk num: 4260
iter_num: 1553, on_card_num: 57, preempted blk num: 4260
iter_num: 1554, on_card_num: 59, preempted blk num: 4260
iter_num: 1555, on_card_num: 61, preempted blk num: 4260
iter_num: 1556, on_card_num: 63, preempted blk num: 4260
iter_num: 1557, on_card_num: 63, preempted blk num: 4260
iter_num: 1558, on_card_num: 63, preempted blk num: 4260
iter_num: 1559, on_card_num: 63, preempted blk num: 4260
to recompute 1: ('355', 58)
iter_num: 1560, on_card_num: 61, preempted blk num: 4268
iter_num: 1561, on_card_num: 62, preempted blk num: 4268
iter_num: 1562, on_card_num: 62, preempted blk num: 4268
iter_num: 1563, on_card_num: 62, preempted blk num: 4268
iter_num: 1564, on_card_num: 62, preempted blk num: 4268
iter_num: 1565, on_card_num: 62, preempted blk num: 4268
iter_num: 1566, on_card_num: 62, preempted blk num: 4268
to recompute 1: ('355', 64)
to recompute 1: ('354', 142)
iter_num: 1567, on_card_num: 59, preempted blk num: 4294
iter_num: 1568, on_card_num: 59, preempted blk num: 4294
iter_num: 1569, on_card_num: 59, preempted blk num: 4294
iter_num: 1570, on_card_num: 59, preempted blk num: 4294
to recompute 1: ('353', 24)
to recompute 1: ('352', 246)
iter_num: 1571, on_card_num: 57, preempted blk num: 4330
iter_num: 1572, on_card_num: 54, preempted blk num: 4330
iter_num: 1573, on_card_num: 56, preempted blk num: 4330
iter_num: 1574, on_card_num: 58, preempted blk num: 4330
iter_num: 1575, on_card_num: 59, preempted blk num: 4330
iter_num: 1576, on_card_num: 64, preempted blk num: 4330
iter_num: 1577, on_card_num: 68, preempted blk num: 4330
iter_num: 1578, on_card_num: 68, preempted blk num: 4330
iter_num: 1579, on_card_num: 68, preempted blk num: 4330
iter_num: 1580, on_card_num: 68, preempted blk num: 4330
iter_num: 1581, on_card_num: 68, preempted blk num: 4330
iter_num: 1582, on_card_num: 68, preempted blk num: 4330
iter_num: 1583, on_card_num: 68, preempted blk num: 4330
iter_num: 1584, on_card_num: 68, preempted blk num: 4330
iter_num: 1585, on_card_num: 68, preempted blk num: 4330
to recompute 1: ('365', 18)
to recompute 1: ('364', 149)
iter_num: 1586, on_card_num: 66, preempted blk num: 4354
iter_num: 1587, on_card_num: 64, preempted blk num: 4354
iter_num: 1588, on_card_num: 64, preempted blk num: 4354
to recompute 1: ('363', 37)
iter_num: 1589, on_card_num: 63, preempted blk num: 4360
to recompute 1: ('362', 144)
iter_num: 1590, on_card_num: 62, preempted blk num: 4378
iter_num: 1591, on_card_num: 61, preempted blk num: 4378
iter_num: 1592, on_card_num: 63, preempted blk num: 4378
iter_num: 1593, on_card_num: 63, preempted blk num: 4378
iter_num: 1594, on_card_num: 63, preempted blk num: 4378
iter_num: 1595, on_card_num: 63, preempted blk num: 4378
iter_num: 1596, on_card_num: 63, preempted blk num: 4378
to recompute 1: ('363', 42)
iter_num: 1597, on_card_num: 62, preempted blk num: 4384
to recompute 1: ('362', 150)
iter_num: 1598, on_card_num: 61, preempted blk num: 4404
iter_num: 1599, on_card_num: 61, preempted blk num: 4404
iter_num: 1600, on_card_num: 61, preempted blk num: 4404
to recompute 1: ('361', 38)
iter_num: 1601, on_card_num: 60, preempted blk num: 4410
to recompute 1: ('360', 65)
iter_num: 1602, on_card_num: 59, preempted blk num: 4418
to recompute 1: ('359', 65)
iter_num: 1603, on_card_num: 58, preempted blk num: 4426
iter_num: 1604, on_card_num: 58, preempted blk num: 4426
to recompute 1: ('357', 59)
to recompute 1: ('356', 400)
iter_num: 1605, on_card_num: 56, preempted blk num: 4484
iter_num: 1606, on_card_num: 56, preempted blk num: 4484
iter_num: 1607, on_card_num: 56, preempted blk num: 4484
iter_num: 1608, on_card_num: 56, preempted blk num: 4484
iter_num: 1609, on_card_num: 56, preempted blk num: 4484
iter_num: 1610, on_card_num: 55, preempted blk num: 4484
iter_num: 1611, on_card_num: 54, preempted blk num: 4484
iter_num: 1612, on_card_num: 55, preempted blk num: 4484
iter_num: 1613, on_card_num: 55, preempted blk num: 4484
iter_num: 1614, on_card_num: 53, preempted blk num: 4484
iter_num: 1615, on_card_num: 57, preempted blk num: 4484
iter_num: 1616, on_card_num: 61, preempted blk num: 4484
iter_num: 1617, on_card_num: 61, preempted blk num: 4484
iter_num: 1618, on_card_num: 61, preempted blk num: 4484
iter_num: 1619, on_card_num: 60, preempted blk num: 4484
iter_num: 1620, on_card_num: 61, preempted blk num: 4484
iter_num: 1621, on_card_num: 62, preempted blk num: 4484
iter_num: 1622, on_card_num: 62, preempted blk num: 4484
iter_num: 1623, on_card_num: 62, preempted blk num: 4484
iter_num: 1624, on_card_num: 62, preempted blk num: 4484
to recompute 1: ('367', 12)
iter_num: 1625, on_card_num: 60, preempted blk num: 4486
iter_num: 1626, on_card_num: 61, preempted blk num: 4486
iter_num: 1627, on_card_num: 61, preempted blk num: 4486
iter_num: 1628, on_card_num: 61, preempted blk num: 4486
iter_num: 1629, on_card_num: 61, preempted blk num: 4486
iter_num: 1630, on_card_num: 61, preempted blk num: 4486
to recompute 1: ('367', 17)
to recompute 1: ('366', 589)
iter_num: 1631, on_card_num: 59, preempted blk num: 4562
iter_num: 1632, on_card_num: 59, preempted blk num: 4562
iter_num: 1633, on_card_num: 59, preempted blk num: 4562
iter_num: 1634, on_card_num: 58, preempted blk num: 4562
iter_num: 1635, on_card_num: 59, preempted blk num: 4562
iter_num: 1636, on_card_num: 59, preempted blk num: 4562
iter_num: 1637, on_card_num: 59, preempted blk num: 4562
iter_num: 1638, on_card_num: 58, preempted blk num: 4562
iter_num: 1639, on_card_num: 60, preempted blk num: 4562
iter_num: 1640, on_card_num: 63, preempted blk num: 4562
iter_num: 1641, on_card_num: 64, preempted blk num: 4562
iter_num: 1642, on_card_num: 64, preempted blk num: 4562
iter_num: 1643, on_card_num: 64, preempted blk num: 4562
iter_num: 1644, on_card_num: 64, preempted blk num: 4562
iter_num: 1645, on_card_num: 64, preempted blk num: 4562
to recompute 1: ('372', 141)
iter_num: 1646, on_card_num: 63, preempted blk num: 4580
to recompute 1: ('371', 17)
to recompute 1: ('370', 10)
to recompute 1: ('369', 21)
iter_num: 1647, on_card_num: 60, preempted blk num: 4588
to recompute 1: ('368', 175)
iter_num: 1648, on_card_num: 59, preempted blk num: 4610
iter_num: 1649, on_card_num: 59, preempted blk num: 4610
iter_num: 1650, on_card_num: 59, preempted blk num: 4610
to recompute 1: ('367', 27)
to recompute 2: ('365', 46)
iter_num: 1651, on_card_num: 57, preempted blk num: 4620
iter_num: 1652, on_card_num: 57, preempted blk num: 4620
to recompute 1: ('364', 179)
iter_num: 1653, on_card_num: 55, preempted blk num: 4644
iter_num: 1654, on_card_num: 55, preempted blk num: 4644
iter_num: 1655, on_card_num: 54, preempted blk num: 4644
iter_num: 1656, on_card_num: 56, preempted blk num: 4644
iter_num: 1657, on_card_num: 57, preempted blk num: 4644
iter_num: 1658, on_card_num: 57, preempted blk num: 4644
iter_num: 1659, on_card_num: 56, preempted blk num: 4644
iter_num: 1660, on_card_num: 56, preempted blk num: 4644
iter_num: 1661, on_card_num: 56, preempted blk num: 4644
iter_num: 1662, on_card_num: 55, preempted blk num: 4644
iter_num: 1663, on_card_num: 55, preempted blk num: 4644
iter_num: 1664, on_card_num: 54, preempted blk num: 4644
iter_num: 1665, on_card_num: 54, preempted blk num: 4644
iter_num: 1666, on_card_num: 54, preempted blk num: 4644
iter_num: 1667, on_card_num: 54, preempted blk num: 4644
iter_num: 1668, on_card_num: 54, preempted blk num: 4644
to recompute 1: ('367', 39)
to recompute 1: ('364', 191)
iter_num: 1669, on_card_num: 52, preempted blk num: 4674
iter_num: 1670, on_card_num: 52, preempted blk num: 4674
iter_num: 1671, on_card_num: 52, preempted blk num: 4674
iter_num: 1672, on_card_num: 52, preempted blk num: 4674
to recompute 1: ('363', 90)
iter_num: 1673, on_card_num: 51, preempted blk num: 4686
iter_num: 1674, on_card_num: 51, preempted blk num: 4686
to recompute 1: ('362', 200)
iter_num: 1675, on_card_num: 50, preempted blk num: 4712
iter_num: 1676, on_card_num: 50, preempted blk num: 4712
iter_num: 1677, on_card_num: 50, preempted blk num: 4712
iter_num: 1678, on_card_num: 50, preempted blk num: 4712
iter_num: 1679, on_card_num: 50, preempted blk num: 4712
to recompute 1: ('361', 93)
iter_num: 1680, on_card_num: 49, preempted blk num: 4724
to recompute 1: ('360', 121)
iter_num: 1681, on_card_num: 48, preempted blk num: 4740
iter_num: 1682, on_card_num: 48, preempted blk num: 4740
iter_num: 1683, on_card_num: 48, preempted blk num: 4740
iter_num: 1684, on_card_num: 48, preempted blk num: 4740
to recompute 1: ('359', 125)
iter_num: 1685, on_card_num: 47, preempted blk num: 4756
iter_num: 1686, on_card_num: 47, preempted blk num: 4756
to recompute 1: ('357', 121)
iter_num: 1687, on_card_num: 46, preempted blk num: 4772
iter_num: 1688, on_card_num: 46, preempted blk num: 4772
iter_num: 1689, on_card_num: 46, preempted blk num: 4772
to recompute 1: ('355', 164)
iter_num: 1690, on_card_num: 44, preempted blk num: 4794
iter_num: 1691, on_card_num: 49, preempted blk num: 4794
iter_num: 1692, on_card_num: 50, preempted blk num: 4794
iter_num: 1693, on_card_num: 50, preempted blk num: 4794
iter_num: 1694, on_card_num: 50, preempted blk num: 4794
iter_num: 1695, on_card_num: 50, preempted blk num: 4794
iter_num: 1696, on_card_num: 50, preempted blk num: 4794
iter_num: 1697, on_card_num: 50, preempted blk num: 4794
iter_num: 1698, on_card_num: 49, preempted blk num: 4794
iter_num: 1699, on_card_num: 52, preempted blk num: 4794
iter_num: 1700, on_card_num: 54, preempted blk num: 4794
iter_num: 1701, on_card_num: 57, preempted blk num: 4794
iter_num: 1702, on_card_num: 58, preempted blk num: 4794
iter_num: 1703, on_card_num: 58, preempted blk num: 4794
iter_num: 1704, on_card_num: 58, preempted blk num: 4794
to recompute 1: ('373', 16)
iter_num: 1705, on_card_num: 57, preempted blk num: 4796
to recompute 1: ('372', 145)
iter_num: 1706, on_card_num: 56, preempted blk num: 4814
iter_num: 1707, on_card_num: 56, preempted blk num: 4814
iter_num: 1708, on_card_num: 56, preempted blk num: 4814
to recompute 1: ('371', 24)
to recompute 1: ('370', 17)
to recompute 1: ('369', 28)
iter_num: 1709, on_card_num: 53, preempted blk num: 4824
iter_num: 1710, on_card_num: 53, preempted blk num: 4824
to recompute 1: ('368', 184)
iter_num: 1711, on_card_num: 50, preempted blk num: 4848
iter_num: 1712, on_card_num: 52, preempted blk num: 4848
iter_num: 1713, on_card_num: 55, preempted blk num: 4848
iter_num: 1714, on_card_num: 56, preempted blk num: 4848
iter_num: 1715, on_card_num: 56, preempted blk num: 4848
iter_num: 1716, on_card_num: 56, preempted blk num: 4848
iter_num: 1717, on_card_num: 56, preempted blk num: 4848
iter_num: 1718, on_card_num: 56, preempted blk num: 4848
to recompute 1: ('373', 21)
to recompute 1: ('372', 150)
iter_num: 1719, on_card_num: 54, preempted blk num: 4872
iter_num: 1720, on_card_num: 53, preempted blk num: 4872
iter_num: 1721, on_card_num: 53, preempted blk num: 4872
iter_num: 1722, on_card_num: 53, preempted blk num: 4872
iter_num: 1723, on_card_num: 53, preempted blk num: 4872
to recompute 1: ('371', 34)
to recompute 1: ('370', 27)
iter_num: 1724, on_card_num: 50, preempted blk num: 4882
iter_num: 1725, on_card_num: 50, preempted blk num: 4882
iter_num: 1726, on_card_num: 50, preempted blk num: 4882
iter_num: 1727, on_card_num: 50, preempted blk num: 4882
to recompute 1: ('369', 42)
iter_num: 1728, on_card_num: 49, preempted blk num: 4888
iter_num: 1729, on_card_num: 49, preempted blk num: 4888
to recompute 1: ('368', 200)
iter_num: 1730, on_card_num: 48, preempted blk num: 4914
iter_num: 1731, on_card_num: 48, preempted blk num: 4914
iter_num: 1732, on_card_num: 48, preempted blk num: 4914
iter_num: 1733, on_card_num: 48, preempted blk num: 4914
to recompute 1: ('367', 68)
iter_num: 1734, on_card_num: 46, preempted blk num: 4924
iter_num: 1735, on_card_num: 47, preempted blk num: 4924
iter_num: 1736, on_card_num: 47, preempted blk num: 4924
iter_num: 1737, on_card_num: 47, preempted blk num: 4924
iter_num: 1738, on_card_num: 47, preempted blk num: 4924
iter_num: 1739, on_card_num: 47, preempted blk num: 4924
to recompute 1: ('367', 73)
iter_num: 1740, on_card_num: 46, preempted blk num: 4934
to recompute 2: ('364', 226)
iter_num: 1741, on_card_num: 45, preempted blk num: 4964
iter_num: 1742, on_card_num: 45, preempted blk num: 4964
iter_num: 1743, on_card_num: 45, preempted blk num: 4964
iter_num: 1744, on_card_num: 45, preempted blk num: 4964
iter_num: 1745, on_card_num: 45, preempted blk num: 4964
iter_num: 1746, on_card_num: 44, preempted blk num: 4964
iter_num: 1747, on_card_num: 46, preempted blk num: 4964
iter_num: 1748, on_card_num: 46, preempted blk num: 4964
iter_num: 1749, on_card_num: 46, preempted blk num: 4964
iter_num: 1750, on_card_num: 46, preempted blk num: 4964
iter_num: 1751, on_card_num: 46, preempted blk num: 4964
iter_num: 1752, on_card_num: 46, preempted blk num: 4964
iter_num: 1753, on_card_num: 46, preempted blk num: 4964
iter_num: 1754, on_card_num: 46, preempted blk num: 4964
iter_num: 1755, on_card_num: 46, preempted blk num: 4964
to recompute 1: ('367', 82)
iter_num: 1756, on_card_num: 45, preempted blk num: 4976
to recompute 1: ('364', 236)
iter_num: 1757, on_card_num: 43, preempted blk num: 5006
iter_num: 1758, on_card_num: 45, preempted blk num: 5006
iter_num: 1759, on_card_num: 45, preempted blk num: 5006
iter_num: 1760, on_card_num: 45, preempted blk num: 5006
iter_num: 1761, on_card_num: 45, preempted blk num: 5006
iter_num: 1762, on_card_num: 45, preempted blk num: 5006
iter_num: 1763, on_card_num: 45, preempted blk num: 5006
iter_num: 1764, on_card_num: 45, preempted blk num: 5006
iter_num: 1765, on_card_num: 45, preempted blk num: 5006
to recompute 1: ('367', 90)
iter_num: 1766, on_card_num: 44, preempted blk num: 5018
iter_num: 1767, on_card_num: 44, preempted blk num: 5018
to recompute 1: ('364', 246)
iter_num: 1768, on_card_num: 43, preempted blk num: 5050
iter_num: 1769, on_card_num: 43, preempted blk num: 5050
iter_num: 1770, on_card_num: 43, preempted blk num: 5050
iter_num: 1771, on_card_num: 43, preempted blk num: 5050
iter_num: 1772, on_card_num: 43, preempted blk num: 5050
iter_num: 1773, on_card_num: 43, preempted blk num: 5050
to recompute 1: ('362', 272)
iter_num: 1774, on_card_num: 42, preempted blk num: 5084
iter_num: 1775, on_card_num: 42, preempted blk num: 5084
iter_num: 1776, on_card_num: 42, preempted blk num: 5084
iter_num: 1777, on_card_num: 42, preempted blk num: 5084
iter_num: 1778, on_card_num: 42, preempted blk num: 5084
iter_num: 1779, on_card_num: 42, preempted blk num: 5084
iter_num: 1780, on_card_num: 42, preempted blk num: 5084
to recompute 1: ('361', 172)
iter_num: 1781, on_card_num: 41, preempted blk num: 5106
iter_num: 1782, on_card_num: 41, preempted blk num: 5106
iter_num: 1783, on_card_num: 41, preempted blk num: 5106
iter_num: 1784, on_card_num: 41, preempted blk num: 5106
iter_num: 1785, on_card_num: 41, preempted blk num: 5106
to recompute 1: ('360', 205)
iter_num: 1786, on_card_num: 40, preempted blk num: 5132
iter_num: 1787, on_card_num: 40, preempted blk num: 5132
iter_num: 1788, on_card_num: 40, preempted blk num: 5132
iter_num: 1789, on_card_num: 40, preempted blk num: 5132
to recompute 1: ('357', 209)
iter_num: 1790, on_card_num: 39, preempted blk num: 5158
iter_num: 1791, on_card_num: 39, preempted blk num: 5158
iter_num: 1792, on_card_num: 39, preempted blk num: 5158
iter_num: 1793, on_card_num: 39, preempted blk num: 5158
iter_num: 1794, on_card_num: 39, preempted blk num: 5158
iter_num: 1795, on_card_num: 39, preempted blk num: 5158
iter_num: 1796, on_card_num: 38, preempted blk num: 5158
iter_num: 1797, on_card_num: 38, preempted blk num: 5158
iter_num: 1798, on_card_num: 38, preempted blk num: 5158
iter_num: 1799, on_card_num: 38, preempted blk num: 5158
iter_num: 1800, on_card_num: 38, preempted blk num: 5158
iter_num: 1801, on_card_num: 38, preempted blk num: 5158
iter_num: 1802, on_card_num: 38, preempted blk num: 5158
iter_num: 1803, on_card_num: 38, preempted blk num: 5158
to recompute 1: ('355', 266)
iter_num: 1804, on_card_num: 37, preempted blk num: 5192
iter_num: 1805, on_card_num: 37, preempted blk num: 5192
iter_num: 1806, on_card_num: 37, preempted blk num: 5192
iter_num: 1807, on_card_num: 37, preempted blk num: 5192
iter_num: 1808, on_card_num: 37, preempted blk num: 5192
iter_num: 1809, on_card_num: 37, preempted blk num: 5192
iter_num: 1810, on_card_num: 37, preempted blk num: 5192
to recompute 1: ('354', 351)
iter_num: 1811, on_card_num: 36, preempted blk num: 5236
iter_num: 1812, on_card_num: 36, preempted blk num: 5236
iter_num: 1813, on_card_num: 36, preempted blk num: 5236
iter_num: 1814, on_card_num: 36, preempted blk num: 5236
iter_num: 1815, on_card_num: 36, preempted blk num: 5236
iter_num: 1816, on_card_num: 36, preempted blk num: 5236
iter_num: 1817, on_card_num: 36, preempted blk num: 5236
iter_num: 1818, on_card_num: 36, preempted blk num: 5236
iter_num: 1819, on_card_num: 36, preempted blk num: 5236
iter_num: 1820, on_card_num: 36, preempted blk num: 5236
to recompute 1: ('352', 465)
iter_num: 1821, on_card_num: 35, preempted blk num: 5294
iter_num: 1822, on_card_num: 35, preempted blk num: 5294
iter_num: 1823, on_card_num: 35, preempted blk num: 5294
iter_num: 1824, on_card_num: 35, preempted blk num: 5294
iter_num: 1825, on_card_num: 35, preempted blk num: 5294
iter_num: 1826, on_card_num: 35, preempted blk num: 5294
iter_num: 1827, on_card_num: 35, preempted blk num: 5294
iter_num: 1828, on_card_num: 35, preempted blk num: 5294
iter_num: 1829, on_card_num: 35, preempted blk num: 5294
iter_num: 1830, on_card_num: 35, preempted blk num: 5294
iter_num: 1831, on_card_num: 35, preempted blk num: 5294
iter_num: 1832, on_card_num: 34, preempted blk num: 5294
iter_num: 1833, on_card_num: 34, preempted blk num: 5294
iter_num: 1834, on_card_num: 34, preempted blk num: 5294
iter_num: 1835, on_card_num: 34, preempted blk num: 5294
iter_num: 1836, on_card_num: 34, preempted blk num: 5294
iter_num: 1837, on_card_num: 34, preempted blk num: 5294
iter_num: 1838, on_card_num: 34, preempted blk num: 5294
iter_num: 1839, on_card_num: 34, preempted blk num: 5294
iter_num: 1840, on_card_num: 34, preempted blk num: 5294
iter_num: 1841, on_card_num: 34, preempted blk num: 5294
iter_num: 1842, on_card_num: 33, preempted blk num: 5294
iter_num: 1843, on_card_num: 33, preempted blk num: 5294
iter_num: 1844, on_card_num: 33, preempted blk num: 5294
iter_num: 1845, on_card_num: 33, preempted blk num: 5294
iter_num: 1846, on_card_num: 33, preempted blk num: 5294
iter_num: 1847, on_card_num: 32, preempted blk num: 5294
iter_num: 1848, on_card_num: 34, preempted blk num: 5294
iter_num: 1849, on_card_num: 34, preempted blk num: 5294
iter_num: 1850, on_card_num: 34, preempted blk num: 5294
iter_num: 1851, on_card_num: 34, preempted blk num: 5294
iter_num: 1852, on_card_num: 34, preempted blk num: 5294
iter_num: 1853, on_card_num: 33, preempted blk num: 5294
iter_num: 1854, on_card_num: 36, preempted blk num: 5294
iter_num: 1855, on_card_num: 36, preempted blk num: 5294
iter_num: 1856, on_card_num: 36, preempted blk num: 5294
iter_num: 1857, on_card_num: 36, preempted blk num: 5294
iter_num: 1858, on_card_num: 36, preempted blk num: 5294
to recompute 1: ('360', 210)
iter_num: 1859, on_card_num: 35, preempted blk num: 5322
iter_num: 1860, on_card_num: 35, preempted blk num: 5322
iter_num: 1861, on_card_num: 35, preempted blk num: 5322
iter_num: 1862, on_card_num: 35, preempted blk num: 5322
iter_num: 1863, on_card_num: 35, preempted blk num: 5322
iter_num: 1864, on_card_num: 35, preempted blk num: 5322
iter_num: 1865, on_card_num: 35, preempted blk num: 5322
iter_num: 1866, on_card_num: 35, preempted blk num: 5322
to recompute 1: ('357', 222)
iter_num: 1867, on_card_num: 33, preempted blk num: 5350
iter_num: 1868, on_card_num: 38, preempted blk num: 5350
iter_num: 1869, on_card_num: 40, preempted blk num: 5350
iter_num: 1870, on_card_num: 43, preempted blk num: 5350
iter_num: 1871, on_card_num: 43, preempted blk num: 5350
iter_num: 1872, on_card_num: 43, preempted blk num: 5350
iter_num: 1873, on_card_num: 43, preempted blk num: 5350
to recompute 1: ('371', 38)
iter_num: 1874, on_card_num: 42, preempted blk num: 5356
iter_num: 1875, on_card_num: 42, preempted blk num: 5356
to recompute 1: ('370', 33)
iter_num: 1876, on_card_num: 40, preempted blk num: 5360
iter_num: 1877, on_card_num: 43, preempted blk num: 5360
iter_num: 1878, on_card_num: 44, preempted blk num: 5360
iter_num: 1879, on_card_num: 45, preempted blk num: 5360
iter_num: 1880, on_card_num: 45, preempted blk num: 5360
iter_num: 1881, on_card_num: 45, preempted blk num: 5360
iter_num: 1882, on_card_num: 45, preempted blk num: 5360
iter_num: 1883, on_card_num: 45, preempted blk num: 5360
iter_num: 1884, on_card_num: 44, preempted blk num: 5360
iter_num: 1885, on_card_num: 44, preempted blk num: 5360
iter_num: 1886, on_card_num: 44, preempted blk num: 5360
iter_num: 1887, on_card_num: 44, preempted blk num: 5360
iter_num: 1888, on_card_num: 44, preempted blk num: 5360
iter_num: 1889, on_card_num: 44, preempted blk num: 5360
iter_num: 1890, on_card_num: 44, preempted blk num: 5360
iter_num: 1891, on_card_num: 44, preempted blk num: 5360
iter_num: 1892, on_card_num: 44, preempted blk num: 5360
to recompute 1: ('374', 336)
iter_num: 1893, on_card_num: 43, preempted blk num: 5402
iter_num: 1894, on_card_num: 43, preempted blk num: 5402
iter_num: 1895, on_card_num: 43, preempted blk num: 5402
iter_num: 1896, on_card_num: 43, preempted blk num: 5402
iter_num: 1897, on_card_num: 43, preempted blk num: 5402
iter_num: 1898, on_card_num: 43, preempted blk num: 5402
iter_num: 1899, on_card_num: 43, preempted blk num: 5402
iter_num: 1900, on_card_num: 43, preempted blk num: 5402
iter_num: 1901, on_card_num: 42, preempted blk num: 5402
iter_num: 1902, on_card_num: 44, preempted blk num: 5402
iter_num: 1903, on_card_num: 47, preempted blk num: 5402
iter_num: 1904, on_card_num: 48, preempted blk num: 5402
iter_num: 1905, on_card_num: 48, preempted blk num: 5402
iter_num: 1906, on_card_num: 48, preempted blk num: 5402
iter_num: 1907, on_card_num: 47, preempted blk num: 5402
iter_num: 1908, on_card_num: 48, preempted blk num: 5402
iter_num: 1909, on_card_num: 47, preempted blk num: 5402
iter_num: 1910, on_card_num: 48, preempted blk num: 5402
iter_num: 1911, on_card_num: 51, preempted blk num: 5402
iter_num: 1912, on_card_num: 53, preempted blk num: 5402
iter_num: 1913, on_card_num: 55, preempted blk num: 5402
iter_num: 1914, on_card_num: 55, preempted blk num: 5402
iter_num: 1915, on_card_num: 55, preempted blk num: 5402
iter_num: 1916, on_card_num: 55, preempted blk num: 5402
iter_num: 1917, on_card_num: 54, preempted blk num: 5402
iter_num: 1918, on_card_num: 54, preempted blk num: 5402
iter_num: 1919, on_card_num: 54, preempted blk num: 5402
iter_num: 1920, on_card_num: 54, preempted blk num: 5402
to recompute 1: ('388', 23)
iter_num: 1921, on_card_num: 53, preempted blk num: 5406
iter_num: 1922, on_card_num: 53, preempted blk num: 5406
to recompute 1: ('387', 63)
iter_num: 1923, on_card_num: 52, preempted blk num: 5414
to recompute 1: ('386', 550)
iter_num: 1924, on_card_num: 51, preempted blk num: 5484
iter_num: 1925, on_card_num: 49, preempted blk num: 5484
iter_num: 1926, on_card_num: 50, preempted blk num: 5484
iter_num: 1927, on_card_num: 52, preempted blk num: 5484
iter_num: 1928, on_card_num: 52, preempted blk num: 5484
iter_num: 1929, on_card_num: 52, preempted blk num: 5484
iter_num: 1930, on_card_num: 52, preempted blk num: 5484
iter_num: 1931, on_card_num: 52, preempted blk num: 5484
iter_num: 1932, on_card_num: 52, preempted blk num: 5484
iter_num: 1933, on_card_num: 52, preempted blk num: 5484
iter_num: 1934, on_card_num: 52, preempted blk num: 5484
iter_num: 1935, on_card_num: 52, preempted blk num: 5484
iter_num: 1936, on_card_num: 51, preempted blk num: 5484
iter_num: 1937, on_card_num: 51, preempted blk num: 5484
iter_num: 1938, on_card_num: 51, preempted blk num: 5484
iter_num: 1939, on_card_num: 51, preempted blk num: 5484
iter_num: 1940, on_card_num: 51, preempted blk num: 5484
iter_num: 1941, on_card_num: 50, preempted blk num: 5484
iter_num: 1942, on_card_num: 50, preempted blk num: 5484
iter_num: 1943, on_card_num: 50, preempted blk num: 5484
iter_num: 1944, on_card_num: 50, preempted blk num: 5484
iter_num: 1945, on_card_num: 50, preempted blk num: 5484
iter_num: 1946, on_card_num: 50, preempted blk num: 5484
iter_num: 1947, on_card_num: 49, preempted blk num: 5484
iter_num: 1948, on_card_num: 50, preempted blk num: 5484
iter_num: 1949, on_card_num: 51, preempted blk num: 5484
iter_num: 1950, on_card_num: 51, preempted blk num: 5484
iter_num: 1951, on_card_num: 51, preempted blk num: 5484
iter_num: 1952, on_card_num: 51, preempted blk num: 5484
iter_num: 1953, on_card_num: 51, preempted blk num: 5484
iter_num: 1954, on_card_num: 51, preempted blk num: 5484
to recompute 1: ('390', 50)
iter_num: 1955, on_card_num: 50, preempted blk num: 5492
to recompute 1: ('389', 922)
iter_num: 1956, on_card_num: 49, preempted blk num: 5608
iter_num: 1957, on_card_num: 48, preempted blk num: 5608
iter_num: 1958, on_card_num: 49, preempted blk num: 5608
iter_num: 1959, on_card_num: 50, preempted blk num: 5608
iter_num: 1960, on_card_num: 50, preempted blk num: 5608
iter_num: 1961, on_card_num: 49, preempted blk num: 5608
iter_num: 1962, on_card_num: 50, preempted blk num: 5608
iter_num: 1963, on_card_num: 53, preempted blk num: 5608
iter_num: 1964, on_card_num: 53, preempted blk num: 5608
iter_num: 1965, on_card_num: 53, preempted blk num: 5608
iter_num: 1966, on_card_num: 52, preempted blk num: 5608
iter_num: 1967, on_card_num: 52, preempted blk num: 5608
iter_num: 1968, on_card_num: 52, preempted blk num: 5608
to recompute 1: ('394', 23)
iter_num: 1969, on_card_num: 51, preempted blk num: 5612
to recompute 1: ('393', 55)
iter_num: 1970, on_card_num: 50, preempted blk num: 5620
to recompute 1: ('392', 19)
iter_num: 1971, on_card_num: 49, preempted blk num: 5624
to recompute 1: ('391', 695)
iter_num: 1972, on_card_num: 48, preempted blk num: 5712
iter_num: 1973, on_card_num: 48, preempted blk num: 5712
iter_num: 1974, on_card_num: 48, preempted blk num: 5712
iter_num: 1975, on_card_num: 48, preempted blk num: 5712
iter_num: 1976, on_card_num: 48, preempted blk num: 5712
iter_num: 1977, on_card_num: 48, preempted blk num: 5712
iter_num: 1978, on_card_num: 48, preempted blk num: 5712
iter_num: 1979, on_card_num: 48, preempted blk num: 5712
iter_num: 1980, on_card_num: 48, preempted blk num: 5712
iter_num: 1981, on_card_num: 48, preempted blk num: 5712
iter_num: 1982, on_card_num: 48, preempted blk num: 5712
iter_num: 1983, on_card_num: 48, preempted blk num: 5712
iter_num: 1984, on_card_num: 48, preempted blk num: 5712
iter_num: 1985, on_card_num: 48, preempted blk num: 5712
to recompute 1: ('390', 75)
iter_num: 1986, on_card_num: 47, preempted blk num: 5722
iter_num: 1987, on_card_num: 47, preempted blk num: 5722
to recompute 1: ('389', 949)
iter_num: 1988, on_card_num: 46, preempted blk num: 5842
iter_num: 1989, on_card_num: 46, preempted blk num: 5842
iter_num: 1990, on_card_num: 46, preempted blk num: 5842
iter_num: 1991, on_card_num: 46, preempted blk num: 5842
iter_num: 1992, on_card_num: 46, preempted blk num: 5842
iter_num: 1993, on_card_num: 46, preempted blk num: 5842
iter_num: 1994, on_card_num: 46, preempted blk num: 5842
iter_num: 1995, on_card_num: 46, preempted blk num: 5842
iter_num: 1996, on_card_num: 46, preempted blk num: 5842
iter_num: 1997, on_card_num: 45, preempted blk num: 5842
iter_num: 1998, on_card_num: 45, preempted blk num: 5842
iter_num: 1999, on_card_num: 45, preempted blk num: 5842
iter_num: 2000, on_card_num: 45, preempted blk num: 5842
iter_num: 2001, on_card_num: 45, preempted blk num: 5842
iter_num: 2002, on_card_num: 45, preempted blk num: 5842
iter_num: 2003, on_card_num: 45, preempted blk num: 5842
iter_num: 2004, on_card_num: 45, preempted blk num: 5842
iter_num: 2005, on_card_num: 45, preempted blk num: 5842
iter_num: 2006, on_card_num: 44, preempted blk num: 5842
iter_num: 2007, on_card_num: 45, preempted blk num: 5842
iter_num: 2008, on_card_num: 46, preempted blk num: 5842
iter_num: 2009, on_card_num: 46, preempted blk num: 5842
iter_num: 2010, on_card_num: 46, preempted blk num: 5842
iter_num: 2011, on_card_num: 46, preempted blk num: 5842
iter_num: 2012, on_card_num: 46, preempted blk num: 5842
iter_num: 2013, on_card_num: 46, preempted blk num: 5842
iter_num: 2014, on_card_num: 45, preempted blk num: 5842
iter_num: 2015, on_card_num: 45, preempted blk num: 5842
iter_num: 2016, on_card_num: 45, preempted blk num: 5842
iter_num: 2017, on_card_num: 45, preempted blk num: 5842
iter_num: 2018, on_card_num: 44, preempted blk num: 5842
iter_num: 2019, on_card_num: 45, preempted blk num: 5842
iter_num: 2020, on_card_num: 48, preempted blk num: 5842
iter_num: 2021, on_card_num: 48, preempted blk num: 5842
iter_num: 2022, on_card_num: 48, preempted blk num: 5842
iter_num: 2023, on_card_num: 48, preempted blk num: 5842
iter_num: 2024, on_card_num: 48, preempted blk num: 5842
iter_num: 2025, on_card_num: 47, preempted blk num: 5842
iter_num: 2026, on_card_num: 46, preempted blk num: 5842
iter_num: 2027, on_card_num: 47, preempted blk num: 5842
iter_num: 2028, on_card_num: 48, preempted blk num: 5842
iter_num: 2029, on_card_num: 47, preempted blk num: 5842
iter_num: 2030, on_card_num: 47, preempted blk num: 5842
iter_num: 2031, on_card_num: 47, preempted blk num: 5842
iter_num: 2032, on_card_num: 47, preempted blk num: 5842
iter_num: 2033, on_card_num: 47, preempted blk num: 5842
iter_num: 2034, on_card_num: 47, preempted blk num: 5842
iter_num: 2035, on_card_num: 47, preempted blk num: 5842
iter_num: 2036, on_card_num: 47, preempted blk num: 5842
iter_num: 2037, on_card_num: 47, preempted blk num: 5842
iter_num: 2038, on_card_num: 47, preempted blk num: 5842
iter_num: 2039, on_card_num: 47, preempted blk num: 5842
iter_num: 2040, on_card_num: 47, preempted blk num: 5842
iter_num: 2041, on_card_num: 47, preempted blk num: 5842
to recompute 1: ('396', 52)
iter_num: 2042, on_card_num: 46, preempted blk num: 5850
to recompute 1: ('395', 980)
iter_num: 2043, on_card_num: 45, preempted blk num: 5974
iter_num: 2044, on_card_num: 45, preempted blk num: 5974
iter_num: 2045, on_card_num: 45, preempted blk num: 5974
iter_num: 2046, on_card_num: 45, preempted blk num: 5974
iter_num: 2047, on_card_num: 45, preempted blk num: 5974
iter_num: 2048, on_card_num: 44, preempted blk num: 5974
iter_num: 2049, on_card_num: 44, preempted blk num: 5974
iter_num: 2050, on_card_num: 43, preempted blk num: 5974
iter_num: 2051, on_card_num: 44, preempted blk num: 5974
iter_num: 2052, on_card_num: 45, preempted blk num: 5974
iter_num: 2053, on_card_num: 45, preempted blk num: 5974
iter_num: 2054, on_card_num: 45, preempted blk num: 5974
iter_num: 2055, on_card_num: 45, preempted blk num: 5974
iter_num: 2056, on_card_num: 45, preempted blk num: 5974
iter_num: 2057, on_card_num: 45, preempted blk num: 5974
iter_num: 2058, on_card_num: 45, preempted blk num: 5974
iter_num: 2059, on_card_num: 44, preempted blk num: 5974
iter_num: 2060, on_card_num: 44, preempted blk num: 5974
iter_num: 2061, on_card_num: 43, preempted blk num: 5974
iter_num: 2062, on_card_num: 45, preempted blk num: 5974
iter_num: 2063, on_card_num: 45, preempted blk num: 5974
iter_num: 2064, on_card_num: 45, preempted blk num: 5974
iter_num: 2065, on_card_num: 45, preempted blk num: 5974
iter_num: 2066, on_card_num: 45, preempted blk num: 5974
iter_num: 2067, on_card_num: 45, preempted blk num: 5974
iter_num: 2068, on_card_num: 43, preempted blk num: 5974
iter_num: 2069, on_card_num: 43, preempted blk num: 5974
iter_num: 2070, on_card_num: 43, preempted blk num: 5974
iter_num: 2071, on_card_num: 43, preempted blk num: 5974
iter_num: 2072, on_card_num: 43, preempted blk num: 5974
iter_num: 2073, on_card_num: 43, preempted blk num: 5974
iter_num: 2074, on_card_num: 43, preempted blk num: 5974
iter_num: 2075, on_card_num: 43, preempted blk num: 5974
iter_num: 2076, on_card_num: 43, preempted blk num: 5974
iter_num: 2077, on_card_num: 43, preempted blk num: 5974
iter_num: 2078, on_card_num: 42, preempted blk num: 5974
iter_num: 2079, on_card_num: 43, preempted blk num: 5974
iter_num: 2080, on_card_num: 45, preempted blk num: 5974
iter_num: 2081, on_card_num: 46, preempted blk num: 5974
iter_num: 2082, on_card_num: 45, preempted blk num: 5974
iter_num: 2083, on_card_num: 44, preempted blk num: 5974
iter_num: 2084, on_card_num: 45, preempted blk num: 5974
iter_num: 2085, on_card_num: 45, preempted blk num: 5974
iter_num: 2086, on_card_num: 45, preempted blk num: 5974
iter_num: 2087, on_card_num: 45, preempted blk num: 5974
iter_num: 2088, on_card_num: 45, preempted blk num: 5974
iter_num: 2089, on_card_num: 45, preempted blk num: 5974
iter_num: 2090, on_card_num: 45, preempted blk num: 5974
iter_num: 2091, on_card_num: 45, preempted blk num: 5974
iter_num: 2092, on_card_num: 45, preempted blk num: 5974
iter_num: 2093, on_card_num: 44, preempted blk num: 5974
iter_num: 2094, on_card_num: 44, preempted blk num: 5974
iter_num: 2095, on_card_num: 44, preempted blk num: 5974
to recompute 1: ('403', 530)
iter_num: 2096, on_card_num: 43, preempted blk num: 6042
iter_num: 2097, on_card_num: 42, preempted blk num: 6042
iter_num: 2098, on_card_num: 43, preempted blk num: 6042
iter_num: 2099, on_card_num: 43, preempted blk num: 6042
iter_num: 2100, on_card_num: 42, preempted blk num: 6042
iter_num: 2101, on_card_num: 43, preempted blk num: 6042
iter_num: 2102, on_card_num: 44, preempted blk num: 6042
iter_num: 2103, on_card_num: 44, preempted blk num: 6042
iter_num: 2104, on_card_num: 44, preempted blk num: 6042
iter_num: 2105, on_card_num: 44, preempted blk num: 6042
iter_num: 2106, on_card_num: 44, preempted blk num: 6042
iter_num: 2107, on_card_num: 43, preempted blk num: 6042
iter_num: 2108, on_card_num: 44, preempted blk num: 6042
iter_num: 2109, on_card_num: 44, preempted blk num: 6042
iter_num: 2110, on_card_num: 44, preempted blk num: 6042
iter_num: 2111, on_card_num: 44, preempted blk num: 6042
iter_num: 2112, on_card_num: 44, preempted blk num: 6042
iter_num: 2113, on_card_num: 44, preempted blk num: 6042
to recompute 1: ('406', 316)
iter_num: 2114, on_card_num: 43, preempted blk num: 6082
iter_num: 2115, on_card_num: 43, preempted blk num: 6082
iter_num: 2116, on_card_num: 43, preempted blk num: 6082
iter_num: 2117, on_card_num: 42, preempted blk num: 6082
iter_num: 2118, on_card_num: 45, preempted blk num: 6082
iter_num: 2119, on_card_num: 46, preempted blk num: 6082
iter_num: 2120, on_card_num: 46, preempted blk num: 6082
iter_num: 2121, on_card_num: 46, preempted blk num: 6082
iter_num: 2122, on_card_num: 44, preempted blk num: 6082
iter_num: 2123, on_card_num: 45, preempted blk num: 6082
iter_num: 2124, on_card_num: 45, preempted blk num: 6082
iter_num: 2125, on_card_num: 45, preempted blk num: 6082
iter_num: 2126, on_card_num: 45, preempted blk num: 6082
iter_num: 2127, on_card_num: 45, preempted blk num: 6082
iter_num: 2128, on_card_num: 44, preempted blk num: 6082
iter_num: 2129, on_card_num: 44, preempted blk num: 6082
iter_num: 2130, on_card_num: 44, preempted blk num: 6082
iter_num: 2131, on_card_num: 44, preempted blk num: 6082
iter_num: 2132, on_card_num: 44, preempted blk num: 6082
iter_num: 2133, on_card_num: 44, preempted blk num: 6082
iter_num: 2134, on_card_num: 44, preempted blk num: 6082
iter_num: 2135, on_card_num: 43, preempted blk num: 6082
iter_num: 2136, on_card_num: 43, preempted blk num: 6082
iter_num: 2137, on_card_num: 43, preempted blk num: 6082
iter_num: 2138, on_card_num: 43, preempted blk num: 6082
iter_num: 2139, on_card_num: 43, preempted blk num: 6082
iter_num: 2140, on_card_num: 43, preempted blk num: 6082
iter_num: 2141, on_card_num: 43, preempted blk num: 6082
iter_num: 2142, on_card_num: 43, preempted blk num: 6082
iter_num: 2143, on_card_num: 43, preempted blk num: 6082
iter_num: 2144, on_card_num: 43, preempted blk num: 6082
iter_num: 2145, on_card_num: 43, preempted blk num: 6082
to recompute 1: ('410', 484)
iter_num: 2146, on_card_num: 42, preempted blk num: 6144
iter_num: 2147, on_card_num: 42, preempted blk num: 6144
iter_num: 2148, on_card_num: 41, preempted blk num: 6144
iter_num: 2149, on_card_num: 42, preempted blk num: 6144
iter_num: 2150, on_card_num: 42, preempted blk num: 6144
iter_num: 2151, on_card_num: 42, preempted blk num: 6144
iter_num: 2152, on_card_num: 42, preempted blk num: 6144
iter_num: 2153, on_card_num: 42, preempted blk num: 6144
iter_num: 2154, on_card_num: 42, preempted blk num: 6144
iter_num: 2155, on_card_num: 41, preempted blk num: 6144
iter_num: 2156, on_card_num: 42, preempted blk num: 6144
iter_num: 2157, on_card_num: 43, preempted blk num: 6144
iter_num: 2158, on_card_num: 43, preempted blk num: 6144
iter_num: 2159, on_card_num: 43, preempted blk num: 6144
iter_num: 2160, on_card_num: 42, preempted blk num: 6144
iter_num: 2161, on_card_num: 44, preempted blk num: 6144
iter_num: 2162, on_card_num: 44, preempted blk num: 6144
iter_num: 2163, on_card_num: 44, preempted blk num: 6144
iter_num: 2164, on_card_num: 44, preempted blk num: 6144
iter_num: 2165, on_card_num: 43, preempted blk num: 6144
iter_num: 2166, on_card_num: 44, preempted blk num: 6144
iter_num: 2167, on_card_num: 44, preempted blk num: 6144
iter_num: 2168, on_card_num: 44, preempted blk num: 6144
iter_num: 2169, on_card_num: 44, preempted blk num: 6144
iter_num: 2170, on_card_num: 44, preempted blk num: 6144
iter_num: 2171, on_card_num: 44, preempted blk num: 6144
iter_num: 2172, on_card_num: 44, preempted blk num: 6144
iter_num: 2173, on_card_num: 43, preempted blk num: 6144
iter_num: 2174, on_card_num: 44, preempted blk num: 6144
iter_num: 2175, on_card_num: 45, preempted blk num: 6144
iter_num: 2176, on_card_num: 45, preempted blk num: 6144
iter_num: 2177, on_card_num: 45, preempted blk num: 6144
iter_num: 2178, on_card_num: 45, preempted blk num: 6144
iter_num: 2179, on_card_num: 43, preempted blk num: 6144
iter_num: 2180, on_card_num: 44, preempted blk num: 6144
iter_num: 2181, on_card_num: 45, preempted blk num: 6144
iter_num: 2182, on_card_num: 47, preempted blk num: 6144
iter_num: 2183, on_card_num: 47, preempted blk num: 6144
iter_num: 2184, on_card_num: 47, preempted blk num: 6144
iter_num: 2185, on_card_num: 46, preempted blk num: 6144
iter_num: 2186, on_card_num: 46, preempted blk num: 6144
iter_num: 2187, on_card_num: 46, preempted blk num: 6144
iter_num: 2188, on_card_num: 46, preempted blk num: 6144
iter_num: 2189, on_card_num: 46, preempted blk num: 6144
iter_num: 2190, on_card_num: 45, preempted blk num: 6144
iter_num: 2191, on_card_num: 46, preempted blk num: 6144
iter_num: 2192, on_card_num: 48, preempted blk num: 6144
iter_num: 2193, on_card_num: 49, preempted blk num: 6144
iter_num: 2194, on_card_num: 50, preempted blk num: 6144
iter_num: 2195, on_card_num: 50, preempted blk num: 6144
iter_num: 2196, on_card_num: 50, preempted blk num: 6144
iter_num: 2197, on_card_num: 50, preempted blk num: 6144
iter_num: 2198, on_card_num: 49, preempted blk num: 6144
iter_num: 2199, on_card_num: 50, preempted blk num: 6144
iter_num: 2200, on_card_num: 49, preempted blk num: 6144
iter_num: 2201, on_card_num: 50, preempted blk num: 6144
iter_num: 2202, on_card_num: 50, preempted blk num: 6144
iter_num: 2203, on_card_num: 50, preempted blk num: 6144
iter_num: 2204, on_card_num: 50, preempted blk num: 6144
iter_num: 2205, on_card_num: 50, preempted blk num: 6144
iter_num: 2206, on_card_num: 50, preempted blk num: 6144
iter_num: 2207, on_card_num: 50, preempted blk num: 6144
to recompute 1: ('428', 239)
iter_num: 2208, on_card_num: 49, preempted blk num: 6174
iter_num: 2209, on_card_num: 49, preempted blk num: 6174
iter_num: 2210, on_card_num: 49, preempted blk num: 6174
iter_num: 2211, on_card_num: 47, preempted blk num: 6174
iter_num: 2212, on_card_num: 49, preempted blk num: 6174
iter_num: 2213, on_card_num: 51, preempted blk num: 6174
iter_num: 2214, on_card_num: 51, preempted blk num: 6174
iter_num: 2215, on_card_num: 51, preempted blk num: 6174
iter_num: 2216, on_card_num: 51, preempted blk num: 6174
iter_num: 2217, on_card_num: 51, preempted blk num: 6174
iter_num: 2218, on_card_num: 51, preempted blk num: 6174
iter_num: 2219, on_card_num: 51, preempted blk num: 6174
iter_num: 2220, on_card_num: 51, preempted blk num: 6174
iter_num: 2221, on_card_num: 51, preempted blk num: 6174
iter_num: 2222, on_card_num: 50, preempted blk num: 6174
iter_num: 2223, on_card_num: 50, preempted blk num: 6174
iter_num: 2224, on_card_num: 50, preempted blk num: 6174
iter_num: 2225, on_card_num: 49, preempted blk num: 6174
iter_num: 2226, on_card_num: 49, preempted blk num: 6174
iter_num: 2227, on_card_num: 49, preempted blk num: 6174
iter_num: 2228, on_card_num: 48, preempted blk num: 6174
iter_num: 2229, on_card_num: 48, preempted blk num: 6174
iter_num: 2230, on_card_num: 48, preempted blk num: 6174
iter_num: 2231, on_card_num: 48, preempted blk num: 6174
iter_num: 2232, on_card_num: 48, preempted blk num: 6174
iter_num: 2233, on_card_num: 47, preempted blk num: 6174
iter_num: 2234, on_card_num: 46, preempted blk num: 6174
iter_num: 2235, on_card_num: 47, preempted blk num: 6174
iter_num: 2236, on_card_num: 47, preempted blk num: 6174
iter_num: 2237, on_card_num: 47, preempted blk num: 6174
iter_num: 2238, on_card_num: 47, preempted blk num: 6174
iter_num: 2239, on_card_num: 46, preempted blk num: 6174
iter_num: 2240, on_card_num: 46, preempted blk num: 6174
iter_num: 2241, on_card_num: 46, preempted blk num: 6174
iter_num: 2242, on_card_num: 46, preempted blk num: 6174
iter_num: 2243, on_card_num: 46, preempted blk num: 6174
iter_num: 2244, on_card_num: 46, preempted blk num: 6174
iter_num: 2245, on_card_num: 46, preempted blk num: 6174
iter_num: 2246, on_card_num: 46, preempted blk num: 6174
iter_num: 2247, on_card_num: 46, preempted blk num: 6174
iter_num: 2248, on_card_num: 46, preempted blk num: 6174
iter_num: 2249, on_card_num: 46, preempted blk num: 6174
iter_num: 2250, on_card_num: 46, preempted blk num: 6174
iter_num: 2251, on_card_num: 46, preempted blk num: 6174
iter_num: 2252, on_card_num: 46, preempted blk num: 6174
iter_num: 2253, on_card_num: 44, preempted blk num: 6174
iter_num: 2254, on_card_num: 45, preempted blk num: 6174
iter_num: 2255, on_card_num: 45, preempted blk num: 6174
iter_num: 2256, on_card_num: 45, preempted blk num: 6174
iter_num: 2257, on_card_num: 43, preempted blk num: 6174
iter_num: 2258, on_card_num: 45, preempted blk num: 6174
iter_num: 2259, on_card_num: 49, preempted blk num: 6174
iter_num: 2260, on_card_num: 50, preempted blk num: 6174
iter_num: 2261, on_card_num: 52, preempted blk num: 6174
iter_num: 2262, on_card_num: 52, preempted blk num: 6174
iter_num: 2263, on_card_num: 52, preempted blk num: 6174
iter_num: 2264, on_card_num: 52, preempted blk num: 6174
iter_num: 2265, on_card_num: 52, preempted blk num: 6174
iter_num: 2266, on_card_num: 52, preempted blk num: 6174
iter_num: 2267, on_card_num: 51, preempted blk num: 6174
iter_num: 2268, on_card_num: 51, preempted blk num: 6174
iter_num: 2269, on_card_num: 51, preempted blk num: 6174
iter_num: 2270, on_card_num: 51, preempted blk num: 6174
iter_num: 2271, on_card_num: 51, preempted blk num: 6174
iter_num: 2272, on_card_num: 51, preempted blk num: 6174
iter_num: 2273, on_card_num: 51, preempted blk num: 6174
iter_num: 2274, on_card_num: 51, preempted blk num: 6174
to recompute 1: ('442', 337)
iter_num: 2275, on_card_num: 50, preempted blk num: 6216
iter_num: 2276, on_card_num: 48, preempted blk num: 6216
iter_num: 2277, on_card_num: 49, preempted blk num: 6216
iter_num: 2278, on_card_num: 48, preempted blk num: 6216
iter_num: 2279, on_card_num: 48, preempted blk num: 6216
iter_num: 2280, on_card_num: 48, preempted blk num: 6216
iter_num: 2281, on_card_num: 47, preempted blk num: 6216
iter_num: 2282, on_card_num: 48, preempted blk num: 6216
iter_num: 2283, on_card_num: 50, preempted blk num: 6216
iter_num: 2284, on_card_num: 50, preempted blk num: 6216
iter_num: 2285, on_card_num: 50, preempted blk num: 6216
iter_num: 2286, on_card_num: 50, preempted blk num: 6216
iter_num: 2287, on_card_num: 50, preempted blk num: 6216
iter_num: 2288, on_card_num: 50, preempted blk num: 6216
iter_num: 2289, on_card_num: 50, preempted blk num: 6216
to recompute 1: ('445', 26)
iter_num: 2290, on_card_num: 49, preempted blk num: 6220
iter_num: 2291, on_card_num: 48, preempted blk num: 6220
iter_num: 2292, on_card_num: 49, preempted blk num: 6220
iter_num: 2293, on_card_num: 50, preempted blk num: 6220
iter_num: 2294, on_card_num: 53, preempted blk num: 6220
iter_num: 2295, on_card_num: 53, preempted blk num: 6220
iter_num: 2296, on_card_num: 52, preempted blk num: 6220
iter_num: 2297, on_card_num: 52, preempted blk num: 6220
iter_num: 2298, on_card_num: 52, preempted blk num: 6220
iter_num: 2299, on_card_num: 52, preempted blk num: 6220
iter_num: 2300, on_card_num: 52, preempted blk num: 6220
iter_num: 2301, on_card_num: 51, preempted blk num: 6220
iter_num: 2302, on_card_num: 50, preempted blk num: 6220
iter_num: 2303, on_card_num: 51, preempted blk num: 6220
iter_num: 2304, on_card_num: 55, preempted blk num: 6220
iter_num: 2305, on_card_num: 55, preempted blk num: 6220
iter_num: 2306, on_card_num: 55, preempted blk num: 6220
iter_num: 2307, on_card_num: 55, preempted blk num: 6220
iter_num: 2308, on_card_num: 55, preempted blk num: 6220
iter_num: 2309, on_card_num: 54, preempted blk num: 6220
iter_num: 2310, on_card_num: 53, preempted blk num: 6220
iter_num: 2311, on_card_num: 57, preempted blk num: 6220
iter_num: 2312, on_card_num: 57, preempted blk num: 6220
iter_num: 2313, on_card_num: 56, preempted blk num: 6220
iter_num: 2314, on_card_num: 56, preempted blk num: 6220
iter_num: 2315, on_card_num: 56, preempted blk num: 6220
iter_num: 2316, on_card_num: 56, preempted blk num: 6220
iter_num: 2317, on_card_num: 56, preempted blk num: 6220
to recompute 1: ('458', 43)
iter_num: 2318, on_card_num: 55, preempted blk num: 6226
to recompute 1: ('457', 16)
iter_num: 2319, on_card_num: 54, preempted blk num: 6228
to recompute 1: ('456', 26)
to recompute 1: ('455', 42)
iter_num: 2320, on_card_num: 51, preempted blk num: 6238
iter_num: 2321, on_card_num: 55, preempted blk num: 6238
iter_num: 2322, on_card_num: 55, preempted blk num: 6238
iter_num: 2323, on_card_num: 55, preempted blk num: 6238
iter_num: 2324, on_card_num: 55, preempted blk num: 6238
iter_num: 2325, on_card_num: 55, preempted blk num: 6238
iter_num: 2326, on_card_num: 54, preempted blk num: 6238
iter_num: 2327, on_card_num: 53, preempted blk num: 6238
iter_num: 2328, on_card_num: 54, preempted blk num: 6238
iter_num: 2329, on_card_num: 55, preempted blk num: 6238
iter_num: 2330, on_card_num: 57, preempted blk num: 6238
iter_num: 2331, on_card_num: 57, preempted blk num: 6238
iter_num: 2332, on_card_num: 57, preempted blk num: 6238
iter_num: 2333, on_card_num: 57, preempted blk num: 6238
iter_num: 2334, on_card_num: 57, preempted blk num: 6238
iter_num: 2335, on_card_num: 56, preempted blk num: 6238
iter_num: 2336, on_card_num: 55, preempted blk num: 6238
iter_num: 2337, on_card_num: 57, preempted blk num: 6238
iter_num: 2338, on_card_num: 58, preempted blk num: 6238
iter_num: 2339, on_card_num: 58, preempted blk num: 6238
iter_num: 2340, on_card_num: 58, preempted blk num: 6238
iter_num: 2341, on_card_num: 58, preempted blk num: 6238
iter_num: 2342, on_card_num: 58, preempted blk num: 6238
to recompute 1: ('465', 99)
iter_num: 2343, on_card_num: 55, preempted blk num: 6252
iter_num: 2344, on_card_num: 56, preempted blk num: 6252
iter_num: 2345, on_card_num: 57, preempted blk num: 6252
iter_num: 2346, on_card_num: 59, preempted blk num: 6252
iter_num: 2347, on_card_num: 60, preempted blk num: 6252
iter_num: 2348, on_card_num: 58, preempted blk num: 6252
iter_num: 2349, on_card_num: 60, preempted blk num: 6252
iter_num: 2350, on_card_num: 66, preempted blk num: 6252
iter_num: 2351, on_card_num: 67, preempted blk num: 6252
iter_num: 2352, on_card_num: 68, preempted blk num: 6252
iter_num: 2353, on_card_num: 68, preempted blk num: 6252
iter_num: 2354, on_card_num: 66, preempted blk num: 6252
iter_num: 2355, on_card_num: 69, preempted blk num: 6252
iter_num: 2356, on_card_num: 70, preempted blk num: 6252
iter_num: 2357, on_card_num: 70, preempted blk num: 6252
iter_num: 2358, on_card_num: 69, preempted blk num: 6252
iter_num: 2359, on_card_num: 70, preempted blk num: 6252
iter_num: 2360, on_card_num: 70, preempted blk num: 6252
iter_num: 2361, on_card_num: 69, preempted blk num: 6252
iter_num: 2362, on_card_num: 72, preempted blk num: 6252
iter_num: 2363, on_card_num: 73, preempted blk num: 6252
iter_num: 2364, on_card_num: 74, preempted blk num: 6252
iter_num: 2365, on_card_num: 74, preempted blk num: 6252
iter_num: 2366, on_card_num: 74, preempted blk num: 6252
iter_num: 2367, on_card_num: 74, preempted blk num: 6252
iter_num: 2368, on_card_num: 74, preempted blk num: 6252
iter_num: 2369, on_card_num: 74, preempted blk num: 6252
iter_num: 2370, on_card_num: 74, preempted blk num: 6252
to recompute 1: ('489', 23)
to recompute 1: ('488', 507)
iter_num: 2371, on_card_num: 72, preempted blk num: 6320
iter_num: 2372, on_card_num: 72, preempted blk num: 6320
iter_num: 2373, on_card_num: 72, preempted blk num: 6320
iter_num: 2374, on_card_num: 71, preempted blk num: 6320
iter_num: 2375, on_card_num: 72, preempted blk num: 6320
iter_num: 2376, on_card_num: 73, preempted blk num: 6320
iter_num: 2377, on_card_num: 74, preempted blk num: 6320
iter_num: 2378, on_card_num: 74, preempted blk num: 6320
iter_num: 2379, on_card_num: 74, preempted blk num: 6320
iter_num: 2380, on_card_num: 73, preempted blk num: 6320
iter_num: 2381, on_card_num: 73, preempted blk num: 6320
iter_num: 2382, on_card_num: 72, preempted blk num: 6320
iter_num: 2383, on_card_num: 73, preempted blk num: 6320
iter_num: 2384, on_card_num: 72, preempted blk num: 6320
iter_num: 2385, on_card_num: 73, preempted blk num: 6320
iter_num: 2386, on_card_num: 72, preempted blk num: 6320
iter_num: 2387, on_card_num: 72, preempted blk num: 6320
iter_num: 2388, on_card_num: 70, preempted blk num: 6320
iter_num: 2389, on_card_num: 71, preempted blk num: 6320
iter_num: 2390, on_card_num: 70, preempted blk num: 6320
iter_num: 2391, on_card_num: 70, preempted blk num: 6320
iter_num: 2392, on_card_num: 70, preempted blk num: 6320
iter_num: 2393, on_card_num: 69, preempted blk num: 6320
iter_num: 2394, on_card_num: 70, preempted blk num: 6320
iter_num: 2395, on_card_num: 70, preempted blk num: 6320
iter_num: 2396, on_card_num: 70, preempted blk num: 6320
iter_num: 2397, on_card_num: 70, preempted blk num: 6320
iter_num: 2398, on_card_num: 70, preempted blk num: 6320
iter_num: 2399, on_card_num: 70, preempted blk num: 6320
to recompute 1: ('494', 348)
iter_num: 2400, on_card_num: 69, preempted blk num: 6364
iter_num: 2401, on_card_num: 69, preempted blk num: 6364
iter_num: 2402, on_card_num: 69, preempted blk num: 6364
iter_num: 2403, on_card_num: 69, preempted blk num: 6364
iter_num: 2404, on_card_num: 69, preempted blk num: 6364
iter_num: 2405, on_card_num: 69, preempted blk num: 6364
to recompute 1: ('493', 684)
iter_num: 2406, on_card_num: 68, preempted blk num: 6450
iter_num: 2407, on_card_num: 67, preempted blk num: 6450
iter_num: 2408, on_card_num: 67, preempted blk num: 6450
iter_num: 2409, on_card_num: 67, preempted blk num: 6450
iter_num: 2410, on_card_num: 66, preempted blk num: 6450
iter_num: 2411, on_card_num: 67, preempted blk num: 6450
iter_num: 2412, on_card_num: 67, preempted blk num: 6450
iter_num: 2413, on_card_num: 67, preempted blk num: 6450
iter_num: 2414, on_card_num: 66, preempted blk num: 6450
iter_num: 2415, on_card_num: 66, preempted blk num: 6450
iter_num: 2416, on_card_num: 65, preempted blk num: 6450
iter_num: 2417, on_card_num: 67, preempted blk num: 6450
iter_num: 2418, on_card_num: 69, preempted blk num: 6450
iter_num: 2419, on_card_num: 69, preempted blk num: 6450
iter_num: 2420, on_card_num: 69, preempted blk num: 6450
iter_num: 2421, on_card_num: 69, preempted blk num: 6450
iter_num: 2422, on_card_num: 68, preempted blk num: 6450
iter_num: 2423, on_card_num: 70, preempted blk num: 6450
iter_num: 2424, on_card_num: 70, preempted blk num: 6450
iter_num: 2425, on_card_num: 70, preempted blk num: 6450
iter_num: 2426, on_card_num: 69, preempted blk num: 6450
iter_num: 2427, on_card_num: 69, preempted blk num: 6450
iter_num: 2428, on_card_num: 69, preempted blk num: 6450
iter_num: 2429, on_card_num: 69, preempted blk num: 6450
iter_num: 2430, on_card_num: 67, preempted blk num: 6450
iter_num: 2431, on_card_num: 68, preempted blk num: 6450
iter_num: 2432, on_card_num: 69, preempted blk num: 6450
iter_num: 2433, on_card_num: 69, preempted blk num: 6450
iter_num: 2434, on_card_num: 69, preempted blk num: 6450
iter_num: 2435, on_card_num: 69, preempted blk num: 6450
to recompute 1: ('501', 22)
iter_num: 2436, on_card_num: 67, preempted blk num: 6454
iter_num: 2437, on_card_num: 68, preempted blk num: 6454
iter_num: 2438, on_card_num: 67, preempted blk num: 6454
iter_num: 2439, on_card_num: 68, preempted blk num: 6454
iter_num: 2440, on_card_num: 68, preempted blk num: 6454
iter_num: 2441, on_card_num: 68, preempted blk num: 6454
iter_num: 2442, on_card_num: 68, preempted blk num: 6454
iter_num: 2443, on_card_num: 68, preempted blk num: 6454
to recompute 1: ('502', 258)
iter_num: 2444, on_card_num: 66, preempted blk num: 6488
iter_num: 2445, on_card_num: 67, preempted blk num: 6488
iter_num: 2446, on_card_num: 66, preempted blk num: 6488
iter_num: 2447, on_card_num: 68, preempted blk num: 6488
iter_num: 2448, on_card_num: 68, preempted blk num: 6488
iter_num: 2449, on_card_num: 68, preempted blk num: 6488
iter_num: 2450, on_card_num: 68, preempted blk num: 6488
iter_num: 2451, on_card_num: 68, preempted blk num: 6488
iter_num: 2452, on_card_num: 68, preempted blk num: 6488
iter_num: 2453, on_card_num: 68, preempted blk num: 6488
iter_num: 2454, on_card_num: 68, preempted blk num: 6488
to recompute 2: ('504', 19)
iter_num: 2455, on_card_num: 67, preempted blk num: 6492
to recompute 1: ('503', 82)
iter_num: 2456, on_card_num: 66, preempted blk num: 6504
to recompute 1: ('502', 269)
iter_num: 2457, on_card_num: 65, preempted blk num: 6538
iter_num: 2458, on_card_num: 65, preempted blk num: 6538
iter_num: 2459, on_card_num: 65, preempted blk num: 6538
iter_num: 2460, on_card_num: 65, preempted blk num: 6538
iter_num: 2461, on_card_num: 65, preempted blk num: 6538
iter_num: 2462, on_card_num: 65, preempted blk num: 6538
to recompute 1: ('501', 45)
to recompute 1: ('500', 861)
iter_num: 2463, on_card_num: 62, preempted blk num: 6652
iter_num: 2464, on_card_num: 63, preempted blk num: 6652
iter_num: 2465, on_card_num: 65, preempted blk num: 6652
iter_num: 2466, on_card_num: 67, preempted blk num: 6652
iter_num: 2467, on_card_num: 67, preempted blk num: 6652
iter_num: 2468, on_card_num: 67, preempted blk num: 6652
iter_num: 2469, on_card_num: 67, preempted blk num: 6652
iter_num: 2470, on_card_num: 67, preempted blk num: 6652
iter_num: 2471, on_card_num: 66, preempted blk num: 6652
iter_num: 2472, on_card_num: 66, preempted blk num: 6652
iter_num: 2473, on_card_num: 66, preempted blk num: 6652
iter_num: 2474, on_card_num: 66, preempted blk num: 6652
iter_num: 2475, on_card_num: 66, preempted blk num: 6652
to recompute 1: ('504', 29)
iter_num: 2476, on_card_num: 65, preempted blk num: 6656
to recompute 1: ('503', 93)
iter_num: 2477, on_card_num: 63, preempted blk num: 6668
iter_num: 2478, on_card_num: 65, preempted blk num: 6668
iter_num: 2479, on_card_num: 65, preempted blk num: 6668
iter_num: 2480, on_card_num: 65, preempted blk num: 6668
iter_num: 2481, on_card_num: 64, preempted blk num: 6668
iter_num: 2482, on_card_num: 64, preempted blk num: 6668
iter_num: 2483, on_card_num: 64, preempted blk num: 6668
to recompute 1: ('504', 35)
iter_num: 2484, on_card_num: 63, preempted blk num: 6674
to recompute 1: ('503', 100)
iter_num: 2485, on_card_num: 62, preempted blk num: 6688
to recompute 1: ('501', 64)
iter_num: 2486, on_card_num: 61, preempted blk num: 6696
to recompute 1: ('500', 881)
iter_num: 2487, on_card_num: 60, preempted blk num: 6806
iter_num: 2488, on_card_num: 60, preempted blk num: 6806
iter_num: 2489, on_card_num: 60, preempted blk num: 6806
iter_num: 2490, on_card_num: 59, preempted blk num: 6806
iter_num: 2491, on_card_num: 59, preempted blk num: 6806
iter_num: 2492, on_card_num: 59, preempted blk num: 6806
iter_num: 2493, on_card_num: 59, preempted blk num: 6806
iter_num: 2494, on_card_num: 58, preempted blk num: 6806
iter_num: 2495, on_card_num: 59, preempted blk num: 6806
iter_num: 2496, on_card_num: 60, preempted blk num: 6806
iter_num: 2497, on_card_num: 60, preempted blk num: 6806
iter_num: 2498, on_card_num: 60, preempted blk num: 6806
iter_num: 2499, on_card_num: 60, preempted blk num: 6806
iter_num: 2500, on_card_num: 59, preempted blk num: 6806
iter_num: 2501, on_card_num: 61, preempted blk num: 6806
iter_num: 2502, on_card_num: 61, preempted blk num: 6806
iter_num: 2503, on_card_num: 61, preempted blk num: 6806
to recompute 1: ('504', 38)
iter_num: 2504, on_card_num: 59, preempted blk num: 6812
iter_num: 2505, on_card_num: 59, preempted blk num: 6812
iter_num: 2506, on_card_num: 59, preempted blk num: 6812
iter_num: 2507, on_card_num: 59, preempted blk num: 6812
iter_num: 2508, on_card_num: 59, preempted blk num: 6812
to recompute 1: ('503', 108)
to recompute 1: ('501', 76)
iter_num: 2509, on_card_num: 57, preempted blk num: 6836
iter_num: 2510, on_card_num: 57, preempted blk num: 6836
to recompute 1: ('500', 895)
iter_num: 2511, on_card_num: 56, preempted blk num: 6948
iter_num: 2512, on_card_num: 56, preempted blk num: 6948
iter_num: 2513, on_card_num: 56, preempted blk num: 6948
iter_num: 2514, on_card_num: 56, preempted blk num: 6948
iter_num: 2515, on_card_num: 56, preempted blk num: 6948
iter_num: 2516, on_card_num: 54, preempted blk num: 6948
iter_num: 2517, on_card_num: 55, preempted blk num: 6948
iter_num: 2518, on_card_num: 56, preempted blk num: 6948
iter_num: 2519, on_card_num: 56, preempted blk num: 6948
iter_num: 2520, on_card_num: 56, preempted blk num: 6948
iter_num: 2521, on_card_num: 56, preempted blk num: 6948
to recompute 1: ('501', 80)
iter_num: 2522, on_card_num: 55, preempted blk num: 6958
iter_num: 2523, on_card_num: 55, preempted blk num: 6958
to recompute 1: ('500', 901)
iter_num: 2524, on_card_num: 53, preempted blk num: 7072
iter_num: 2525, on_card_num: 54, preempted blk num: 7072
iter_num: 2526, on_card_num: 54, preempted blk num: 7072
iter_num: 2527, on_card_num: 54, preempted blk num: 7072
iter_num: 2528, on_card_num: 54, preempted blk num: 7072
iter_num: 2529, on_card_num: 54, preempted blk num: 7072
to recompute 1: ('500', 906)
iter_num: 2530, on_card_num: 50, preempted blk num: 7186
iter_num: 2531, on_card_num: 51, preempted blk num: 7186
iter_num: 2532, on_card_num: 54, preempted blk num: 7186
iter_num: 2533, on_card_num: 54, preempted blk num: 7186
iter_num: 2534, on_card_num: 54, preempted blk num: 7186
iter_num: 2535, on_card_num: 54, preempted blk num: 7186
iter_num: 2536, on_card_num: 54, preempted blk num: 7186
iter_num: 2537, on_card_num: 54, preempted blk num: 7186
iter_num: 2538, on_card_num: 54, preempted blk num: 7186
iter_num: 2539, on_card_num: 54, preempted blk num: 7186
iter_num: 2540, on_card_num: 54, preempted blk num: 7186
iter_num: 2541, on_card_num: 54, preempted blk num: 7186
to recompute 1: ('504', 48)
iter_num: 2542, on_card_num: 53, preempted blk num: 7192
iter_num: 2543, on_card_num: 53, preempted blk num: 7192
to recompute 1: ('503', 120)
iter_num: 2544, on_card_num: 52, preempted blk num: 7208
iter_num: 2545, on_card_num: 52, preempted blk num: 7208
to recompute 1: ('501', 94)
iter_num: 2546, on_card_num: 51, preempted blk num: 7220
iter_num: 2547, on_card_num: 51, preempted blk num: 7220
to recompute 1: ('500', 922)
iter_num: 2548, on_card_num: 50, preempted blk num: 7336
iter_num: 2549, on_card_num: 50, preempted blk num: 7336
iter_num: 2550, on_card_num: 50, preempted blk num: 7336
iter_num: 2551, on_card_num: 50, preempted blk num: 7336
iter_num: 2552, on_card_num: 50, preempted blk num: 7336
iter_num: 2553, on_card_num: 50, preempted blk num: 7336
iter_num: 2554, on_card_num: 50, preempted blk num: 7336
iter_num: 2555, on_card_num: 50, preempted blk num: 7336
iter_num: 2556, on_card_num: 50, preempted blk num: 7336
iter_num: 2557, on_card_num: 50, preempted blk num: 7336
iter_num: 2558, on_card_num: 50, preempted blk num: 7336
iter_num: 2559, on_card_num: 50, preempted blk num: 7336
iter_num: 2560, on_card_num: 49, preempted blk num: 7336
iter_num: 2561, on_card_num: 49, preempted blk num: 7336
iter_num: 2562, on_card_num: 49, preempted blk num: 7336
iter_num: 2563, on_card_num: 49, preempted blk num: 7336
iter_num: 2564, on_card_num: 49, preempted blk num: 7336
iter_num: 2565, on_card_num: 49, preempted blk num: 7336
iter_num: 2566, on_card_num: 49, preempted blk num: 7336
iter_num: 2567, on_card_num: 49, preempted blk num: 7336
iter_num: 2568, on_card_num: 49, preempted blk num: 7336
iter_num: 2569, on_card_num: 49, preempted blk num: 7336
iter_num: 2570, on_card_num: 49, preempted blk num: 7336
iter_num: 2571, on_card_num: 48, preempted blk num: 7336
iter_num: 2572, on_card_num: 48, preempted blk num: 7336
iter_num: 2573, on_card_num: 48, preempted blk num: 7336
iter_num: 2574, on_card_num: 48, preempted blk num: 7336
iter_num: 2575, on_card_num: 48, preempted blk num: 7336
iter_num: 2576, on_card_num: 48, preempted blk num: 7336
iter_num: 2577, on_card_num: 47, preempted blk num: 7336
iter_num: 2578, on_card_num: 48, preempted blk num: 7336
iter_num: 2579, on_card_num: 49, preempted blk num: 7336
iter_num: 2580, on_card_num: 49, preempted blk num: 7336
iter_num: 2581, on_card_num: 49, preempted blk num: 7336
iter_num: 2582, on_card_num: 49, preempted blk num: 7336
iter_num: 2583, on_card_num: 49, preempted blk num: 7336
iter_num: 2584, on_card_num: 49, preempted blk num: 7336
to recompute 1: ('501', 100)
iter_num: 2585, on_card_num: 47, preempted blk num: 7350
iter_num: 2586, on_card_num: 48, preempted blk num: 7350
iter_num: 2587, on_card_num: 48, preempted blk num: 7350
iter_num: 2588, on_card_num: 48, preempted blk num: 7350
iter_num: 2589, on_card_num: 48, preempted blk num: 7350
iter_num: 2590, on_card_num: 48, preempted blk num: 7350
to recompute 1: ('501', 105)
iter_num: 2591, on_card_num: 47, preempted blk num: 7364
iter_num: 2592, on_card_num: 47, preempted blk num: 7364
to recompute 1: ('500', 935)
iter_num: 2593, on_card_num: 46, preempted blk num: 7482
iter_num: 2594, on_card_num: 46, preempted blk num: 7482
iter_num: 2595, on_card_num: 46, preempted blk num: 7482
iter_num: 2596, on_card_num: 46, preempted blk num: 7482
iter_num: 2597, on_card_num: 46, preempted blk num: 7482
iter_num: 2598, on_card_num: 45, preempted blk num: 7482
iter_num: 2599, on_card_num: 44, preempted blk num: 7482
iter_num: 2600, on_card_num: 44, preempted blk num: 7482
iter_num: 2601, on_card_num: 44, preempted blk num: 7482
iter_num: 2602, on_card_num: 44, preempted blk num: 7482
iter_num: 2603, on_card_num: 44, preempted blk num: 7482
iter_num: 2604, on_card_num: 44, preempted blk num: 7482
iter_num: 2605, on_card_num: 44, preempted blk num: 7482
iter_num: 2606, on_card_num: 44, preempted blk num: 7482
iter_num: 2607, on_card_num: 43, preempted blk num: 7482
iter_num: 2608, on_card_num: 44, preempted blk num: 7482
iter_num: 2609, on_card_num: 44, preempted blk num: 7482
iter_num: 2610, on_card_num: 44, preempted blk num: 7482
iter_num: 2611, on_card_num: 44, preempted blk num: 7482
iter_num: 2612, on_card_num: 44, preempted blk num: 7482
iter_num: 2613, on_card_num: 44, preempted blk num: 7482
to recompute 1: ('500', 941)
iter_num: 2614, on_card_num: 43, preempted blk num: 7600
iter_num: 2615, on_card_num: 43, preempted blk num: 7600
iter_num: 2616, on_card_num: 43, preempted blk num: 7600
iter_num: 2617, on_card_num: 42, preempted blk num: 7600
iter_num: 2618, on_card_num: 43, preempted blk num: 7600
iter_num: 2619, on_card_num: 46, preempted blk num: 7600
iter_num: 2620, on_card_num: 46, preempted blk num: 7600
iter_num: 2621, on_card_num: 46, preempted blk num: 7600
iter_num: 2622, on_card_num: 46, preempted blk num: 7600
iter_num: 2623, on_card_num: 46, preempted blk num: 7600
iter_num: 2624, on_card_num: 46, preempted blk num: 7600
iter_num: 2625, on_card_num: 45, preempted blk num: 7600
iter_num: 2626, on_card_num: 46, preempted blk num: 7600
iter_num: 2627, on_card_num: 49, preempted blk num: 7600
iter_num: 2628, on_card_num: 49, preempted blk num: 7600
iter_num: 2629, on_card_num: 49, preempted blk num: 7600
iter_num: 2630, on_card_num: 49, preempted blk num: 7600
iter_num: 2631, on_card_num: 49, preempted blk num: 7600
to recompute 1: ('508', 31)
iter_num: 2632, on_card_num: 47, preempted blk num: 7604
iter_num: 2633, on_card_num: 49, preempted blk num: 7604
iter_num: 2634, on_card_num: 50, preempted blk num: 7604
iter_num: 2635, on_card_num: 52, preempted blk num: 7604
iter_num: 2636, on_card_num: 51, preempted blk num: 7604
iter_num: 2637, on_card_num: 52, preempted blk num: 7604
iter_num: 2638, on_card_num: 54, preempted blk num: 7604
iter_num: 2639, on_card_num: 54, preempted blk num: 7604
iter_num: 2640, on_card_num: 54, preempted blk num: 7604
iter_num: 2641, on_card_num: 54, preempted blk num: 7604
iter_num: 2642, on_card_num: 54, preempted blk num: 7604
iter_num: 2643, on_card_num: 52, preempted blk num: 7604
iter_num: 2644, on_card_num: 51, preempted blk num: 7604
iter_num: 2645, on_card_num: 52, preempted blk num: 7604
iter_num: 2646, on_card_num: 51, preempted blk num: 7604
iter_num: 2647, on_card_num: 52, preempted blk num: 7604
iter_num: 2648, on_card_num: 54, preempted blk num: 7604
iter_num: 2649, on_card_num: 54, preempted blk num: 7604
iter_num: 2650, on_card_num: 54, preempted blk num: 7604
iter_num: 2651, on_card_num: 54, preempted blk num: 7604
iter_num: 2652, on_card_num: 53, preempted blk num: 7604
iter_num: 2653, on_card_num: 53, preempted blk num: 7604
iter_num: 2654, on_card_num: 53, preempted blk num: 7604
iter_num: 2655, on_card_num: 53, preempted blk num: 7604
iter_num: 2656, on_card_num: 53, preempted blk num: 7604
iter_num: 2657, on_card_num: 53, preempted blk num: 7604
iter_num: 2658, on_card_num: 53, preempted blk num: 7604
iter_num: 2659, on_card_num: 52, preempted blk num: 7604
iter_num: 2660, on_card_num: 53, preempted blk num: 7604
iter_num: 2661, on_card_num: 56, preempted blk num: 7604
iter_num: 2662, on_card_num: 55, preempted blk num: 7604
iter_num: 2663, on_card_num: 56, preempted blk num: 7604
iter_num: 2664, on_card_num: 57, preempted blk num: 7604
iter_num: 2665, on_card_num: 56, preempted blk num: 7604
iter_num: 2666, on_card_num: 56, preempted blk num: 7604
iter_num: 2667, on_card_num: 56, preempted blk num: 7604
iter_num: 2668, on_card_num: 56, preempted blk num: 7604
iter_num: 2669, on_card_num: 55, preempted blk num: 7604
iter_num: 2670, on_card_num: 56, preempted blk num: 7604
iter_num: 2671, on_card_num: 56, preempted blk num: 7604
iter_num: 2672, on_card_num: 56, preempted blk num: 7604
iter_num: 2673, on_card_num: 56, preempted blk num: 7604
iter_num: 2674, on_card_num: 56, preempted blk num: 7604
to recompute 1: ('526', 463)
iter_num: 2675, on_card_num: 55, preempted blk num: 7662
iter_num: 2676, on_card_num: 55, preempted blk num: 7662
iter_num: 2677, on_card_num: 55, preempted blk num: 7662
iter_num: 2678, on_card_num: 55, preempted blk num: 7662
iter_num: 2679, on_card_num: 55, preempted blk num: 7662
iter_num: 2680, on_card_num: 55, preempted blk num: 7662
iter_num: 2681, on_card_num: 55, preempted blk num: 7662
iter_num: 2682, on_card_num: 55, preempted blk num: 7662
to recompute 1: ('525', 62)
iter_num: 2683, on_card_num: 54, preempted blk num: 7670
iter_num: 2684, on_card_num: 54, preempted blk num: 7670
to recompute 1: ('524', 452)
iter_num: 2685, on_card_num: 53, preempted blk num: 7728
iter_num: 2686, on_card_num: 53, preempted blk num: 7728
iter_num: 2687, on_card_num: 51, preempted blk num: 7728
iter_num: 2688, on_card_num: 52, preempted blk num: 7728
iter_num: 2689, on_card_num: 53, preempted blk num: 7728
iter_num: 2690, on_card_num: 53, preempted blk num: 7728
iter_num: 2691, on_card_num: 53, preempted blk num: 7728
iter_num: 2692, on_card_num: 52, preempted blk num: 7728
iter_num: 2693, on_card_num: 53, preempted blk num: 7728
iter_num: 2694, on_card_num: 53, preempted blk num: 7728
iter_num: 2695, on_card_num: 53, preempted blk num: 7728
iter_num: 2696, on_card_num: 52, preempted blk num: 7728
iter_num: 2697, on_card_num: 54, preempted blk num: 7728
iter_num: 2698, on_card_num: 58, preempted blk num: 7728
iter_num: 2699, on_card_num: 58, preempted blk num: 7728
iter_num: 2700, on_card_num: 57, preempted blk num: 7728
iter_num: 2701, on_card_num: 57, preempted blk num: 7728
iter_num: 2702, on_card_num: 57, preempted blk num: 7728
iter_num: 2703, on_card_num: 57, preempted blk num: 7728
iter_num: 2704, on_card_num: 55, preempted blk num: 7728
iter_num: 2705, on_card_num: 54, preempted blk num: 7728
iter_num: 2706, on_card_num: 55, preempted blk num: 7728
iter_num: 2707, on_card_num: 55, preempted blk num: 7728
iter_num: 2708, on_card_num: 55, preempted blk num: 7728
iter_num: 2709, on_card_num: 55, preempted blk num: 7728
iter_num: 2710, on_card_num: 55, preempted blk num: 7728
to recompute 1: ('533', 1021)
iter_num: 2711, on_card_num: 54, preempted blk num: 7856
iter_num: 2712, on_card_num: 54, preempted blk num: 7856
iter_num: 2713, on_card_num: 54, preempted blk num: 7856
iter_num: 2714, on_card_num: 54, preempted blk num: 7856
iter_num: 2715, on_card_num: 53, preempted blk num: 7856
iter_num: 2716, on_card_num: 54, preempted blk num: 7856
iter_num: 2717, on_card_num: 57, preempted blk num: 7856
iter_num: 2718, on_card_num: 56, preempted blk num: 7856
iter_num: 2719, on_card_num: 58, preempted blk num: 7856
iter_num: 2720, on_card_num: 58, preempted blk num: 7856
iter_num: 2721, on_card_num: 58, preempted blk num: 7856
iter_num: 2722, on_card_num: 58, preempted blk num: 7856
iter_num: 2723, on_card_num: 57, preempted blk num: 7856
iter_num: 2724, on_card_num: 58, preempted blk num: 7856
iter_num: 2725, on_card_num: 59, preempted blk num: 7856
iter_num: 2726, on_card_num: 59, preempted blk num: 7856
iter_num: 2727, on_card_num: 57, preempted blk num: 7856
iter_num: 2728, on_card_num: 59, preempted blk num: 7856
iter_num: 2729, on_card_num: 60, preempted blk num: 7856
iter_num: 2730, on_card_num: 62, preempted blk num: 7856
iter_num: 2731, on_card_num: 64, preempted blk num: 7856
iter_num: 2732, on_card_num: 64, preempted blk num: 7856
iter_num: 2733, on_card_num: 64, preempted blk num: 7856
iter_num: 2734, on_card_num: 64, preempted blk num: 7856
iter_num: 2735, on_card_num: 64, preempted blk num: 7856
iter_num: 2736, on_card_num: 63, preempted blk num: 7856
iter_num: 2737, on_card_num: 64, preempted blk num: 7856
iter_num: 2738, on_card_num: 63, preempted blk num: 7856
iter_num: 2739, on_card_num: 63, preempted blk num: 7856
iter_num: 2740, on_card_num: 63, preempted blk num: 7856
iter_num: 2741, on_card_num: 63, preempted blk num: 7856
iter_num: 2742, on_card_num: 63, preempted blk num: 7856
iter_num: 2743, on_card_num: 63, preempted blk num: 7856
to recompute 1: ('548', 391)
iter_num: 2744, on_card_num: 61, preempted blk num: 7906
iter_num: 2745, on_card_num: 62, preempted blk num: 7906
iter_num: 2746, on_card_num: 62, preempted blk num: 7906
iter_num: 2747, on_card_num: 62, preempted blk num: 7906
iter_num: 2748, on_card_num: 61, preempted blk num: 7906
iter_num: 2749, on_card_num: 61, preempted blk num: 7906
iter_num: 2750, on_card_num: 61, preempted blk num: 7906
iter_num: 2751, on_card_num: 61, preempted blk num: 7906
to recompute 1: ('548', 398)
iter_num: 2752, on_card_num: 60, preempted blk num: 7956
iter_num: 2753, on_card_num: 60, preempted blk num: 7956
iter_num: 2754, on_card_num: 60, preempted blk num: 7956
iter_num: 2755, on_card_num: 60, preempted blk num: 7956
iter_num: 2756, on_card_num: 60, preempted blk num: 7956
iter_num: 2757, on_card_num: 60, preempted blk num: 7956
iter_num: 2758, on_card_num: 59, preempted blk num: 7956
iter_num: 2759, on_card_num: 58, preempted blk num: 7956
iter_num: 2760, on_card_num: 59, preempted blk num: 7956
iter_num: 2761, on_card_num: 58, preempted blk num: 7956
iter_num: 2762, on_card_num: 59, preempted blk num: 7956
iter_num: 2763, on_card_num: 60, preempted blk num: 7956
iter_num: 2764, on_card_num: 59, preempted blk num: 7956
iter_num: 2765, on_card_num: 59, preempted blk num: 7956
iter_num: 2766, on_card_num: 59, preempted blk num: 7956
iter_num: 2767, on_card_num: 59, preempted blk num: 7956
iter_num: 2768, on_card_num: 59, preempted blk num: 7956
iter_num: 2769, on_card_num: 58, preempted blk num: 7956
iter_num: 2770, on_card_num: 58, preempted blk num: 7956
iter_num: 2771, on_card_num: 58, preempted blk num: 7956
iter_num: 2772, on_card_num: 58, preempted blk num: 7956
iter_num: 2773, on_card_num: 58, preempted blk num: 7956
iter_num: 2774, on_card_num: 58, preempted blk num: 7956
iter_num: 2775, on_card_num: 58, preempted blk num: 7956
iter_num: 2776, on_card_num: 58, preempted blk num: 7956
iter_num: 2777, on_card_num: 58, preempted blk num: 7956
iter_num: 2778, on_card_num: 57, preempted blk num: 7956
iter_num: 2779, on_card_num: 57, preempted blk num: 7956
iter_num: 2780, on_card_num: 56, preempted blk num: 7956
iter_num: 2781, on_card_num: 57, preempted blk num: 7956
iter_num: 2782, on_card_num: 58, preempted blk num: 7956
iter_num: 2783, on_card_num: 60, preempted blk num: 7956
iter_num: 2784, on_card_num: 60, preempted blk num: 7956
iter_num: 2785, on_card_num: 60, preempted blk num: 7956
iter_num: 2786, on_card_num: 59, preempted blk num: 7956
iter_num: 2787, on_card_num: 60, preempted blk num: 7956
iter_num: 2788, on_card_num: 60, preempted blk num: 7956
iter_num: 2789, on_card_num: 60, preempted blk num: 7956
iter_num: 2790, on_card_num: 60, preempted blk num: 7956
to recompute 1: ('555', 597)
iter_num: 2791, on_card_num: 59, preempted blk num: 8032
iter_num: 2792, on_card_num: 59, preempted blk num: 8032
iter_num: 2793, on_card_num: 59, preempted blk num: 8032
iter_num: 2794, on_card_num: 59, preempted blk num: 8032
iter_num: 2795, on_card_num: 58, preempted blk num: 8032
iter_num: 2796, on_card_num: 59, preempted blk num: 8032
iter_num: 2797, on_card_num: 60, preempted blk num: 8032
iter_num: 2798, on_card_num: 60, preempted blk num: 8032
iter_num: 2799, on_card_num: 60, preempted blk num: 8032
iter_num: 2800, on_card_num: 59, preempted blk num: 8032
iter_num: 2801, on_card_num: 59, preempted blk num: 8032
iter_num: 2802, on_card_num: 59, preempted blk num: 8032
iter_num: 2803, on_card_num: 58, preempted blk num: 8032
iter_num: 2804, on_card_num: 59, preempted blk num: 8032
iter_num: 2805, on_card_num: 61, preempted blk num: 8032
iter_num: 2806, on_card_num: 61, preempted blk num: 8032
iter_num: 2807, on_card_num: 61, preempted blk num: 8032
iter_num: 2808, on_card_num: 61, preempted blk num: 8032
iter_num: 2809, on_card_num: 60, preempted blk num: 8032
iter_num: 2810, on_card_num: 60, preempted blk num: 8032
iter_num: 2811, on_card_num: 60, preempted blk num: 8032
iter_num: 2812, on_card_num: 60, preempted blk num: 8032
iter_num: 2813, on_card_num: 60, preempted blk num: 8032
iter_num: 2814, on_card_num: 58, preempted blk num: 8032
iter_num: 2815, on_card_num: 59, preempted blk num: 8032
iter_num: 2816, on_card_num: 60, preempted blk num: 8032
iter_num: 2817, on_card_num: 60, preempted blk num: 8032
iter_num: 2818, on_card_num: 60, preempted blk num: 8032
iter_num: 2819, on_card_num: 60, preempted blk num: 8032
iter_num: 2820, on_card_num: 60, preempted blk num: 8032
iter_num: 2821, on_card_num: 59, preempted blk num: 8032
iter_num: 2822, on_card_num: 60, preempted blk num: 8032
iter_num: 2823, on_card_num: 60, preempted blk num: 8032
iter_num: 2824, on_card_num: 60, preempted blk num: 8032
iter_num: 2825, on_card_num: 59, preempted blk num: 8032
iter_num: 2826, on_card_num: 59, preempted blk num: 8032
iter_num: 2827, on_card_num: 59, preempted blk num: 8032
iter_num: 2828, on_card_num: 59, preempted blk num: 8032
iter_num: 2829, on_card_num: 59, preempted blk num: 8032
iter_num: 2830, on_card_num: 59, preempted blk num: 8032
iter_num: 2831, on_card_num: 59, preempted blk num: 8032
iter_num: 2832, on_card_num: 58, preempted blk num: 8032
iter_num: 2833, on_card_num: 58, preempted blk num: 8032
iter_num: 2834, on_card_num: 58, preempted blk num: 8032
iter_num: 2835, on_card_num: 57, preempted blk num: 8032
iter_num: 2836, on_card_num: 57, preempted blk num: 8032
iter_num: 2837, on_card_num: 56, preempted blk num: 8032
iter_num: 2838, on_card_num: 57, preempted blk num: 8032
iter_num: 2839, on_card_num: 59, preempted blk num: 8032
iter_num: 2840, on_card_num: 59, preempted blk num: 8032
iter_num: 2841, on_card_num: 59, preempted blk num: 8032
iter_num: 2842, on_card_num: 58, preempted blk num: 8032
iter_num: 2843, on_card_num: 58, preempted blk num: 8032
iter_num: 2844, on_card_num: 58, preempted blk num: 8032
iter_num: 2845, on_card_num: 58, preempted blk num: 8032
to recompute 1: ('565', 14)
to recompute 1: ('564', 89)
iter_num: 2846, on_card_num: 55, preempted blk num: 8046
iter_num: 2847, on_card_num: 57, preempted blk num: 8046
iter_num: 2848, on_card_num: 55, preempted blk num: 8046
iter_num: 2849, on_card_num: 56, preempted blk num: 8046
iter_num: 2850, on_card_num: 57, preempted blk num: 8046
iter_num: 2851, on_card_num: 58, preempted blk num: 8046
iter_num: 2852, on_card_num: 60, preempted blk num: 8046
iter_num: 2853, on_card_num: 60, preempted blk num: 8046
iter_num: 2854, on_card_num: 60, preempted blk num: 8046
iter_num: 2855, on_card_num: 59, preempted blk num: 8046
iter_num: 2856, on_card_num: 60, preempted blk num: 8046
iter_num: 2857, on_card_num: 60, preempted blk num: 8046
iter_num: 2858, on_card_num: 60, preempted blk num: 8046
iter_num: 2859, on_card_num: 60, preempted blk num: 8046
iter_num: 2860, on_card_num: 60, preempted blk num: 8046
to recompute 1: ('571', 22)
to recompute 1: ('570', 22)
to recompute 2: ('569', 26)
iter_num: 2861, on_card_num: 57, preempted blk num: 8058
to recompute 1: ('568', 674)
iter_num: 2862, on_card_num: 56, preempted blk num: 8144
iter_num: 2863, on_card_num: 56, preempted blk num: 8144
iter_num: 2864, on_card_num: 56, preempted blk num: 8144
iter_num: 2865, on_card_num: 56, preempted blk num: 8144
iter_num: 2866, on_card_num: 56, preempted blk num: 8144
iter_num: 2867, on_card_num: 56, preempted blk num: 8144
iter_num: 2868, on_card_num: 56, preempted blk num: 8144
iter_num: 2869, on_card_num: 55, preempted blk num: 8144
iter_num: 2870, on_card_num: 55, preempted blk num: 8144
iter_num: 2871, on_card_num: 54, preempted blk num: 8144
iter_num: 2872, on_card_num: 53, preempted blk num: 8144
iter_num: 2873, on_card_num: 54, preempted blk num: 8144
iter_num: 2874, on_card_num: 58, preempted blk num: 8144
iter_num: 2875, on_card_num: 59, preempted blk num: 8144
iter_num: 2876, on_card_num: 58, preempted blk num: 8144
iter_num: 2877, on_card_num: 60, preempted blk num: 8144
iter_num: 2878, on_card_num: 61, preempted blk num: 8144
iter_num: 2879, on_card_num: 63, preempted blk num: 8144
iter_num: 2880, on_card_num: 63, preempted blk num: 8144
iter_num: 2881, on_card_num: 63, preempted blk num: 8144
iter_num: 2882, on_card_num: 63, preempted blk num: 8144
iter_num: 2883, on_card_num: 63, preempted blk num: 8144
to recompute 1: ('578', 32)
to recompute 1: ('577', 71)
iter_num: 2884, on_card_num: 61, preempted blk num: 8158
to recompute 1: ('576', 383)
iter_num: 2885, on_card_num: 60, preempted blk num: 8206
iter_num: 2886, on_card_num: 60, preempted blk num: 8206
iter_num: 2887, on_card_num: 60, preempted blk num: 8206
iter_num: 2888, on_card_num: 60, preempted blk num: 8206
iter_num: 2889, on_card_num: 60, preempted blk num: 8206
iter_num: 2890, on_card_num: 60, preempted blk num: 8206
iter_num: 2891, on_card_num: 59, preempted blk num: 8206
iter_num: 2892, on_card_num: 59, preempted blk num: 8206
iter_num: 2893, on_card_num: 59, preempted blk num: 8206
iter_num: 2894, on_card_num: 59, preempted blk num: 8206
iter_num: 2895, on_card_num: 59, preempted blk num: 8206
iter_num: 2896, on_card_num: 58, preempted blk num: 8206
iter_num: 2897, on_card_num: 59, preempted blk num: 8206
iter_num: 2898, on_card_num: 59, preempted blk num: 8206
iter_num: 2899, on_card_num: 58, preempted blk num: 8206
iter_num: 2900, on_card_num: 61, preempted blk num: 8206
iter_num: 2901, on_card_num: 59, preempted blk num: 8206
iter_num: 2902, on_card_num: 62, preempted blk num: 8206
iter_num: 2903, on_card_num: 63, preempted blk num: 8206
iter_num: 2904, on_card_num: 63, preempted blk num: 8206
iter_num: 2905, on_card_num: 62, preempted blk num: 8206
iter_num: 2906, on_card_num: 63, preempted blk num: 8206
iter_num: 2907, on_card_num: 62, preempted blk num: 8206
iter_num: 2908, on_card_num: 62, preempted blk num: 8206
iter_num: 2909, on_card_num: 62, preempted blk num: 8206
iter_num: 2910, on_card_num: 62, preempted blk num: 8206
iter_num: 2911, on_card_num: 62, preempted blk num: 8206
iter_num: 2912, on_card_num: 61, preempted blk num: 8206
iter_num: 2913, on_card_num: 61, preempted blk num: 8206
iter_num: 2914, on_card_num: 60, preempted blk num: 8206
iter_num: 2915, on_card_num: 61, preempted blk num: 8206
iter_num: 2916, on_card_num: 61, preempted blk num: 8206
iter_num: 2917, on_card_num: 61, preempted blk num: 8206
iter_num: 2918, on_card_num: 61, preempted blk num: 8206
iter_num: 2919, on_card_num: 60, preempted blk num: 8206
iter_num: 2920, on_card_num: 61, preempted blk num: 8206
iter_num: 2921, on_card_num: 61, preempted blk num: 8206
iter_num: 2922, on_card_num: 61, preempted blk num: 8206
iter_num: 2923, on_card_num: 59, preempted blk num: 8206
iter_num: 2924, on_card_num: 60, preempted blk num: 8206
iter_num: 2925, on_card_num: 61, preempted blk num: 8206
iter_num: 2926, on_card_num: 60, preempted blk num: 8206
iter_num: 2927, on_card_num: 61, preempted blk num: 8206
iter_num: 2928, on_card_num: 62, preempted blk num: 8206
iter_num: 2929, on_card_num: 61, preempted blk num: 8206
iter_num: 2930, on_card_num: 60, preempted blk num: 8206
iter_num: 2931, on_card_num: 60, preempted blk num: 8206
iter_num: 2932, on_card_num: 60, preempted blk num: 8206
iter_num: 2933, on_card_num: 60, preempted blk num: 8206
iter_num: 2934, on_card_num: 60, preempted blk num: 8206
iter_num: 2935, on_card_num: 60, preempted blk num: 8206
iter_num: 2936, on_card_num: 60, preempted blk num: 8206
iter_num: 2937, on_card_num: 60, preempted blk num: 8206
iter_num: 2938, on_card_num: 60, preempted blk num: 8206
iter_num: 2939, on_card_num: 60, preempted blk num: 8206
to recompute 1: ('590', 26)
iter_num: 2940, on_card_num: 58, preempted blk num: 8210
iter_num: 2941, on_card_num: 59, preempted blk num: 8210
iter_num: 2942, on_card_num: 59, preempted blk num: 8210
iter_num: 2943, on_card_num: 59, preempted blk num: 8210
iter_num: 2944, on_card_num: 58, preempted blk num: 8210
iter_num: 2945, on_card_num: 59, preempted blk num: 8210
iter_num: 2946, on_card_num: 60, preempted blk num: 8210
iter_num: 2947, on_card_num: 61, preempted blk num: 8210
iter_num: 2948, on_card_num: 63, preempted blk num: 8210
iter_num: 2949, on_card_num: 63, preempted blk num: 8210
iter_num: 2950, on_card_num: 63, preempted blk num: 8210
iter_num: 2951, on_card_num: 62, preempted blk num: 8210
iter_num: 2952, on_card_num: 65, preempted blk num: 8210
iter_num: 2953, on_card_num: 65, preempted blk num: 8210
iter_num: 2954, on_card_num: 64, preempted blk num: 8210
iter_num: 2955, on_card_num: 64, preempted blk num: 8210
iter_num: 2956, on_card_num: 64, preempted blk num: 8210
iter_num: 2957, on_card_num: 64, preempted blk num: 8210
iter_num: 2958, on_card_num: 64, preempted blk num: 8210
iter_num: 2959, on_card_num: 64, preempted blk num: 8210
iter_num: 2960, on_card_num: 64, preempted blk num: 8210
iter_num: 2961, on_card_num: 63, preempted blk num: 8210
iter_num: 2962, on_card_num: 64, preempted blk num: 8210
iter_num: 2963, on_card_num: 65, preempted blk num: 8210
iter_num: 2964, on_card_num: 65, preempted blk num: 8210
iter_num: 2965, on_card_num: 65, preempted blk num: 8210
iter_num: 2966, on_card_num: 65, preempted blk num: 8210
iter_num: 2967, on_card_num: 65, preempted blk num: 8210
iter_num: 2968, on_card_num: 64, preempted blk num: 8210
iter_num: 2969, on_card_num: 64, preempted blk num: 8210
iter_num: 2970, on_card_num: 63, preempted blk num: 8210
iter_num: 2971, on_card_num: 63, preempted blk num: 8210
iter_num: 2972, on_card_num: 63, preempted blk num: 8210
iter_num: 2973, on_card_num: 63, preempted blk num: 8210
iter_num: 2974, on_card_num: 63, preempted blk num: 8210
iter_num: 2975, on_card_num: 63, preempted blk num: 8210
iter_num: 2976, on_card_num: 62, preempted blk num: 8210
iter_num: 2977, on_card_num: 62, preempted blk num: 8210
iter_num: 2978, on_card_num: 62, preempted blk num: 8210
iter_num: 2979, on_card_num: 62, preempted blk num: 8210
iter_num: 2980, on_card_num: 62, preempted blk num: 8210
iter_num: 2981, on_card_num: 62, preempted blk num: 8210
iter_num: 2982, on_card_num: 61, preempted blk num: 8210
iter_num: 2983, on_card_num: 61, preempted blk num: 8210
iter_num: 2984, on_card_num: 61, preempted blk num: 8210
iter_num: 2985, on_card_num: 61, preempted blk num: 8210
iter_num: 2986, on_card_num: 61, preempted blk num: 8210
to recompute 1: ('600', 43)
iter_num: 2987, on_card_num: 59, preempted blk num: 8216
iter_num: 2988, on_card_num: 60, preempted blk num: 8216
iter_num: 2989, on_card_num: 60, preempted blk num: 8216
iter_num: 2990, on_card_num: 60, preempted blk num: 8216
iter_num: 2991, on_card_num: 60, preempted blk num: 8216
iter_num: 2992, on_card_num: 59, preempted blk num: 8216
iter_num: 2993, on_card_num: 58, preempted blk num: 8216
iter_num: 2994, on_card_num: 57, preempted blk num: 8216
iter_num: 2995, on_card_num: 58, preempted blk num: 8216
iter_num: 2996, on_card_num: 58, preempted blk num: 8216
iter_num: 2997, on_card_num: 58, preempted blk num: 8216
iter_num: 2998, on_card_num: 57, preempted blk num: 8216
iter_num: 2999, on_card_num: 57, preempted blk num: 8216
iter_num: 3000, on_card_num: 57, preempted blk num: 8216
iter_num: 3001, on_card_num: 57, preempted blk num: 8216
iter_num: 3002, on_card_num: 57, preempted blk num: 8216
iter_num: 3003, on_card_num: 56, preempted blk num: 8216
iter_num: 3004, on_card_num: 56, preempted blk num: 8216
iter_num: 3005, on_card_num: 55, preempted blk num: 8216
iter_num: 3006, on_card_num: 56, preempted blk num: 8216
iter_num: 3007, on_card_num: 57, preempted blk num: 8216
iter_num: 3008, on_card_num: 57, preempted blk num: 8216
iter_num: 3009, on_card_num: 57, preempted blk num: 8216
iter_num: 3010, on_card_num: 57, preempted blk num: 8216
iter_num: 3011, on_card_num: 57, preempted blk num: 8216
iter_num: 3012, on_card_num: 57, preempted blk num: 8216
iter_num: 3013, on_card_num: 57, preempted blk num: 8216
iter_num: 3014, on_card_num: 57, preempted blk num: 8216
iter_num: 3015, on_card_num: 57, preempted blk num: 8216
iter_num: 3016, on_card_num: 57, preempted blk num: 8216
to recompute 1: ('603', 24)
iter_num: 3017, on_card_num: 56, preempted blk num: 8220
to recompute 1: ('602', 684)
iter_num: 3018, on_card_num: 55, preempted blk num: 8306
iter_num: 3019, on_card_num: 55, preempted blk num: 8306
iter_num: 3020, on_card_num: 54, preempted blk num: 8306
iter_num: 3021, on_card_num: 54, preempted blk num: 8306
iter_num: 3022, on_card_num: 54, preempted blk num: 8306
iter_num: 3023, on_card_num: 54, preempted blk num: 8306
iter_num: 3024, on_card_num: 54, preempted blk num: 8306
iter_num: 3025, on_card_num: 54, preempted blk num: 8306
iter_num: 3026, on_card_num: 53, preempted blk num: 8306
iter_num: 3027, on_card_num: 54, preempted blk num: 8306
iter_num: 3028, on_card_num: 55, preempted blk num: 8306
iter_num: 3029, on_card_num: 55, preempted blk num: 8306
iter_num: 3030, on_card_num: 55, preempted blk num: 8306
iter_num: 3031, on_card_num: 55, preempted blk num: 8306
iter_num: 3032, on_card_num: 55, preempted blk num: 8306
to recompute 1: ('603', 29)
iter_num: 3033, on_card_num: 54, preempted blk num: 8310
to recompute 1: ('602', 690)
iter_num: 3034, on_card_num: 53, preempted blk num: 8398
iter_num: 3035, on_card_num: 53, preempted blk num: 8398
iter_num: 3036, on_card_num: 53, preempted blk num: 8398
iter_num: 3037, on_card_num: 53, preempted blk num: 8398
iter_num: 3038, on_card_num: 53, preempted blk num: 8398
iter_num: 3039, on_card_num: 53, preempted blk num: 8398
iter_num: 3040, on_card_num: 53, preempted blk num: 8398
iter_num: 3041, on_card_num: 53, preempted blk num: 8398
iter_num: 3042, on_card_num: 53, preempted blk num: 8398
iter_num: 3043, on_card_num: 53, preempted blk num: 8398
iter_num: 3044, on_card_num: 52, preempted blk num: 8398
iter_num: 3045, on_card_num: 52, preempted blk num: 8398
iter_num: 3046, on_card_num: 52, preempted blk num: 8398
iter_num: 3047, on_card_num: 52, preempted blk num: 8398
iter_num: 3048, on_card_num: 51, preempted blk num: 8398
iter_num: 3049, on_card_num: 50, preempted blk num: 8398
iter_num: 3050, on_card_num: 51, preempted blk num: 8398
iter_num: 3051, on_card_num: 52, preempted blk num: 8398
iter_num: 3052, on_card_num: 51, preempted blk num: 8398
iter_num: 3053, on_card_num: 51, preempted blk num: 8398
iter_num: 3054, on_card_num: 51, preempted blk num: 8398
iter_num: 3055, on_card_num: 51, preempted blk num: 8398
iter_num: 3056, on_card_num: 51, preempted blk num: 8398
iter_num: 3057, on_card_num: 50, preempted blk num: 8398
iter_num: 3058, on_card_num: 50, preempted blk num: 8398
iter_num: 3059, on_card_num: 50, preempted blk num: 8398
iter_num: 3060, on_card_num: 50, preempted blk num: 8398
iter_num: 3061, on_card_num: 50, preempted blk num: 8398
iter_num: 3062, on_card_num: 50, preempted blk num: 8398
iter_num: 3063, on_card_num: 50, preempted blk num: 8398
iter_num: 3064, on_card_num: 50, preempted blk num: 8398
to recompute 1: ('603', 43)
iter_num: 3065, on_card_num: 49, preempted blk num: 8404
to recompute 1: ('602', 705)
iter_num: 3066, on_card_num: 47, preempted blk num: 8492
iter_num: 3067, on_card_num: 48, preempted blk num: 8492
iter_num: 3068, on_card_num: 49, preempted blk num: 8492
iter_num: 3069, on_card_num: 49, preempted blk num: 8492
iter_num: 3070, on_card_num: 49, preempted blk num: 8492
iter_num: 3071, on_card_num: 49, preempted blk num: 8492
iter_num: 3072, on_card_num: 49, preempted blk num: 8492
iter_num: 3073, on_card_num: 49, preempted blk num: 8492
iter_num: 3074, on_card_num: 49, preempted blk num: 8492
iter_num: 3075, on_card_num: 49, preempted blk num: 8492
to recompute 1: ('603', 51)
iter_num: 3076, on_card_num: 48, preempted blk num: 8500
to recompute 1: ('602', 714)
iter_num: 3077, on_card_num: 47, preempted blk num: 8590
iter_num: 3078, on_card_num: 47, preempted blk num: 8590
iter_num: 3079, on_card_num: 47, preempted blk num: 8590
iter_num: 3080, on_card_num: 46, preempted blk num: 8590
iter_num: 3081, on_card_num: 47, preempted blk num: 8590
iter_num: 3082, on_card_num: 48, preempted blk num: 8590
iter_num: 3083, on_card_num: 48, preempted blk num: 8590
iter_num: 3084, on_card_num: 48, preempted blk num: 8590
iter_num: 3085, on_card_num: 48, preempted blk num: 8590
iter_num: 3086, on_card_num: 48, preempted blk num: 8590
iter_num: 3087, on_card_num: 48, preempted blk num: 8590
iter_num: 3088, on_card_num: 48, preempted blk num: 8590
iter_num: 3089, on_card_num: 48, preempted blk num: 8590
iter_num: 3090, on_card_num: 48, preempted blk num: 8590
to recompute 1: ('603', 60)
to recompute 1: ('602', 723)
iter_num: 3091, on_card_num: 46, preempted blk num: 8690
iter_num: 3092, on_card_num: 46, preempted blk num: 8690
iter_num: 3093, on_card_num: 46, preempted blk num: 8690
iter_num: 3094, on_card_num: 46, preempted blk num: 8690
iter_num: 3095, on_card_num: 46, preempted blk num: 8690
iter_num: 3096, on_card_num: 46, preempted blk num: 8690
iter_num: 3097, on_card_num: 46, preempted blk num: 8690
iter_num: 3098, on_card_num: 46, preempted blk num: 8690
iter_num: 3099, on_card_num: 45, preempted blk num: 8690
iter_num: 3100, on_card_num: 45, preempted blk num: 8690
iter_num: 3101, on_card_num: 45, preempted blk num: 8690
iter_num: 3102, on_card_num: 45, preempted blk num: 8690
iter_num: 3103, on_card_num: 45, preempted blk num: 8690
iter_num: 3104, on_card_num: 45, preempted blk num: 8690
iter_num: 3105, on_card_num: 45, preempted blk num: 8690
iter_num: 3106, on_card_num: 45, preempted blk num: 8690
iter_num: 3107, on_card_num: 45, preempted blk num: 8690
iter_num: 3108, on_card_num: 45, preempted blk num: 8690
iter_num: 3109, on_card_num: 45, preempted blk num: 8690
iter_num: 3110, on_card_num: 45, preempted blk num: 8690
iter_num: 3111, on_card_num: 45, preempted blk num: 8690
iter_num: 3112, on_card_num: 45, preempted blk num: 8690
iter_num: 3113, on_card_num: 45, preempted blk num: 8690
to recompute 1: ('600', 158)
iter_num: 3114, on_card_num: 43, preempted blk num: 8710
iter_num: 3115, on_card_num: 44, preempted blk num: 8710
iter_num: 3116, on_card_num: 45, preempted blk num: 8710
iter_num: 3117, on_card_num: 46, preempted blk num: 8710
iter_num: 3118, on_card_num: 46, preempted blk num: 8710
iter_num: 3119, on_card_num: 46, preempted blk num: 8710
iter_num: 3120, on_card_num: 46, preempted blk num: 8710
iter_num: 3121, on_card_num: 46, preempted blk num: 8710
iter_num: 3122, on_card_num: 46, preempted blk num: 8710
iter_num: 3123, on_card_num: 46, preempted blk num: 8710
iter_num: 3124, on_card_num: 45, preempted blk num: 8710
iter_num: 3125, on_card_num: 45, preempted blk num: 8710
iter_num: 3126, on_card_num: 45, preempted blk num: 8710
iter_num: 3127, on_card_num: 45, preempted blk num: 8710
iter_num: 3128, on_card_num: 45, preempted blk num: 8710
iter_num: 3129, on_card_num: 45, preempted blk num: 8710
iter_num: 3130, on_card_num: 44, preempted blk num: 8710
iter_num: 3131, on_card_num: 45, preempted blk num: 8710
iter_num: 3132, on_card_num: 46, preempted blk num: 8710
iter_num: 3133, on_card_num: 44, preempted blk num: 8710
iter_num: 3134, on_card_num: 45, preempted blk num: 8710
iter_num: 3135, on_card_num: 45, preempted blk num: 8710
iter_num: 3136, on_card_num: 45, preempted blk num: 8710
iter_num: 3137, on_card_num: 45, preempted blk num: 8710
iter_num: 3138, on_card_num: 45, preempted blk num: 8710
iter_num: 3139, on_card_num: 45, preempted blk num: 8710
iter_num: 3140, on_card_num: 45, preempted blk num: 8710
iter_num: 3141, on_card_num: 45, preempted blk num: 8710
iter_num: 3142, on_card_num: 45, preempted blk num: 8710
iter_num: 3143, on_card_num: 45, preempted blk num: 8710
iter_num: 3144, on_card_num: 44, preempted blk num: 8710
iter_num: 3145, on_card_num: 45, preempted blk num: 8710
iter_num: 3146, on_card_num: 45, preempted blk num: 8710
iter_num: 3147, on_card_num: 45, preempted blk num: 8710
iter_num: 3148, on_card_num: 45, preempted blk num: 8710
iter_num: 3149, on_card_num: 45, preempted blk num: 8710
to recompute 1: ('607', 402)
iter_num: 3150, on_card_num: 44, preempted blk num: 8762
iter_num: 3151, on_card_num: 44, preempted blk num: 8762
iter_num: 3152, on_card_num: 44, preempted blk num: 8762
iter_num: 3153, on_card_num: 44, preempted blk num: 8762
iter_num: 3154, on_card_num: 44, preempted blk num: 8762
iter_num: 3155, on_card_num: 44, preempted blk num: 8762
iter_num: 3156, on_card_num: 44, preempted blk num: 8762
iter_num: 3157, on_card_num: 43, preempted blk num: 8762
iter_num: 3158, on_card_num: 44, preempted blk num: 8762
iter_num: 3159, on_card_num: 44, preempted blk num: 8762
iter_num: 3160, on_card_num: 44, preempted blk num: 8762
iter_num: 3161, on_card_num: 44, preempted blk num: 8762
iter_num: 3162, on_card_num: 44, preempted blk num: 8762
iter_num: 3163, on_card_num: 44, preempted blk num: 8762
iter_num: 3164, on_card_num: 44, preempted blk num: 8762
iter_num: 3165, on_card_num: 43, preempted blk num: 8762
iter_num: 3166, on_card_num: 43, preempted blk num: 8762
iter_num: 3167, on_card_num: 43, preempted blk num: 8762
iter_num: 3168, on_card_num: 43, preempted blk num: 8762
iter_num: 3169, on_card_num: 43, preempted blk num: 8762
iter_num: 3170, on_card_num: 43, preempted blk num: 8762
iter_num: 3171, on_card_num: 43, preempted blk num: 8762
iter_num: 3172, on_card_num: 43, preempted blk num: 8762
iter_num: 3173, on_card_num: 43, preempted blk num: 8762
iter_num: 3174, on_card_num: 43, preempted blk num: 8762
to recompute 1: ('607', 419)
iter_num: 3175, on_card_num: 42, preempted blk num: 8816
iter_num: 3176, on_card_num: 42, preempted blk num: 8816
iter_num: 3177, on_card_num: 42, preempted blk num: 8816
iter_num: 3178, on_card_num: 42, preempted blk num: 8816
iter_num: 3179, on_card_num: 42, preempted blk num: 8816
iter_num: 3180, on_card_num: 41, preempted blk num: 8816
iter_num: 3181, on_card_num: 42, preempted blk num: 8816
iter_num: 3182, on_card_num: 42, preempted blk num: 8816
iter_num: 3183, on_card_num: 42, preempted blk num: 8816
iter_num: 3184, on_card_num: 42, preempted blk num: 8816
iter_num: 3185, on_card_num: 42, preempted blk num: 8816
iter_num: 3186, on_card_num: 42, preempted blk num: 8816
iter_num: 3187, on_card_num: 42, preempted blk num: 8816
iter_num: 3188, on_card_num: 41, preempted blk num: 8816
iter_num: 3189, on_card_num: 41, preempted blk num: 8816
iter_num: 3190, on_card_num: 40, preempted blk num: 8816
iter_num: 3191, on_card_num: 42, preempted blk num: 8816
iter_num: 3192, on_card_num: 43, preempted blk num: 8816
iter_num: 3193, on_card_num: 43, preempted blk num: 8816
iter_num: 3194, on_card_num: 43, preempted blk num: 8816
iter_num: 3195, on_card_num: 43, preempted blk num: 8816
iter_num: 3196, on_card_num: 43, preempted blk num: 8816
to recompute 1: ('610', 20)
iter_num: 3197, on_card_num: 42, preempted blk num: 8820
to recompute 1: ('609', 82)
iter_num: 3198, on_card_num: 41, preempted blk num: 8832
iter_num: 3199, on_card_num: 41, preempted blk num: 8832
to recompute 1: ('608', 328)
iter_num: 3200, on_card_num: 39, preempted blk num: 8874
iter_num: 3201, on_card_num: 41, preempted blk num: 8874
iter_num: 3202, on_card_num: 43, preempted blk num: 8874
iter_num: 3203, on_card_num: 43, preempted blk num: 8874
iter_num: 3204, on_card_num: 43, preempted blk num: 8874
iter_num: 3205, on_card_num: 43, preempted blk num: 8874
iter_num: 3206, on_card_num: 43, preempted blk num: 8874
iter_num: 3207, on_card_num: 43, preempted blk num: 8874
iter_num: 3208, on_card_num: 43, preempted blk num: 8874
to recompute 1: ('611', 96)
iter_num: 3209, on_card_num: 39, preempted blk num: 8886
iter_num: 3210, on_card_num: 41, preempted blk num: 8886
iter_num: 3211, on_card_num: 42, preempted blk num: 8886
iter_num: 3212, on_card_num: 43, preempted blk num: 8886
iter_num: 3213, on_card_num: 43, preempted blk num: 8886
iter_num: 3214, on_card_num: 43, preempted blk num: 8886
iter_num: 3215, on_card_num: 43, preempted blk num: 8886
iter_num: 3216, on_card_num: 43, preempted blk num: 8886
iter_num: 3217, on_card_num: 42, preempted blk num: 8886
iter_num: 3218, on_card_num: 43, preempted blk num: 8886
iter_num: 3219, on_card_num: 44, preempted blk num: 8886
iter_num: 3220, on_card_num: 43, preempted blk num: 8886
iter_num: 3221, on_card_num: 45, preempted blk num: 8886
iter_num: 3222, on_card_num: 45, preempted blk num: 8886
iter_num: 3223, on_card_num: 45, preempted blk num: 8886
iter_num: 3224, on_card_num: 45, preempted blk num: 8886
iter_num: 3225, on_card_num: 45, preempted blk num: 8886
to recompute 1: ('618', 450)
iter_num: 3226, on_card_num: 44, preempted blk num: 8944
iter_num: 3227, on_card_num: 44, preempted blk num: 8944
iter_num: 3228, on_card_num: 44, preempted blk num: 8944
iter_num: 3229, on_card_num: 44, preempted blk num: 8944
iter_num: 3230, on_card_num: 44, preempted blk num: 8944
iter_num: 3231, on_card_num: 44, preempted blk num: 8944
iter_num: 3232, on_card_num: 43, preempted blk num: 8944
iter_num: 3233, on_card_num: 43, preempted blk num: 8944
iter_num: 3234, on_card_num: 43, preempted blk num: 8944
iter_num: 3235, on_card_num: 42, preempted blk num: 8944
iter_num: 3236, on_card_num: 43, preempted blk num: 8944
iter_num: 3237, on_card_num: 45, preempted blk num: 8944
iter_num: 3238, on_card_num: 44, preempted blk num: 8944
iter_num: 3239, on_card_num: 45, preempted blk num: 8944
iter_num: 3240, on_card_num: 46, preempted blk num: 8944
iter_num: 3241, on_card_num: 47, preempted blk num: 8944
iter_num: 3242, on_card_num: 50, preempted blk num: 8944
iter_num: 3243, on_card_num: 49, preempted blk num: 8944
iter_num: 3244, on_card_num: 49, preempted blk num: 8944
iter_num: 3245, on_card_num: 47, preempted blk num: 8944
iter_num: 3246, on_card_num: 48, preempted blk num: 8944
iter_num: 3247, on_card_num: 51, preempted blk num: 8944
iter_num: 3248, on_card_num: 53, preempted blk num: 8944
iter_num: 3249, on_card_num: 52, preempted blk num: 8944
iter_num: 3250, on_card_num: 53, preempted blk num: 8944
iter_num: 3251, on_card_num: 53, preempted blk num: 8944
iter_num: 3252, on_card_num: 53, preempted blk num: 8944
iter_num: 3253, on_card_num: 52, preempted blk num: 8944
iter_num: 3254, on_card_num: 53, preempted blk num: 8944
iter_num: 3255, on_card_num: 53, preempted blk num: 8944
iter_num: 3256, on_card_num: 52, preempted blk num: 8944
iter_num: 3257, on_card_num: 52, preempted blk num: 8944
iter_num: 3258, on_card_num: 51, preempted blk num: 8944
iter_num: 3259, on_card_num: 51, preempted blk num: 8944
iter_num: 3260, on_card_num: 51, preempted blk num: 8944
iter_num: 3261, on_card_num: 51, preempted blk num: 8944
iter_num: 3262, on_card_num: 51, preempted blk num: 8944
iter_num: 3263, on_card_num: 51, preempted blk num: 8944
iter_num: 3264, on_card_num: 51, preempted blk num: 8944
iter_num: 3265, on_card_num: 51, preempted blk num: 8944
iter_num: 3266, on_card_num: 51, preempted blk num: 8944
iter_num: 3267, on_card_num: 51, preempted blk num: 8944
iter_num: 3268, on_card_num: 51, preempted blk num: 8944
iter_num: 3269, on_card_num: 50, preempted blk num: 8944
iter_num: 3270, on_card_num: 51, preempted blk num: 8944
iter_num: 3271, on_card_num: 52, preempted blk num: 8944
iter_num: 3272, on_card_num: 52, preempted blk num: 8944
iter_num: 3273, on_card_num: 50, preempted blk num: 8944
iter_num: 3274, on_card_num: 52, preempted blk num: 8944
iter_num: 3275, on_card_num: 54, preempted blk num: 8944
iter_num: 3276, on_card_num: 56, preempted blk num: 8944
iter_num: 3277, on_card_num: 55, preempted blk num: 8944
iter_num: 3278, on_card_num: 56, preempted blk num: 8944
iter_num: 3279, on_card_num: 57, preempted blk num: 8944
iter_num: 3280, on_card_num: 56, preempted blk num: 8944
iter_num: 3281, on_card_num: 57, preempted blk num: 8944
iter_num: 3282, on_card_num: 59, preempted blk num: 8944
iter_num: 3283, on_card_num: 58, preempted blk num: 8944
iter_num: 3284, on_card_num: 59, preempted blk num: 8944
iter_num: 3285, on_card_num: 59, preempted blk num: 8944
iter_num: 3286, on_card_num: 59, preempted blk num: 8944
to recompute 1: ('648', 507)
iter_num: 3287, on_card_num: 58, preempted blk num: 9008
iter_num: 3288, on_card_num: 58, preempted blk num: 9008
iter_num: 3289, on_card_num: 58, preempted blk num: 9008
iter_num: 3290, on_card_num: 57, preempted blk num: 9008
iter_num: 3291, on_card_num: 58, preempted blk num: 9008
iter_num: 3292, on_card_num: 57, preempted blk num: 9008
iter_num: 3293, on_card_num: 57, preempted blk num: 9008
iter_num: 3294, on_card_num: 57, preempted blk num: 9008
iter_num: 3295, on_card_num: 57, preempted blk num: 9008
iter_num: 3296, on_card_num: 57, preempted blk num: 9008
iter_num: 3297, on_card_num: 57, preempted blk num: 9008
iter_num: 3298, on_card_num: 57, preempted blk num: 9008
iter_num: 3299, on_card_num: 57, preempted blk num: 9008
iter_num: 3300, on_card_num: 56, preempted blk num: 9008
iter_num: 3301, on_card_num: 56, preempted blk num: 9008
iter_num: 3302, on_card_num: 55, preempted blk num: 9008
iter_num: 3303, on_card_num: 56, preempted blk num: 9008
iter_num: 3304, on_card_num: 60, preempted blk num: 9008
iter_num: 3305, on_card_num: 60, preempted blk num: 9008
iter_num: 3306, on_card_num: 59, preempted blk num: 9008
iter_num: 3307, on_card_num: 60, preempted blk num: 9008
iter_num: 3308, on_card_num: 61, preempted blk num: 9008
iter_num: 3309, on_card_num: 61, preempted blk num: 9008
iter_num: 3310, on_card_num: 61, preempted blk num: 9008
to recompute 1: ('655', 19)
iter_num: 3311, on_card_num: 59, preempted blk num: 9012
iter_num: 3312, on_card_num: 59, preempted blk num: 9012
to recompute 1: ('654', 802)
iter_num: 3313, on_card_num: 58, preempted blk num: 9114
iter_num: 3314, on_card_num: 58, preempted blk num: 9114
iter_num: 3315, on_card_num: 58, preempted blk num: 9114
iter_num: 3316, on_card_num: 56, preempted blk num: 9114
iter_num: 3317, on_card_num: 57, preempted blk num: 9114
iter_num: 3318, on_card_num: 59, preempted blk num: 9114
iter_num: 3319, on_card_num: 60, preempted blk num: 9114
iter_num: 3320, on_card_num: 60, preempted blk num: 9114
iter_num: 3321, on_card_num: 59, preempted blk num: 9114
iter_num: 3322, on_card_num: 60, preempted blk num: 9114
iter_num: 3323, on_card_num: 61, preempted blk num: 9114
iter_num: 3324, on_card_num: 61, preempted blk num: 9114
iter_num: 3325, on_card_num: 60, preempted blk num: 9114
iter_num: 3326, on_card_num: 61, preempted blk num: 9114
iter_num: 3327, on_card_num: 62, preempted blk num: 9114
iter_num: 3328, on_card_num: 63, preempted blk num: 9114
iter_num: 3329, on_card_num: 64, preempted blk num: 9114
iter_num: 3330, on_card_num: 64, preempted blk num: 9114
iter_num: 3331, on_card_num: 64, preempted blk num: 9114
to recompute 1: ('663', 17)
iter_num: 3332, on_card_num: 63, preempted blk num: 9116
to recompute 1: ('662', 329)
iter_num: 3333, on_card_num: 62, preempted blk num: 9158
iter_num: 3334, on_card_num: 61, preempted blk num: 9158
iter_num: 3335, on_card_num: 62, preempted blk num: 9158
iter_num: 3336, on_card_num: 63, preempted blk num: 9158
iter_num: 3337, on_card_num: 63, preempted blk num: 9158
iter_num: 3338, on_card_num: 62, preempted blk num: 9158
iter_num: 3339, on_card_num: 61, preempted blk num: 9158
iter_num: 3340, on_card_num: 62, preempted blk num: 9158
iter_num: 3341, on_card_num: 62, preempted blk num: 9158
iter_num: 3342, on_card_num: 62, preempted blk num: 9158
iter_num: 3343, on_card_num: 61, preempted blk num: 9158
iter_num: 3344, on_card_num: 62, preempted blk num: 9158
iter_num: 3345, on_card_num: 63, preempted blk num: 9158
iter_num: 3346, on_card_num: 64, preempted blk num: 9158
iter_num: 3347, on_card_num: 65, preempted blk num: 9158
iter_num: 3348, on_card_num: 65, preempted blk num: 9158
iter_num: 3349, on_card_num: 64, preempted blk num: 9158
iter_num: 3350, on_card_num: 64, preempted blk num: 9158
iter_num: 3351, on_card_num: 64, preempted blk num: 9158
iter_num: 3352, on_card_num: 64, preempted blk num: 9158
iter_num: 3353, on_card_num: 63, preempted blk num: 9158
iter_num: 3354, on_card_num: 65, preempted blk num: 9158
iter_num: 3355, on_card_num: 65, preempted blk num: 9158
iter_num: 3356, on_card_num: 65, preempted blk num: 9158
iter_num: 3357, on_card_num: 65, preempted blk num: 9158
iter_num: 3358, on_card_num: 64, preempted blk num: 9158
iter_num: 3359, on_card_num: 65, preempted blk num: 9158
iter_num: 3360, on_card_num: 65, preempted blk num: 9158
iter_num: 3361, on_card_num: 63, preempted blk num: 9158
iter_num: 3362, on_card_num: 64, preempted blk num: 9158
iter_num: 3363, on_card_num: 64, preempted blk num: 9158
iter_num: 3364, on_card_num: 64, preempted blk num: 9158
iter_num: 3365, on_card_num: 64, preempted blk num: 9158
iter_num: 3366, on_card_num: 63, preempted blk num: 9158
iter_num: 3367, on_card_num: 63, preempted blk num: 9158
iter_num: 3368, on_card_num: 62, preempted blk num: 9158
iter_num: 3369, on_card_num: 63, preempted blk num: 9158
iter_num: 3370, on_card_num: 64, preempted blk num: 9158
iter_num: 3371, on_card_num: 63, preempted blk num: 9158
iter_num: 3372, on_card_num: 63, preempted blk num: 9158
iter_num: 3373, on_card_num: 63, preempted blk num: 9158
iter_num: 3374, on_card_num: 63, preempted blk num: 9158
iter_num: 3375, on_card_num: 63, preempted blk num: 9158
iter_num: 3376, on_card_num: 62, preempted blk num: 9158
iter_num: 3377, on_card_num: 62, preempted blk num: 9158
iter_num: 3378, on_card_num: 62, preempted blk num: 9158
iter_num: 3379, on_card_num: 62, preempted blk num: 9158
to recompute 1: ('674', 21)
to recompute 1: ('673', 772)
iter_num: 3380, on_card_num: 59, preempted blk num: 9260
iter_num: 3381, on_card_num: 60, preempted blk num: 9260
iter_num: 3382, on_card_num: 61, preempted blk num: 9260
iter_num: 3383, on_card_num: 61, preempted blk num: 9260
iter_num: 3384, on_card_num: 61, preempted blk num: 9260
iter_num: 3385, on_card_num: 59, preempted blk num: 9260
iter_num: 3386, on_card_num: 60, preempted blk num: 9260
iter_num: 3387, on_card_num: 60, preempted blk num: 9260
iter_num: 3388, on_card_num: 60, preempted blk num: 9260
iter_num: 3389, on_card_num: 60, preempted blk num: 9260
to recompute 1: ('675', 948)
iter_num: 3390, on_card_num: 59, preempted blk num: 9380
iter_num: 3391, on_card_num: 59, preempted blk num: 9380
iter_num: 3392, on_card_num: 58, preempted blk num: 9380
iter_num: 3393, on_card_num: 59, preempted blk num: 9380
iter_num: 3394, on_card_num: 59, preempted blk num: 9380
iter_num: 3395, on_card_num: 59, preempted blk num: 9380
iter_num: 3396, on_card_num: 59, preempted blk num: 9380
iter_num: 3397, on_card_num: 59, preempted blk num: 9380
iter_num: 3398, on_card_num: 59, preempted blk num: 9380
to recompute 1: ('675', 954)
iter_num: 3399, on_card_num: 58, preempted blk num: 9500
iter_num: 3400, on_card_num: 57, preempted blk num: 9500
iter_num: 3401, on_card_num: 57, preempted blk num: 9500
iter_num: 3402, on_card_num: 57, preempted blk num: 9500
iter_num: 3403, on_card_num: 57, preempted blk num: 9500
iter_num: 3404, on_card_num: 57, preempted blk num: 9500
iter_num: 3405, on_card_num: 57, preempted blk num: 9500
iter_num: 3406, on_card_num: 57, preempted blk num: 9500
iter_num: 3407, on_card_num: 57, preempted blk num: 9500
iter_num: 3408, on_card_num: 56, preempted blk num: 9500
iter_num: 3409, on_card_num: 56, preempted blk num: 9500
iter_num: 3410, on_card_num: 58, preempted blk num: 9500
iter_num: 3411, on_card_num: 59, preempted blk num: 9500
iter_num: 3412, on_card_num: 59, preempted blk num: 9500
iter_num: 3413, on_card_num: 59, preempted blk num: 9500
iter_num: 3414, on_card_num: 59, preempted blk num: 9500
iter_num: 3415, on_card_num: 57, preempted blk num: 9500
iter_num: 3416, on_card_num: 58, preempted blk num: 9500
iter_num: 3417, on_card_num: 59, preempted blk num: 9500
iter_num: 3418, on_card_num: 60, preempted blk num: 9500
iter_num: 3419, on_card_num: 60, preempted blk num: 9500
iter_num: 3420, on_card_num: 60, preempted blk num: 9500
to recompute 1: ('681', 31)
iter_num: 3421, on_card_num: 59, preempted blk num: 9504
to recompute 1: ('680', 626)
iter_num: 3422, on_card_num: 58, preempted blk num: 9584
iter_num: 3423, on_card_num: 58, preempted blk num: 9584
iter_num: 3424, on_card_num: 58, preempted blk num: 9584
iter_num: 3425, on_card_num: 58, preempted blk num: 9584
iter_num: 3426, on_card_num: 58, preempted blk num: 9584
iter_num: 3427, on_card_num: 58, preempted blk num: 9584
iter_num: 3428, on_card_num: 58, preempted blk num: 9584
iter_num: 3429, on_card_num: 57, preempted blk num: 9584
iter_num: 3430, on_card_num: 58, preempted blk num: 9584
iter_num: 3431, on_card_num: 59, preempted blk num: 9584
iter_num: 3432, on_card_num: 59, preempted blk num: 9584
iter_num: 3433, on_card_num: 59, preempted blk num: 9584
iter_num: 3434, on_card_num: 59, preempted blk num: 9584
iter_num: 3435, on_card_num: 58, preempted blk num: 9584
iter_num: 3436, on_card_num: 57, preempted blk num: 9584
iter_num: 3437, on_card_num: 57, preempted blk num: 9584
iter_num: 3438, on_card_num: 57, preempted blk num: 9584
iter_num: 3439, on_card_num: 56, preempted blk num: 9584
iter_num: 3440, on_card_num: 55, preempted blk num: 9584
iter_num: 3441, on_card_num: 55, preempted blk num: 9584
iter_num: 3442, on_card_num: 54, preempted blk num: 9584
iter_num: 3443, on_card_num: 56, preempted blk num: 9584
iter_num: 3444, on_card_num: 60, preempted blk num: 9584
iter_num: 3445, on_card_num: 60, preempted blk num: 9584
iter_num: 3446, on_card_num: 60, preempted blk num: 9584
iter_num: 3447, on_card_num: 59, preempted blk num: 9584
iter_num: 3448, on_card_num: 60, preempted blk num: 9584
iter_num: 3449, on_card_num: 59, preempted blk num: 9584
iter_num: 3450, on_card_num: 58, preempted blk num: 9584
iter_num: 3451, on_card_num: 57, preempted blk num: 9584
iter_num: 3452, on_card_num: 58, preempted blk num: 9584
iter_num: 3453, on_card_num: 59, preempted blk num: 9584
iter_num: 3454, on_card_num: 59, preempted blk num: 9584
iter_num: 3455, on_card_num: 59, preempted blk num: 9584
iter_num: 3456, on_card_num: 59, preempted blk num: 9584
iter_num: 3457, on_card_num: 59, preempted blk num: 9584
to recompute 1: ('690', 36)
iter_num: 3458, on_card_num: 58, preempted blk num: 9590
to recompute 1: ('689', 958)
iter_num: 3459, on_card_num: 57, preempted blk num: 9710
iter_num: 3460, on_card_num: 56, preempted blk num: 9710
iter_num: 3461, on_card_num: 56, preempted blk num: 9710
iter_num: 3462, on_card_num: 56, preempted blk num: 9710
iter_num: 3463, on_card_num: 56, preempted blk num: 9710
iter_num: 3464, on_card_num: 56, preempted blk num: 9710
iter_num: 3465, on_card_num: 56, preempted blk num: 9710
iter_num: 3466, on_card_num: 56, preempted blk num: 9710
iter_num: 3467, on_card_num: 56, preempted blk num: 9710
iter_num: 3468, on_card_num: 56, preempted blk num: 9710
iter_num: 3469, on_card_num: 56, preempted blk num: 9710
iter_num: 3470, on_card_num: 56, preempted blk num: 9710
iter_num: 3471, on_card_num: 55, preempted blk num: 9710
iter_num: 3472, on_card_num: 55, preempted blk num: 9710
iter_num: 3473, on_card_num: 55, preempted blk num: 9710
iter_num: 3474, on_card_num: 54, preempted blk num: 9710
iter_num: 3475, on_card_num: 55, preempted blk num: 9710
iter_num: 3476, on_card_num: 59, preempted blk num: 9710
iter_num: 3477, on_card_num: 59, preempted blk num: 9710
iter_num: 3478, on_card_num: 59, preempted blk num: 9710
to recompute 1: ('693', 33)
to recompute 1: ('692', 32)
to recompute 1: ('691', 89)
iter_num: 3479, on_card_num: 56, preempted blk num: 9730
iter_num: 3480, on_card_num: 55, preempted blk num: 9730
iter_num: 3481, on_card_num: 59, preempted blk num: 9730
iter_num: 3482, on_card_num: 60, preempted blk num: 9730
iter_num: 3483, on_card_num: 60, preempted blk num: 9730
iter_num: 3484, on_card_num: 60, preempted blk num: 9730
iter_num: 3485, on_card_num: 60, preempted blk num: 9730
iter_num: 3486, on_card_num: 60, preempted blk num: 9730
iter_num: 3487, on_card_num: 58, preempted blk num: 9730
iter_num: 3488, on_card_num: 60, preempted blk num: 9730
iter_num: 3489, on_card_num: 60, preempted blk num: 9730
iter_num: 3490, on_card_num: 60, preempted blk num: 9730
iter_num: 3491, on_card_num: 60, preempted blk num: 9730
iter_num: 3492, on_card_num: 60, preempted blk num: 9730
iter_num: 3493, on_card_num: 60, preempted blk num: 9730
iter_num: 3494, on_card_num: 60, preempted blk num: 9730
iter_num: 3495, on_card_num: 60, preempted blk num: 9730
iter_num: 3496, on_card_num: 59, preempted blk num: 9730
iter_num: 3497, on_card_num: 59, preempted blk num: 9730
iter_num: 3498, on_card_num: 59, preempted blk num: 9730
to recompute 1: ('697', 501)
iter_num: 3499, on_card_num: 58, preempted blk num: 9794
iter_num: 3500, on_card_num: 58, preempted blk num: 9794
iter_num: 3501, on_card_num: 57, preempted blk num: 9794
iter_num: 3502, on_card_num: 57, preempted blk num: 9794
iter_num: 3503, on_card_num: 57, preempted blk num: 9794
iter_num: 3504, on_card_num: 56, preempted blk num: 9794
iter_num: 3505, on_card_num: 57, preempted blk num: 9794
iter_num: 3506, on_card_num: 56, preempted blk num: 9794
iter_num: 3507, on_card_num: 57, preempted blk num: 9794
iter_num: 3508, on_card_num: 58, preempted blk num: 9794
iter_num: 3509, on_card_num: 58, preempted blk num: 9794
iter_num: 3510, on_card_num: 58, preempted blk num: 9794
iter_num: 3511, on_card_num: 58, preempted blk num: 9794
iter_num: 3512, on_card_num: 58, preempted blk num: 9794
iter_num: 3513, on_card_num: 58, preempted blk num: 9794
to recompute 1: ('699', 40)
to recompute 1: ('698', 405)
iter_num: 3514, on_card_num: 55, preempted blk num: 9852
iter_num: 3515, on_card_num: 56, preempted blk num: 9852
iter_num: 3516, on_card_num: 57, preempted blk num: 9852
iter_num: 3517, on_card_num: 57, preempted blk num: 9852
iter_num: 3518, on_card_num: 57, preempted blk num: 9852
iter_num: 3519, on_card_num: 56, preempted blk num: 9852
iter_num: 3520, on_card_num: 56, preempted blk num: 9852
iter_num: 3521, on_card_num: 56, preempted blk num: 9852
iter_num: 3522, on_card_num: 56, preempted blk num: 9852
iter_num: 3523, on_card_num: 56, preempted blk num: 9852
iter_num: 3524, on_card_num: 56, preempted blk num: 9852
iter_num: 3525, on_card_num: 55, preempted blk num: 9852
iter_num: 3526, on_card_num: 56, preempted blk num: 9852
iter_num: 3527, on_card_num: 57, preempted blk num: 9852
iter_num: 3528, on_card_num: 57, preempted blk num: 9852
iter_num: 3529, on_card_num: 57, preempted blk num: 9852
iter_num: 3530, on_card_num: 57, preempted blk num: 9852
iter_num: 3531, on_card_num: 57, preempted blk num: 9852
iter_num: 3532, on_card_num: 56, preempted blk num: 9852
iter_num: 3533, on_card_num: 56, preempted blk num: 9852
iter_num: 3534, on_card_num: 56, preempted blk num: 9852
iter_num: 3535, on_card_num: 56, preempted blk num: 9852
to recompute 1: ('701', 26)
iter_num: 3536, on_card_num: 55, preempted blk num: 9856
to recompute 1: ('700', 668)
iter_num: 3537, on_card_num: 54, preempted blk num: 9940
iter_num: 3538, on_card_num: 54, preempted blk num: 9940
iter_num: 3539, on_card_num: 54, preempted blk num: 9940
iter_num: 3540, on_card_num: 54, preempted blk num: 9940
iter_num: 3541, on_card_num: 54, preempted blk num: 9940
iter_num: 3542, on_card_num: 54, preempted blk num: 9940
iter_num: 3543, on_card_num: 53, preempted blk num: 9940
iter_num: 3544, on_card_num: 53, preempted blk num: 9940
iter_num: 3545, on_card_num: 53, preempted blk num: 9940
iter_num: 3546, on_card_num: 53, preempted blk num: 9940
iter_num: 3547, on_card_num: 52, preempted blk num: 9940
iter_num: 3548, on_card_num: 52, preempted blk num: 9940
iter_num: 3549, on_card_num: 52, preempted blk num: 9940
iter_num: 3550, on_card_num: 52, preempted blk num: 9940
iter_num: 3551, on_card_num: 51, preempted blk num: 9940
iter_num: 3552, on_card_num: 52, preempted blk num: 9940
iter_num: 3553, on_card_num: 53, preempted blk num: 9940
iter_num: 3554, on_card_num: 53, preempted blk num: 9940
iter_num: 3555, on_card_num: 53, preempted blk num: 9940
iter_num: 3556, on_card_num: 53, preempted blk num: 9940
iter_num: 3557, on_card_num: 53, preempted blk num: 9940
iter_num: 3558, on_card_num: 53, preempted blk num: 9940
iter_num: 3559, on_card_num: 53, preempted blk num: 9940
iter_num: 3560, on_card_num: 53, preempted blk num: 9940
iter_num: 3561, on_card_num: 53, preempted blk num: 9940
iter_num: 3562, on_card_num: 53, preempted blk num: 9940
iter_num: 3563, on_card_num: 53, preempted blk num: 9940
iter_num: 3564, on_card_num: 53, preempted blk num: 9940
iter_num: 3565, on_card_num: 52, preempted blk num: 9940
iter_num: 3566, on_card_num: 51, preempted blk num: 9940
iter_num: 3567, on_card_num: 51, preempted blk num: 9940
iter_num: 3568, on_card_num: 51, preempted blk num: 9940
iter_num: 3569, on_card_num: 51, preempted blk num: 9940
iter_num: 3570, on_card_num: 51, preempted blk num: 9940
iter_num: 3571, on_card_num: 51, preempted blk num: 9940
iter_num: 3572, on_card_num: 51, preempted blk num: 9940
iter_num: 3573, on_card_num: 51, preempted blk num: 9940
to recompute 1: ('701', 47)
iter_num: 3574, on_card_num: 50, preempted blk num: 9946
to recompute 1: ('700', 690)
iter_num: 3575, on_card_num: 49, preempted blk num: 10034
iter_num: 3576, on_card_num: 49, preempted blk num: 10034
iter_num: 3577, on_card_num: 49, preempted blk num: 10034
iter_num: 3578, on_card_num: 49, preempted blk num: 10034
iter_num: 3579, on_card_num: 49, preempted blk num: 10034
iter_num: 3580, on_card_num: 49, preempted blk num: 10034
iter_num: 3581, on_card_num: 49, preempted blk num: 10034
iter_num: 3582, on_card_num: 49, preempted blk num: 10034
iter_num: 3583, on_card_num: 49, preempted blk num: 10034
iter_num: 3584, on_card_num: 49, preempted blk num: 10034
iter_num: 3585, on_card_num: 49, preempted blk num: 10034
iter_num: 3586, on_card_num: 49, preempted blk num: 10034
iter_num: 3587, on_card_num: 49, preempted blk num: 10034
iter_num: 3588, on_card_num: 49, preempted blk num: 10034
to recompute 1: ('699', 109)
iter_num: 3589, on_card_num: 48, preempted blk num: 10048
iter_num: 3590, on_card_num: 47, preempted blk num: 10048
iter_num: 3591, on_card_num: 48, preempted blk num: 10048
iter_num: 3592, on_card_num: 47, preempted blk num: 10048
iter_num: 3593, on_card_num: 48, preempted blk num: 10048
iter_num: 3594, on_card_num: 49, preempted blk num: 10048
iter_num: 3595, on_card_num: 49, preempted blk num: 10048
iter_num: 3596, on_card_num: 49, preempted blk num: 10048
iter_num: 3597, on_card_num: 49, preempted blk num: 10048
iter_num: 3598, on_card_num: 49, preempted blk num: 10048
iter_num: 3599, on_card_num: 49, preempted blk num: 10048
iter_num: 3600, on_card_num: 49, preempted blk num: 10048
iter_num: 3601, on_card_num: 49, preempted blk num: 10048
iter_num: 3602, on_card_num: 49, preempted blk num: 10048
iter_num: 3603, on_card_num: 49, preempted blk num: 10048
iter_num: 3604, on_card_num: 49, preempted blk num: 10048
to recompute 1: ('701', 58)
iter_num: 3605, on_card_num: 48, preempted blk num: 10056
to recompute 1: ('700', 702)
iter_num: 3606, on_card_num: 47, preempted blk num: 10144
iter_num: 3607, on_card_num: 47, preempted blk num: 10144
iter_num: 3608, on_card_num: 47, preempted blk num: 10144
iter_num: 3609, on_card_num: 47, preempted blk num: 10144
iter_num: 3610, on_card_num: 47, preempted blk num: 10144
iter_num: 3611, on_card_num: 47, preempted blk num: 10144
iter_num: 3612, on_card_num: 47, preempted blk num: 10144
iter_num: 3613, on_card_num: 47, preempted blk num: 10144
iter_num: 3614, on_card_num: 47, preempted blk num: 10144
iter_num: 3615, on_card_num: 47, preempted blk num: 10144
iter_num: 3616, on_card_num: 47, preempted blk num: 10144
iter_num: 3617, on_card_num: 46, preempted blk num: 10144
iter_num: 3618, on_card_num: 47, preempted blk num: 10144
iter_num: 3619, on_card_num: 47, preempted blk num: 10144
iter_num: 3620, on_card_num: 47, preempted blk num: 10144
iter_num: 3621, on_card_num: 47, preempted blk num: 10144
to recompute 1: ('700', 706)
iter_num: 3622, on_card_num: 46, preempted blk num: 10234
iter_num: 3623, on_card_num: 46, preempted blk num: 10234
iter_num: 3624, on_card_num: 46, preempted blk num: 10234
iter_num: 3625, on_card_num: 46, preempted blk num: 10234
iter_num: 3626, on_card_num: 46, preempted blk num: 10234
iter_num: 3627, on_card_num: 45, preempted blk num: 10234
iter_num: 3628, on_card_num: 45, preempted blk num: 10234
iter_num: 3629, on_card_num: 45, preempted blk num: 10234
iter_num: 3630, on_card_num: 45, preempted blk num: 10234
iter_num: 3631, on_card_num: 45, preempted blk num: 10234
iter_num: 3632, on_card_num: 45, preempted blk num: 10234
iter_num: 3633, on_card_num: 45, preempted blk num: 10234
iter_num: 3634, on_card_num: 44, preempted blk num: 10234
iter_num: 3635, on_card_num: 44, preempted blk num: 10234
iter_num: 3636, on_card_num: 44, preempted blk num: 10234
iter_num: 3637, on_card_num: 43, preempted blk num: 10234
iter_num: 3638, on_card_num: 43, preempted blk num: 10234
iter_num: 3639, on_card_num: 43, preempted blk num: 10234
iter_num: 3640, on_card_num: 42, preempted blk num: 10234
iter_num: 3641, on_card_num: 43, preempted blk num: 10234
iter_num: 3642, on_card_num: 44, preempted blk num: 10234
iter_num: 3643, on_card_num: 44, preempted blk num: 10234
iter_num: 3644, on_card_num: 44, preempted blk num: 10234
iter_num: 3645, on_card_num: 44, preempted blk num: 10234
iter_num: 3646, on_card_num: 44, preempted blk num: 10234
iter_num: 3647, on_card_num: 44, preempted blk num: 10234
iter_num: 3648, on_card_num: 44, preempted blk num: 10234
iter_num: 3649, on_card_num: 44, preempted blk num: 10234
iter_num: 3650, on_card_num: 44, preempted blk num: 10234
iter_num: 3651, on_card_num: 44, preempted blk num: 10234
iter_num: 3652, on_card_num: 44, preempted blk num: 10234
iter_num: 3653, on_card_num: 44, preempted blk num: 10234
iter_num: 3654, on_card_num: 44, preempted blk num: 10234
to recompute 1: ('701', 71)
iter_num: 3655, on_card_num: 43, preempted blk num: 10244
iter_num: 3656, on_card_num: 42, preempted blk num: 10244
iter_num: 3657, on_card_num: 43, preempted blk num: 10244
iter_num: 3658, on_card_num: 43, preempted blk num: 10244
iter_num: 3659, on_card_num: 43, preempted blk num: 10244
iter_num: 3660, on_card_num: 43, preempted blk num: 10244
iter_num: 3661, on_card_num: 43, preempted blk num: 10244
iter_num: 3662, on_card_num: 43, preempted blk num: 10244
iter_num: 3663, on_card_num: 43, preempted blk num: 10244
iter_num: 3664, on_card_num: 43, preempted blk num: 10244
iter_num: 3665, on_card_num: 43, preempted blk num: 10244
iter_num: 3666, on_card_num: 43, preempted blk num: 10244
iter_num: 3667, on_card_num: 43, preempted blk num: 10244
iter_num: 3668, on_card_num: 43, preempted blk num: 10244
iter_num: 3669, on_card_num: 43, preempted blk num: 10244
iter_num: 3670, on_card_num: 42, preempted blk num: 10244
iter_num: 3671, on_card_num: 42, preempted blk num: 10244
iter_num: 3672, on_card_num: 42, preempted blk num: 10244
iter_num: 3673, on_card_num: 42, preempted blk num: 10244
iter_num: 3674, on_card_num: 42, preempted blk num: 10244
iter_num: 3675, on_card_num: 42, preempted blk num: 10244
iter_num: 3676, on_card_num: 42, preempted blk num: 10244
iter_num: 3677, on_card_num: 42, preempted blk num: 10244
iter_num: 3678, on_card_num: 42, preempted blk num: 10244
iter_num: 3679, on_card_num: 41, preempted blk num: 10244
iter_num: 3680, on_card_num: 41, preempted blk num: 10244
iter_num: 3681, on_card_num: 41, preempted blk num: 10244
iter_num: 3682, on_card_num: 41, preempted blk num: 10244
iter_num: 3683, on_card_num: 41, preempted blk num: 10244
iter_num: 3684, on_card_num: 41, preempted blk num: 10244
iter_num: 3685, on_card_num: 41, preempted blk num: 10244
iter_num: 3686, on_card_num: 41, preempted blk num: 10244
iter_num: 3687, on_card_num: 40, preempted blk num: 10244
iter_num: 3688, on_card_num: 40, preempted blk num: 10244
iter_num: 3689, on_card_num: 39, preempted blk num: 10244
iter_num: 3690, on_card_num: 40, preempted blk num: 10244
iter_num: 3691, on_card_num: 40, preempted blk num: 10244
iter_num: 3692, on_card_num: 39, preempted blk num: 10244
iter_num: 3693, on_card_num: 39, preempted blk num: 10244
iter_num: 3694, on_card_num: 39, preempted blk num: 10244
iter_num: 3695, on_card_num: 39, preempted blk num: 10244
iter_num: 3696, on_card_num: 39, preempted blk num: 10244
iter_num: 3697, on_card_num: 39, preempted blk num: 10244
iter_num: 3698, on_card_num: 39, preempted blk num: 10244
iter_num: 3699, on_card_num: 39, preempted blk num: 10244
iter_num: 3700, on_card_num: 39, preempted blk num: 10244
iter_num: 3701, on_card_num: 39, preempted blk num: 10244
iter_num: 3702, on_card_num: 39, preempted blk num: 10244
iter_num: 3703, on_card_num: 38, preempted blk num: 10244
iter_num: 3704, on_card_num: 39, preempted blk num: 10244
iter_num: 3705, on_card_num: 41, preempted blk num: 10244
iter_num: 3706, on_card_num: 41, preempted blk num: 10244
iter_num: 3707, on_card_num: 41, preempted blk num: 10244
iter_num: 3708, on_card_num: 41, preempted blk num: 10244
iter_num: 3709, on_card_num: 41, preempted blk num: 10244
iter_num: 3710, on_card_num: 41, preempted blk num: 10244
iter_num: 3711, on_card_num: 41, preempted blk num: 10244
iter_num: 3712, on_card_num: 41, preempted blk num: 10244
iter_num: 3713, on_card_num: 41, preempted blk num: 10244
iter_num: 3714, on_card_num: 40, preempted blk num: 10244
iter_num: 3715, on_card_num: 40, preempted blk num: 10244
iter_num: 3716, on_card_num: 39, preempted blk num: 10244
iter_num: 3717, on_card_num: 40, preempted blk num: 10244
iter_num: 3718, on_card_num: 40, preempted blk num: 10244
iter_num: 3719, on_card_num: 40, preempted blk num: 10244
iter_num: 3720, on_card_num: 39, preempted blk num: 10244
iter_num: 3721, on_card_num: 39, preempted blk num: 10244
iter_num: 3722, on_card_num: 39, preempted blk num: 10244
iter_num: 3723, on_card_num: 38, preempted blk num: 10244
iter_num: 3724, on_card_num: 40, preempted blk num: 10244
iter_num: 3725, on_card_num: 40, preempted blk num: 10244
iter_num: 3726, on_card_num: 40, preempted blk num: 10244
iter_num: 3727, on_card_num: 40, preempted blk num: 10244
iter_num: 3728, on_card_num: 40, preempted blk num: 10244
to recompute 1: ('708', 528)
iter_num: 3729, on_card_num: 39, preempted blk num: 10310
iter_num: 3730, on_card_num: 39, preempted blk num: 10310
iter_num: 3731, on_card_num: 39, preempted blk num: 10310
iter_num: 3732, on_card_num: 39, preempted blk num: 10310
iter_num: 3733, on_card_num: 39, preempted blk num: 10310
iter_num: 3734, on_card_num: 39, preempted blk num: 10310
iter_num: 3735, on_card_num: 39, preempted blk num: 10310
iter_num: 3736, on_card_num: 39, preempted blk num: 10310
iter_num: 3737, on_card_num: 39, preempted blk num: 10310
iter_num: 3738, on_card_num: 39, preempted blk num: 10310
iter_num: 3739, on_card_num: 39, preempted blk num: 10310
iter_num: 3740, on_card_num: 39, preempted blk num: 10310
iter_num: 3741, on_card_num: 38, preempted blk num: 10310
iter_num: 3742, on_card_num: 38, preempted blk num: 10310
iter_num: 3743, on_card_num: 38, preempted blk num: 10310
iter_num: 3744, on_card_num: 38, preempted blk num: 10310
iter_num: 3745, on_card_num: 37, preempted blk num: 10310
iter_num: 3746, on_card_num: 38, preempted blk num: 10310
iter_num: 3747, on_card_num: 39, preempted blk num: 10310
iter_num: 3748, on_card_num: 39, preempted blk num: 10310
iter_num: 3749, on_card_num: 39, preempted blk num: 10310
iter_num: 3750, on_card_num: 39, preempted blk num: 10310
iter_num: 3751, on_card_num: 38, preempted blk num: 10310
iter_num: 3752, on_card_num: 38, preempted blk num: 10310
iter_num: 3753, on_card_num: 38, preempted blk num: 10310
iter_num: 3754, on_card_num: 38, preempted blk num: 10310
iter_num: 3755, on_card_num: 38, preempted blk num: 10310
iter_num: 3756, on_card_num: 38, preempted blk num: 10310
iter_num: 3757, on_card_num: 38, preempted blk num: 10310
iter_num: 3758, on_card_num: 37, preempted blk num: 10310
iter_num: 3759, on_card_num: 37, preempted blk num: 10310
iter_num: 3760, on_card_num: 37, preempted blk num: 10310
iter_num: 3761, on_card_num: 37, preempted blk num: 10310
iter_num: 3762, on_card_num: 37, preempted blk num: 10310
iter_num: 3763, on_card_num: 37, preempted blk num: 10310
iter_num: 3764, on_card_num: 37, preempted blk num: 10310
iter_num: 3765, on_card_num: 37, preempted blk num: 10310
iter_num: 3766, on_card_num: 37, preempted blk num: 10310
iter_num: 3767, on_card_num: 37, preempted blk num: 10310
iter_num: 3768, on_card_num: 37, preempted blk num: 10310
iter_num: 3769, on_card_num: 37, preempted blk num: 10310
iter_num: 3770, on_card_num: 37, preempted blk num: 10310
iter_num: 3771, on_card_num: 36, preempted blk num: 10310
iter_num: 3772, on_card_num: 36, preempted blk num: 10310
iter_num: 3773, on_card_num: 36, preempted blk num: 10310
iter_num: 3774, on_card_num: 36, preempted blk num: 10310
iter_num: 3775, on_card_num: 36, preempted blk num: 10310
iter_num: 3776, on_card_num: 36, preempted blk num: 10310
iter_num: 3777, on_card_num: 35, preempted blk num: 10310
iter_num: 3778, on_card_num: 36, preempted blk num: 10310
iter_num: 3779, on_card_num: 38, preempted blk num: 10310
iter_num: 3780, on_card_num: 38, preempted blk num: 10310
iter_num: 3781, on_card_num: 38, preempted blk num: 10310
iter_num: 3782, on_card_num: 38, preempted blk num: 10310
iter_num: 3783, on_card_num: 38, preempted blk num: 10310
iter_num: 3784, on_card_num: 38, preempted blk num: 10310
iter_num: 3785, on_card_num: 38, preempted blk num: 10310
iter_num: 3786, on_card_num: 38, preempted blk num: 10310
iter_num: 3787, on_card_num: 37, preempted blk num: 10310
iter_num: 3788, on_card_num: 37, preempted blk num: 10310
iter_num: 3789, on_card_num: 37, preempted blk num: 10310
iter_num: 3790, on_card_num: 37, preempted blk num: 10310
iter_num: 3791, on_card_num: 37, preempted blk num: 10310
iter_num: 3792, on_card_num: 37, preempted blk num: 10310
iter_num: 3793, on_card_num: 37, preempted blk num: 10310
iter_num: 3794, on_card_num: 37, preempted blk num: 10310
iter_num: 3795, on_card_num: 37, preempted blk num: 10310
iter_num: 3796, on_card_num: 37, preempted blk num: 10310
iter_num: 3797, on_card_num: 37, preempted blk num: 10310
iter_num: 3798, on_card_num: 37, preempted blk num: 10310
iter_num: 3799, on_card_num: 37, preempted blk num: 10310
iter_num: 3800, on_card_num: 36, preempted blk num: 10310
iter_num: 3801, on_card_num: 36, preempted blk num: 10310
iter_num: 3802, on_card_num: 36, preempted blk num: 10310
iter_num: 3803, on_card_num: 36, preempted blk num: 10310
iter_num: 3804, on_card_num: 35, preempted blk num: 10310
iter_num: 3805, on_card_num: 36, preempted blk num: 10310
iter_num: 3806, on_card_num: 41, preempted blk num: 10310
iter_num: 3807, on_card_num: 45, preempted blk num: 10310
iter_num: 3808, on_card_num: 48, preempted blk num: 10310
iter_num: 3809, on_card_num: 49, preempted blk num: 10310
iter_num: 3810, on_card_num: 49, preempted blk num: 10310
iter_num: 3811, on_card_num: 48, preempted blk num: 10310
iter_num: 3812, on_card_num: 48, preempted blk num: 10310
iter_num: 3813, on_card_num: 48, preempted blk num: 10310
iter_num: 3814, on_card_num: 47, preempted blk num: 10310
iter_num: 3815, on_card_num: 48, preempted blk num: 10310
iter_num: 3816, on_card_num: 48, preempted blk num: 10310
iter_num: 3817, on_card_num: 48, preempted blk num: 10310
iter_num: 3818, on_card_num: 48, preempted blk num: 10310
iter_num: 3819, on_card_num: 48, preempted blk num: 10310
iter_num: 3820, on_card_num: 48, preempted blk num: 10310
iter_num: 3821, on_card_num: 48, preempted blk num: 10310
iter_num: 3822, on_card_num: 47, preempted blk num: 10310
iter_num: 3823, on_card_num: 48, preempted blk num: 10310
iter_num: 3824, on_card_num: 49, preempted blk num: 10310
iter_num: 3825, on_card_num: 49, preempted blk num: 10310
iter_num: 3826, on_card_num: 47, preempted blk num: 10310
iter_num: 3827, on_card_num: 48, preempted blk num: 10310
iter_num: 3828, on_card_num: 50, preempted blk num: 10310
iter_num: 3829, on_card_num: 50, preempted blk num: 10310
iter_num: 3830, on_card_num: 50, preempted blk num: 10310
iter_num: 3831, on_card_num: 50, preempted blk num: 10310
iter_num: 3832, on_card_num: 50, preempted blk num: 10310
iter_num: 3833, on_card_num: 50, preempted blk num: 10310
iter_num: 3834, on_card_num: 50, preempted blk num: 10310
iter_num: 3835, on_card_num: 50, preempted blk num: 10310
iter_num: 3836, on_card_num: 50, preempted blk num: 10310
iter_num: 3837, on_card_num: 50, preempted blk num: 10310
to recompute 1: ('732', 17)
to recompute 1: ('731', 26)
iter_num: 3838, on_card_num: 48, preempted blk num: 10316
iter_num: 3839, on_card_num: 47, preempted blk num: 10316
iter_num: 3840, on_card_num: 49, preempted blk num: 10316
iter_num: 3841, on_card_num: 49, preempted blk num: 10316
iter_num: 3842, on_card_num: 49, preempted blk num: 10316
iter_num: 3843, on_card_num: 49, preempted blk num: 10316
iter_num: 3844, on_card_num: 49, preempted blk num: 10316
iter_num: 3845, on_card_num: 49, preempted blk num: 10316
iter_num: 3846, on_card_num: 49, preempted blk num: 10316
iter_num: 3847, on_card_num: 49, preempted blk num: 10316
iter_num: 3848, on_card_num: 49, preempted blk num: 10316
iter_num: 3849, on_card_num: 49, preempted blk num: 10316
iter_num: 3850, on_card_num: 49, preempted blk num: 10316
to recompute 1: ('732', 28)
to recompute 1: ('731', 37)
iter_num: 3851, on_card_num: 47, preempted blk num: 10326
to recompute 1: ('730', 371)
iter_num: 3852, on_card_num: 46, preempted blk num: 10374
iter_num: 3853, on_card_num: 46, preempted blk num: 10374
iter_num: 3854, on_card_num: 45, preempted blk num: 10374
iter_num: 3855, on_card_num: 46, preempted blk num: 10374
iter_num: 3856, on_card_num: 48, preempted blk num: 10374
iter_num: 3857, on_card_num: 49, preempted blk num: 10374
iter_num: 3858, on_card_num: 52, preempted blk num: 10374
iter_num: 3859, on_card_num: 52, preempted blk num: 10374
iter_num: 3860, on_card_num: 52, preempted blk num: 10374
iter_num: 3861, on_card_num: 52, preempted blk num: 10374
iter_num: 3862, on_card_num: 52, preempted blk num: 10374
to recompute 1: ('736', 11)
to recompute 1: ('735', 18)
iter_num: 3863, on_card_num: 50, preempted blk num: 10380
to recompute 1: ('734', 33)
iter_num: 3864, on_card_num: 49, preempted blk num: 10384
to recompute 1: ('733', 313)
iter_num: 3865, on_card_num: 48, preempted blk num: 10424
iter_num: 3866, on_card_num: 48, preempted blk num: 10424
iter_num: 3867, on_card_num: 46, preempted blk num: 10424
iter_num: 3868, on_card_num: 47, preempted blk num: 10424
iter_num: 3869, on_card_num: 50, preempted blk num: 10424
iter_num: 3870, on_card_num: 51, preempted blk num: 10424
iter_num: 3871, on_card_num: 51, preempted blk num: 10424
iter_num: 3872, on_card_num: 51, preempted blk num: 10424
iter_num: 3873, on_card_num: 50, preempted blk num: 10424
iter_num: 3874, on_card_num: 50, preempted blk num: 10424
iter_num: 3875, on_card_num: 50, preempted blk num: 10424
iter_num: 3876, on_card_num: 50, preempted blk num: 10424
iter_num: 3877, on_card_num: 50, preempted blk num: 10424
iter_num: 3878, on_card_num: 49, preempted blk num: 10424
iter_num: 3879, on_card_num: 49, preempted blk num: 10424
iter_num: 3880, on_card_num: 49, preempted blk num: 10424
iter_num: 3881, on_card_num: 48, preempted blk num: 10424
iter_num: 3882, on_card_num: 48, preempted blk num: 10424
iter_num: 3883, on_card_num: 48, preempted blk num: 10424
iter_num: 3884, on_card_num: 48, preempted blk num: 10424
iter_num: 3885, on_card_num: 48, preempted blk num: 10424
iter_num: 3886, on_card_num: 47, preempted blk num: 10424
iter_num: 3887, on_card_num: 48, preempted blk num: 10424
iter_num: 3888, on_card_num: 48, preempted blk num: 10424
iter_num: 3889, on_card_num: 48, preempted blk num: 10424
iter_num: 3890, on_card_num: 48, preempted blk num: 10424
iter_num: 3891, on_card_num: 48, preempted blk num: 10424
iter_num: 3892, on_card_num: 48, preempted blk num: 10424
iter_num: 3893, on_card_num: 47, preempted blk num: 10424
iter_num: 3894, on_card_num: 47, preempted blk num: 10424
iter_num: 3895, on_card_num: 47, preempted blk num: 10424
iter_num: 3896, on_card_num: 47, preempted blk num: 10424
iter_num: 3897, on_card_num: 47, preempted blk num: 10424
iter_num: 3898, on_card_num: 47, preempted blk num: 10424
iter_num: 3899, on_card_num: 47, preempted blk num: 10424
iter_num: 3900, on_card_num: 47, preempted blk num: 10424
iter_num: 3901, on_card_num: 47, preempted blk num: 10424
to recompute 1: ('738', 907)
iter_num: 3902, on_card_num: 46, preempted blk num: 10538
iter_num: 3903, on_card_num: 46, preempted blk num: 10538
iter_num: 3904, on_card_num: 46, preempted blk num: 10538
iter_num: 3905, on_card_num: 46, preempted blk num: 10538
iter_num: 3906, on_card_num: 46, preempted blk num: 10538
iter_num: 3907, on_card_num: 46, preempted blk num: 10538
iter_num: 3908, on_card_num: 46, preempted blk num: 10538
iter_num: 3909, on_card_num: 46, preempted blk num: 10538
iter_num: 3910, on_card_num: 46, preempted blk num: 10538
iter_num: 3911, on_card_num: 46, preempted blk num: 10538
iter_num: 3912, on_card_num: 45, preempted blk num: 10538
iter_num: 3913, on_card_num: 44, preempted blk num: 10538
iter_num: 3914, on_card_num: 45, preempted blk num: 10538
iter_num: 3915, on_card_num: 45, preempted blk num: 10538
iter_num: 3916, on_card_num: 45, preempted blk num: 10538
iter_num: 3917, on_card_num: 45, preempted blk num: 10538
iter_num: 3918, on_card_num: 45, preempted blk num: 10538
iter_num: 3919, on_card_num: 44, preempted blk num: 10538
iter_num: 3920, on_card_num: 44, preempted blk num: 10538
iter_num: 3921, on_card_num: 44, preempted blk num: 10538
iter_num: 3922, on_card_num: 44, preempted blk num: 10538
to recompute 1: ('738', 916)
iter_num: 3923, on_card_num: 43, preempted blk num: 10654
iter_num: 3924, on_card_num: 43, preempted blk num: 10654
iter_num: 3925, on_card_num: 43, preempted blk num: 10654
iter_num: 3926, on_card_num: 43, preempted blk num: 10654
iter_num: 3927, on_card_num: 43, preempted blk num: 10654
iter_num: 3928, on_card_num: 43, preempted blk num: 10654
iter_num: 3929, on_card_num: 43, preempted blk num: 10654
iter_num: 3930, on_card_num: 42, preempted blk num: 10654
iter_num: 3931, on_card_num: 42, preempted blk num: 10654
iter_num: 3932, on_card_num: 42, preempted blk num: 10654
iter_num: 3933, on_card_num: 42, preempted blk num: 10654
iter_num: 3934, on_card_num: 42, preempted blk num: 10654
iter_num: 3935, on_card_num: 42, preempted blk num: 10654
iter_num: 3936, on_card_num: 42, preempted blk num: 10654
iter_num: 3937, on_card_num: 42, preempted blk num: 10654
iter_num: 3938, on_card_num: 41, preempted blk num: 10654
iter_num: 3939, on_card_num: 41, preempted blk num: 10654
iter_num: 3940, on_card_num: 41, preempted blk num: 10654
iter_num: 3941, on_card_num: 40, preempted blk num: 10654
iter_num: 3942, on_card_num: 41, preempted blk num: 10654
iter_num: 3943, on_card_num: 41, preempted blk num: 10654
iter_num: 3944, on_card_num: 41, preempted blk num: 10654
iter_num: 3945, on_card_num: 41, preempted blk num: 10654
iter_num: 3946, on_card_num: 41, preempted blk num: 10654
iter_num: 3947, on_card_num: 41, preempted blk num: 10654
iter_num: 3948, on_card_num: 41, preempted blk num: 10654
iter_num: 3949, on_card_num: 41, preempted blk num: 10654
iter_num: 3950, on_card_num: 40, preempted blk num: 10654
iter_num: 3951, on_card_num: 41, preempted blk num: 10654
iter_num: 3952, on_card_num: 43, preempted blk num: 10654
iter_num: 3953, on_card_num: 43, preempted blk num: 10654
iter_num: 3954, on_card_num: 43, preempted blk num: 10654
iter_num: 3955, on_card_num: 43, preempted blk num: 10654
iter_num: 3956, on_card_num: 43, preempted blk num: 10654
iter_num: 3957, on_card_num: 43, preempted blk num: 10654
iter_num: 3958, on_card_num: 43, preempted blk num: 10654
to recompute 1: ('741', 21)
to recompute 1: ('740', 119)
iter_num: 3959, on_card_num: 40, preempted blk num: 10674
iter_num: 3960, on_card_num: 42, preempted blk num: 10674
iter_num: 3961, on_card_num: 43, preempted blk num: 10674
iter_num: 3962, on_card_num: 44, preempted blk num: 10674
iter_num: 3963, on_card_num: 44, preempted blk num: 10674
iter_num: 3964, on_card_num: 44, preempted blk num: 10674
iter_num: 3965, on_card_num: 44, preempted blk num: 10674
iter_num: 3966, on_card_num: 44, preempted blk num: 10674
iter_num: 3967, on_card_num: 44, preempted blk num: 10674
iter_num: 3968, on_card_num: 44, preempted blk num: 10674
iter_num: 3969, on_card_num: 44, preempted blk num: 10674
to recompute 1: ('743', 197)
iter_num: 3970, on_card_num: 43, preempted blk num: 10700
iter_num: 3971, on_card_num: 43, preempted blk num: 10700
iter_num: 3972, on_card_num: 43, preempted blk num: 10700
iter_num: 3973, on_card_num: 43, preempted blk num: 10700
to recompute 2: ('742', 575)
iter_num: 3974, on_card_num: 42, preempted blk num: 10772
iter_num: 3975, on_card_num: 42, preempted blk num: 10772
iter_num: 3976, on_card_num: 41, preempted blk num: 10772
iter_num: 3977, on_card_num: 42, preempted blk num: 10772
iter_num: 3978, on_card_num: 44, preempted blk num: 10772
iter_num: 3979, on_card_num: 45, preempted blk num: 10772
iter_num: 3980, on_card_num: 45, preempted blk num: 10772
iter_num: 3981, on_card_num: 45, preempted blk num: 10772
iter_num: 3982, on_card_num: 45, preempted blk num: 10772
iter_num: 3983, on_card_num: 45, preempted blk num: 10772
iter_num: 3984, on_card_num: 45, preempted blk num: 10772
iter_num: 3985, on_card_num: 45, preempted blk num: 10772
iter_num: 3986, on_card_num: 45, preempted blk num: 10772
iter_num: 3987, on_card_num: 45, preempted blk num: 10772
iter_num: 3988, on_card_num: 45, preempted blk num: 10772
to recompute 1: ('745', 30)
iter_num: 3989, on_card_num: 44, preempted blk num: 10776
to recompute 1: ('744', 251)
iter_num: 3990, on_card_num: 43, preempted blk num: 10808
iter_num: 3991, on_card_num: 43, preempted blk num: 10808
iter_num: 3992, on_card_num: 42, preempted blk num: 10808
iter_num: 3993, on_card_num: 44, preempted blk num: 10808
iter_num: 3994, on_card_num: 44, preempted blk num: 10808
iter_num: 3995, on_card_num: 44, preempted blk num: 10808
iter_num: 3996, on_card_num: 44, preempted blk num: 10808
iter_num: 3997, on_card_num: 44, preempted blk num: 10808
iter_num: 3998, on_card_num: 43, preempted blk num: 10808
iter_num: 3999, on_card_num: 44, preempted blk num: 10808
iter_num: 4000, on_card_num: 43, preempted blk num: 10808
iter_num: 4001, on_card_num: 43, preempted blk num: 10808
iter_num: 4002, on_card_num: 43, preempted blk num: 10808
iter_num: 4003, on_card_num: 43, preempted blk num: 10808
iter_num: 4004, on_card_num: 43, preempted blk num: 10808
iter_num: 4005, on_card_num: 43, preempted blk num: 10808
iter_num: 4006, on_card_num: 43, preempted blk num: 10808
to recompute 1: ('746', 476)
iter_num: 4007, on_card_num: 41, preempted blk num: 10868
iter_num: 4008, on_card_num: 42, preempted blk num: 10868
iter_num: 4009, on_card_num: 42, preempted blk num: 10868
iter_num: 4010, on_card_num: 42, preempted blk num: 10868
iter_num: 4011, on_card_num: 42, preempted blk num: 10868
iter_num: 4012, on_card_num: 42, preempted blk num: 10868
iter_num: 4013, on_card_num: 42, preempted blk num: 10868
to recompute 1: ('746', 482)
iter_num: 4014, on_card_num: 40, preempted blk num: 10930
iter_num: 4015, on_card_num: 42, preempted blk num: 10930
iter_num: 4016, on_card_num: 42, preempted blk num: 10930
iter_num: 4017, on_card_num: 42, preempted blk num: 10930
iter_num: 4018, on_card_num: 42, preempted blk num: 10930
to recompute 1: ('747', 461)
iter_num: 4019, on_card_num: 41, preempted blk num: 10988
iter_num: 4020, on_card_num: 41, preempted blk num: 10988
iter_num: 4021, on_card_num: 41, preempted blk num: 10988
iter_num: 4022, on_card_num: 41, preempted blk num: 10988
iter_num: 4023, on_card_num: 40, preempted blk num: 10988
iter_num: 4024, on_card_num: 41, preempted blk num: 10988
iter_num: 4025, on_card_num: 41, preempted blk num: 10988
iter_num: 4026, on_card_num: 41, preempted blk num: 10988
iter_num: 4027, on_card_num: 40, preempted blk num: 10988
iter_num: 4028, on_card_num: 41, preempted blk num: 10988
iter_num: 4029, on_card_num: 42, preempted blk num: 10988
iter_num: 4030, on_card_num: 42, preempted blk num: 10988
iter_num: 4031, on_card_num: 42, preempted blk num: 10988
iter_num: 4032, on_card_num: 42, preempted blk num: 10988
iter_num: 4033, on_card_num: 42, preempted blk num: 10988
iter_num: 4034, on_card_num: 42, preempted blk num: 10988
iter_num: 4035, on_card_num: 42, preempted blk num: 10988
to recompute 2: ('749', 15)
iter_num: 4036, on_card_num: 41, preempted blk num: 10990
to recompute 1: ('748', 338)
iter_num: 4037, on_card_num: 40, preempted blk num: 11034
iter_num: 4038, on_card_num: 40, preempted blk num: 11034
iter_num: 4039, on_card_num: 40, preempted blk num: 11034
iter_num: 4040, on_card_num: 40, preempted blk num: 11034
iter_num: 4041, on_card_num: 40, preempted blk num: 11034
iter_num: 4042, on_card_num: 40, preempted blk num: 11034
iter_num: 4043, on_card_num: 40, preempted blk num: 11034
iter_num: 4044, on_card_num: 40, preempted blk num: 11034
iter_num: 4045, on_card_num: 40, preempted blk num: 11034
to recompute 1: ('747', 481)
iter_num: 4046, on_card_num: 39, preempted blk num: 11094
iter_num: 4047, on_card_num: 39, preempted blk num: 11094
iter_num: 4048, on_card_num: 39, preempted blk num: 11094
iter_num: 4049, on_card_num: 39, preempted blk num: 11094
iter_num: 4050, on_card_num: 39, preempted blk num: 11094
iter_num: 4051, on_card_num: 39, preempted blk num: 11094
iter_num: 4052, on_card_num: 39, preempted blk num: 11094
iter_num: 4053, on_card_num: 39, preempted blk num: 11094
iter_num: 4054, on_card_num: 39, preempted blk num: 11094
iter_num: 4055, on_card_num: 38, preempted blk num: 11094
iter_num: 4056, on_card_num: 39, preempted blk num: 11094
iter_num: 4057, on_card_num: 39, preempted blk num: 11094
iter_num: 4058, on_card_num: 39, preempted blk num: 11094
iter_num: 4059, on_card_num: 39, preempted blk num: 11094
iter_num: 4060, on_card_num: 39, preempted blk num: 11094
iter_num: 4061, on_card_num: 39, preempted blk num: 11094
iter_num: 4062, on_card_num: 39, preempted blk num: 11094
iter_num: 4063, on_card_num: 39, preempted blk num: 11094
to recompute 1: ('747', 489)
iter_num: 4064, on_card_num: 38, preempted blk num: 11156
iter_num: 4065, on_card_num: 37, preempted blk num: 11156
iter_num: 4066, on_card_num: 39, preempted blk num: 11156
iter_num: 4067, on_card_num: 40, preempted blk num: 11156
iter_num: 4068, on_card_num: 40, preempted blk num: 11156
iter_num: 4069, on_card_num: 39, preempted blk num: 11156
iter_num: 4070, on_card_num: 40, preempted blk num: 11156
iter_num: 4071, on_card_num: 41, preempted blk num: 11156
iter_num: 4072, on_card_num: 42, preempted blk num: 11156
iter_num: 4073, on_card_num: 45, preempted blk num: 11156
iter_num: 4074, on_card_num: 47, preempted blk num: 11156
iter_num: 4075, on_card_num: 48, preempted blk num: 11156
iter_num: 4076, on_card_num: 47, preempted blk num: 11156
iter_num: 4077, on_card_num: 48, preempted blk num: 11156
iter_num: 4078, on_card_num: 50, preempted blk num: 11156
iter_num: 4079, on_card_num: 49, preempted blk num: 11156
iter_num: 4080, on_card_num: 48, preempted blk num: 11156
iter_num: 4081, on_card_num: 47, preempted blk num: 11156
iter_num: 4082, on_card_num: 47, preempted blk num: 11156
iter_num: 4083, on_card_num: 46, preempted blk num: 11156
iter_num: 4084, on_card_num: 47, preempted blk num: 11156
iter_num: 4085, on_card_num: 47, preempted blk num: 11156
iter_num: 4086, on_card_num: 47, preempted blk num: 11156
iter_num: 4087, on_card_num: 47, preempted blk num: 11156
iter_num: 4088, on_card_num: 47, preempted blk num: 11156
iter_num: 4089, on_card_num: 47, preempted blk num: 11156
iter_num: 4090, on_card_num: 47, preempted blk num: 11156
to recompute 1: ('762', 1010)
iter_num: 4091, on_card_num: 45, preempted blk num: 11284
iter_num: 4092, on_card_num: 46, preempted blk num: 11284
iter_num: 4093, on_card_num: 46, preempted blk num: 11284
iter_num: 4094, on_card_num: 46, preempted blk num: 11284
iter_num: 4095, on_card_num: 46, preempted blk num: 11284
iter_num: 4096, on_card_num: 46, preempted blk num: 11284
to recompute 1: ('762', 1015)
iter_num: 4097, on_card_num: 45, preempted blk num: 11412
iter_num: 4098, on_card_num: 44, preempted blk num: 11412
iter_num: 4099, on_card_num: 45, preempted blk num: 11412
iter_num: 4100, on_card_num: 44, preempted blk num: 11412
iter_num: 4101, on_card_num: 45, preempted blk num: 11412
iter_num: 4102, on_card_num: 43, preempted blk num: 11412
iter_num: 4103, on_card_num: 45, preempted blk num: 11412
iter_num: 4104, on_card_num: 48, preempted blk num: 11412
iter_num: 4105, on_card_num: 49, preempted blk num: 11412
iter_num: 4106, on_card_num: 50, preempted blk num: 11412
iter_num: 4107, on_card_num: 50, preempted blk num: 11412
iter_num: 4108, on_card_num: 49, preempted blk num: 11412
iter_num: 4109, on_card_num: 49, preempted blk num: 11412
iter_num: 4110, on_card_num: 49, preempted blk num: 11412
iter_num: 4111, on_card_num: 49, preempted blk num: 11412
iter_num: 4112, on_card_num: 49, preempted blk num: 11412
iter_num: 4113, on_card_num: 48, preempted blk num: 11412
iter_num: 4114, on_card_num: 49, preempted blk num: 11412
iter_num: 4115, on_card_num: 50, preempted blk num: 11412
iter_num: 4116, on_card_num: 50, preempted blk num: 11412
iter_num: 4117, on_card_num: 50, preempted blk num: 11412
iter_num: 4118, on_card_num: 50, preempted blk num: 11412
iter_num: 4119, on_card_num: 50, preempted blk num: 11412
to recompute 1: ('772', 12)
iter_num: 4120, on_card_num: 48, preempted blk num: 11414
iter_num: 4121, on_card_num: 48, preempted blk num: 11414
to recompute 1: ('771', 500)
iter_num: 4122, on_card_num: 47, preempted blk num: 11478
iter_num: 4123, on_card_num: 47, preempted blk num: 11478
iter_num: 4124, on_card_num: 47, preempted blk num: 11478
iter_num: 4125, on_card_num: 47, preempted blk num: 11478
iter_num: 4126, on_card_num: 46, preempted blk num: 11478
iter_num: 4127, on_card_num: 47, preempted blk num: 11478
iter_num: 4128, on_card_num: 48, preempted blk num: 11478
iter_num: 4129, on_card_num: 47, preempted blk num: 11478
iter_num: 4130, on_card_num: 46, preempted blk num: 11478
iter_num: 4131, on_card_num: 46, preempted blk num: 11478
iter_num: 4132, on_card_num: 46, preempted blk num: 11478
iter_num: 4133, on_card_num: 45, preempted blk num: 11478
iter_num: 4134, on_card_num: 46, preempted blk num: 11478
iter_num: 4135, on_card_num: 51, preempted blk num: 11478
iter_num: 4136, on_card_num: 51, preempted blk num: 11478
iter_num: 4137, on_card_num: 50, preempted blk num: 11478
iter_num: 4138, on_card_num: 51, preempted blk num: 11478
iter_num: 4139, on_card_num: 52, preempted blk num: 11478
iter_num: 4140, on_card_num: 52, preempted blk num: 11478
iter_num: 4141, on_card_num: 52, preempted blk num: 11478
iter_num: 4142, on_card_num: 52, preempted blk num: 11478
iter_num: 4143, on_card_num: 52, preempted blk num: 11478
iter_num: 4144, on_card_num: 52, preempted blk num: 11478
to recompute 1: ('780', 186)
iter_num: 4145, on_card_num: 50, preempted blk num: 11502
iter_num: 4146, on_card_num: 52, preempted blk num: 11502
iter_num: 4147, on_card_num: 52, preempted blk num: 11502
iter_num: 4148, on_card_num: 52, preempted blk num: 11502
iter_num: 4149, on_card_num: 51, preempted blk num: 11502
iter_num: 4150, on_card_num: 53, preempted blk num: 11502
iter_num: 4151, on_card_num: 55, preempted blk num: 11502
iter_num: 4152, on_card_num: 53, preempted blk num: 11502
iter_num: 4153, on_card_num: 54, preempted blk num: 11502
iter_num: 4154, on_card_num: 55, preempted blk num: 11502
iter_num: 4155, on_card_num: 55, preempted blk num: 11502
iter_num: 4156, on_card_num: 55, preempted blk num: 11502
iter_num: 4157, on_card_num: 55, preempted blk num: 11502
iter_num: 4158, on_card_num: 55, preempted blk num: 11502
to recompute 1: ('787', 321)
iter_num: 4159, on_card_num: 54, preempted blk num: 11542
iter_num: 4160, on_card_num: 54, preempted blk num: 11542
iter_num: 4161, on_card_num: 53, preempted blk num: 11542
iter_num: 4162, on_card_num: 54, preempted blk num: 11542
iter_num: 4163, on_card_num: 54, preempted blk num: 11542
iter_num: 4164, on_card_num: 54, preempted blk num: 11542
iter_num: 4165, on_card_num: 54, preempted blk num: 11542
to recompute 1: ('787', 325)
iter_num: 4166, on_card_num: 53, preempted blk num: 11584
iter_num: 4167, on_card_num: 53, preempted blk num: 11584
iter_num: 4168, on_card_num: 53, preempted blk num: 11584
iter_num: 4169, on_card_num: 52, preempted blk num: 11584
iter_num: 4170, on_card_num: 53, preempted blk num: 11584
iter_num: 4171, on_card_num: 51, preempted blk num: 11584
iter_num: 4172, on_card_num: 52, preempted blk num: 11584
iter_num: 4173, on_card_num: 53, preempted blk num: 11584
iter_num: 4174, on_card_num: 55, preempted blk num: 11584
iter_num: 4175, on_card_num: 55, preempted blk num: 11584
iter_num: 4176, on_card_num: 55, preempted blk num: 11584
iter_num: 4177, on_card_num: 55, preempted blk num: 11584
iter_num: 4178, on_card_num: 54, preempted blk num: 11584
iter_num: 4179, on_card_num: 55, preempted blk num: 11584
iter_num: 4180, on_card_num: 55, preempted blk num: 11584
iter_num: 4181, on_card_num: 55, preempted blk num: 11584
iter_num: 4182, on_card_num: 55, preempted blk num: 11584
iter_num: 4183, on_card_num: 55, preempted blk num: 11584
iter_num: 4184, on_card_num: 55, preempted blk num: 11584
iter_num: 4185, on_card_num: 55, preempted blk num: 11584
to recompute 1: ('792', 24)
to recompute 1: ('791', 29)
iter_num: 4186, on_card_num: 53, preempted blk num: 11592
to recompute 1: ('790', 78)
iter_num: 4187, on_card_num: 52, preempted blk num: 11602
to recompute 1: ('788', 101)
iter_num: 4188, on_card_num: 50, preempted blk num: 11616
iter_num: 4189, on_card_num: 49, preempted blk num: 11616
iter_num: 4190, on_card_num: 53, preempted blk num: 11616
iter_num: 4191, on_card_num: 53, preempted blk num: 11616
iter_num: 4192, on_card_num: 53, preempted blk num: 11616
iter_num: 4193, on_card_num: 53, preempted blk num: 11616
iter_num: 4194, on_card_num: 53, preempted blk num: 11616
iter_num: 4195, on_card_num: 53, preempted blk num: 11616
to recompute 1: ('792', 30)
iter_num: 4196, on_card_num: 52, preempted blk num: 11620
to recompute 1: ('791', 36)
to recompute 1: ('790', 85)
iter_num: 4197, on_card_num: 50, preempted blk num: 11638
iter_num: 4198, on_card_num: 50, preempted blk num: 11638
to recompute 1: ('788', 110)
iter_num: 4199, on_card_num: 49, preempted blk num: 11652
iter_num: 4200, on_card_num: 49, preempted blk num: 11652
to recompute 1: ('787', 351)
iter_num: 4201, on_card_num: 48, preempted blk num: 11696
iter_num: 4202, on_card_num: 47, preempted blk num: 11696
iter_num: 4203, on_card_num: 47, preempted blk num: 11696
iter_num: 4204, on_card_num: 47, preempted blk num: 11696
iter_num: 4205, on_card_num: 47, preempted blk num: 11696
iter_num: 4206, on_card_num: 47, preempted blk num: 11696
iter_num: 4207, on_card_num: 47, preempted blk num: 11696
iter_num: 4208, on_card_num: 47, preempted blk num: 11696
iter_num: 4209, on_card_num: 47, preempted blk num: 11696
iter_num: 4210, on_card_num: 47, preempted blk num: 11696
iter_num: 4211, on_card_num: 47, preempted blk num: 11696
iter_num: 4212, on_card_num: 47, preempted blk num: 11696
iter_num: 4213, on_card_num: 47, preempted blk num: 11696
to recompute 1: ('786', 964)
iter_num: 4214, on_card_num: 46, preempted blk num: 11818
iter_num: 4215, on_card_num: 46, preempted blk num: 11818
iter_num: 4216, on_card_num: 46, preempted blk num: 11818
iter_num: 4217, on_card_num: 45, preempted blk num: 11818
iter_num: 4218, on_card_num: 46, preempted blk num: 11818
iter_num: 4219, on_card_num: 47, preempted blk num: 11818
iter_num: 4220, on_card_num: 47, preempted blk num: 11818
iter_num: 4221, on_card_num: 47, preempted blk num: 11818
iter_num: 4222, on_card_num: 47, preempted blk num: 11818
iter_num: 4223, on_card_num: 47, preempted blk num: 11818
iter_num: 4224, on_card_num: 47, preempted blk num: 11818
to recompute 1: ('787', 357)
iter_num: 4225, on_card_num: 46, preempted blk num: 11864
iter_num: 4226, on_card_num: 46, preempted blk num: 11864
iter_num: 4227, on_card_num: 46, preempted blk num: 11864
iter_num: 4228, on_card_num: 46, preempted blk num: 11864
iter_num: 4229, on_card_num: 45, preempted blk num: 11864
iter_num: 4230, on_card_num: 47, preempted blk num: 11864
iter_num: 4231, on_card_num: 50, preempted blk num: 11864
iter_num: 4232, on_card_num: 50, preempted blk num: 11864
iter_num: 4233, on_card_num: 50, preempted blk num: 11864
iter_num: 4234, on_card_num: 50, preempted blk num: 11864
iter_num: 4235, on_card_num: 50, preempted blk num: 11864
iter_num: 4236, on_card_num: 50, preempted blk num: 11864
to recompute 1: ('792', 36)
iter_num: 4237, on_card_num: 49, preempted blk num: 11870
iter_num: 4238, on_card_num: 48, preempted blk num: 11870
iter_num: 4239, on_card_num: 48, preempted blk num: 11870
to recompute 1: ('791', 45)
iter_num: 4240, on_card_num: 47, preempted blk num: 11876
to recompute 1: ('788', 120)
iter_num: 4241, on_card_num: 46, preempted blk num: 11892
iter_num: 4242, on_card_num: 46, preempted blk num: 11892
iter_num: 4243, on_card_num: 46, preempted blk num: 11892
iter_num: 4244, on_card_num: 46, preempted blk num: 11892
to recompute 1: ('787', 371)
iter_num: 4245, on_card_num: 45, preempted blk num: 11940
iter_num: 4246, on_card_num: 45, preempted blk num: 11940
iter_num: 4247, on_card_num: 45, preempted blk num: 11940
iter_num: 4248, on_card_num: 45, preempted blk num: 11940
iter_num: 4249, on_card_num: 45, preempted blk num: 11940
iter_num: 4250, on_card_num: 45, preempted blk num: 11940
iter_num: 4251, on_card_num: 45, preempted blk num: 11940
iter_num: 4252, on_card_num: 45, preempted blk num: 11940
to recompute 1: ('786', 996)
iter_num: 4253, on_card_num: 44, preempted blk num: 12066
iter_num: 4254, on_card_num: 44, preempted blk num: 12066
iter_num: 4255, on_card_num: 43, preempted blk num: 12066
iter_num: 4256, on_card_num: 44, preempted blk num: 12066
iter_num: 4257, on_card_num: 44, preempted blk num: 12066
iter_num: 4258, on_card_num: 44, preempted blk num: 12066
iter_num: 4259, on_card_num: 44, preempted blk num: 12066
iter_num: 4260, on_card_num: 43, preempted blk num: 12066
iter_num: 4261, on_card_num: 44, preempted blk num: 12066
iter_num: 4262, on_card_num: 44, preempted blk num: 12066
iter_num: 4263, on_card_num: 44, preempted blk num: 12066
iter_num: 4264, on_card_num: 43, preempted blk num: 12066
iter_num: 4265, on_card_num: 46, preempted blk num: 12066
iter_num: 4266, on_card_num: 46, preempted blk num: 12066
iter_num: 4267, on_card_num: 45, preempted blk num: 12066
iter_num: 4268, on_card_num: 46, preempted blk num: 12066
iter_num: 4269, on_card_num: 48, preempted blk num: 12066
iter_num: 4270, on_card_num: 50, preempted blk num: 12066
iter_num: 4271, on_card_num: 50, preempted blk num: 12066
iter_num: 4272, on_card_num: 50, preempted blk num: 12066
iter_num: 4273, on_card_num: 50, preempted blk num: 12066
iter_num: 4274, on_card_num: 50, preempted blk num: 12066
iter_num: 4275, on_card_num: 49, preempted blk num: 12066
iter_num: 4276, on_card_num: 49, preempted blk num: 12066
iter_num: 4277, on_card_num: 49, preempted blk num: 12066
iter_num: 4278, on_card_num: 49, preempted blk num: 12066
iter_num: 4279, on_card_num: 49, preempted blk num: 12066
iter_num: 4280, on_card_num: 49, preempted blk num: 12066
to recompute 1: ('797', 273)
iter_num: 4281, on_card_num: 47, preempted blk num: 12100
iter_num: 4282, on_card_num: 48, preempted blk num: 12100
iter_num: 4283, on_card_num: 48, preempted blk num: 12100
iter_num: 4284, on_card_num: 47, preempted blk num: 12100
iter_num: 4285, on_card_num: 48, preempted blk num: 12100
iter_num: 4286, on_card_num: 48, preempted blk num: 12100
iter_num: 4287, on_card_num: 48, preempted blk num: 12100
iter_num: 4288, on_card_num: 48, preempted blk num: 12100
iter_num: 4289, on_card_num: 48, preempted blk num: 12100
iter_num: 4290, on_card_num: 48, preempted blk num: 12100
iter_num: 4291, on_card_num: 48, preempted blk num: 12100
to recompute 1: ('798', 292)
iter_num: 4292, on_card_num: 47, preempted blk num: 12138
iter_num: 4293, on_card_num: 46, preempted blk num: 12138
iter_num: 4294, on_card_num: 47, preempted blk num: 12138
iter_num: 4295, on_card_num: 47, preempted blk num: 12138
iter_num: 4296, on_card_num: 47, preempted blk num: 12138
iter_num: 4297, on_card_num: 46, preempted blk num: 12138
iter_num: 4298, on_card_num: 46, preempted blk num: 12138
iter_num: 4299, on_card_num: 46, preempted blk num: 12138
iter_num: 4300, on_card_num: 44, preempted blk num: 12138
iter_num: 4301, on_card_num: 44, preempted blk num: 12138
iter_num: 4302, on_card_num: 44, preempted blk num: 12138
iter_num: 4303, on_card_num: 44, preempted blk num: 12138
iter_num: 4304, on_card_num: 44, preempted blk num: 12138
iter_num: 4305, on_card_num: 44, preempted blk num: 12138
iter_num: 4306, on_card_num: 44, preempted blk num: 12138
iter_num: 4307, on_card_num: 44, preempted blk num: 12138
iter_num: 4308, on_card_num: 44, preempted blk num: 12138
iter_num: 4309, on_card_num: 44, preempted blk num: 12138
iter_num: 4310, on_card_num: 44, preempted blk num: 12138
iter_num: 4311, on_card_num: 44, preempted blk num: 12138
iter_num: 4312, on_card_num: 44, preempted blk num: 12138
iter_num: 4313, on_card_num: 44, preempted blk num: 12138
iter_num: 4314, on_card_num: 44, preempted blk num: 12138
iter_num: 4315, on_card_num: 44, preempted blk num: 12138
iter_num: 4316, on_card_num: 44, preempted blk num: 12138
iter_num: 4317, on_card_num: 44, preempted blk num: 12138
to recompute 1: ('798', 316)
iter_num: 4318, on_card_num: 43, preempted blk num: 12178
iter_num: 4319, on_card_num: 42, preempted blk num: 12178
iter_num: 4320, on_card_num: 41, preempted blk num: 12178
iter_num: 4321, on_card_num: 43, preempted blk num: 12178
iter_num: 4322, on_card_num: 43, preempted blk num: 12178
iter_num: 4323, on_card_num: 43, preempted blk num: 12178
iter_num: 4324, on_card_num: 42, preempted blk num: 12178
iter_num: 4325, on_card_num: 42, preempted blk num: 12178
iter_num: 4326, on_card_num: 41, preempted blk num: 12178
iter_num: 4327, on_card_num: 41, preempted blk num: 12178
iter_num: 4328, on_card_num: 41, preempted blk num: 12178
iter_num: 4329, on_card_num: 41, preempted blk num: 12178
iter_num: 4330, on_card_num: 41, preempted blk num: 12178
iter_num: 4331, on_card_num: 41, preempted blk num: 12178
iter_num: 4332, on_card_num: 41, preempted blk num: 12178
iter_num: 4333, on_card_num: 41, preempted blk num: 12178
iter_num: 4334, on_card_num: 41, preempted blk num: 12178
iter_num: 4335, on_card_num: 41, preempted blk num: 12178
iter_num: 4336, on_card_num: 41, preempted blk num: 12178
iter_num: 4337, on_card_num: 40, preempted blk num: 12178
iter_num: 4338, on_card_num: 41, preempted blk num: 12178
iter_num: 4339, on_card_num: 41, preempted blk num: 12178
iter_num: 4340, on_card_num: 41, preempted blk num: 12178
iter_num: 4341, on_card_num: 41, preempted blk num: 12178
iter_num: 4342, on_card_num: 41, preempted blk num: 12178
iter_num: 4343, on_card_num: 41, preempted blk num: 12178
iter_num: 4344, on_card_num: 41, preempted blk num: 12178
iter_num: 4345, on_card_num: 41, preempted blk num: 12178
to recompute 1: ('800', 433)
iter_num: 4346, on_card_num: 40, preempted blk num: 12232
iter_num: 4347, on_card_num: 40, preempted blk num: 12232
iter_num: 4348, on_card_num: 39, preempted blk num: 12232
iter_num: 4349, on_card_num: 39, preempted blk num: 12232
iter_num: 4350, on_card_num: 39, preempted blk num: 12232
iter_num: 4351, on_card_num: 39, preempted blk num: 12232
iter_num: 4352, on_card_num: 39, preempted blk num: 12232
iter_num: 4353, on_card_num: 39, preempted blk num: 12232
iter_num: 4354, on_card_num: 39, preempted blk num: 12232
iter_num: 4355, on_card_num: 39, preempted blk num: 12232
iter_num: 4356, on_card_num: 39, preempted blk num: 12232
iter_num: 4357, on_card_num: 39, preempted blk num: 12232
iter_num: 4358, on_card_num: 39, preempted blk num: 12232
iter_num: 4359, on_card_num: 39, preempted blk num: 12232
iter_num: 4360, on_card_num: 39, preempted blk num: 12232
iter_num: 4361, on_card_num: 38, preempted blk num: 12232
iter_num: 4362, on_card_num: 38, preempted blk num: 12232
iter_num: 4363, on_card_num: 37, preempted blk num: 12232
iter_num: 4364, on_card_num: 38, preempted blk num: 12232
iter_num: 4365, on_card_num: 38, preempted blk num: 12232
iter_num: 4366, on_card_num: 38, preempted blk num: 12232
iter_num: 4367, on_card_num: 38, preempted blk num: 12232
iter_num: 4368, on_card_num: 38, preempted blk num: 12232
iter_num: 4369, on_card_num: 38, preempted blk num: 12232
iter_num: 4370, on_card_num: 38, preempted blk num: 12232
iter_num: 4371, on_card_num: 38, preempted blk num: 12232
iter_num: 4372, on_card_num: 38, preempted blk num: 12232
to recompute 1: ('800', 442)
iter_num: 4373, on_card_num: 37, preempted blk num: 12288
iter_num: 4374, on_card_num: 37, preempted blk num: 12288
iter_num: 4375, on_card_num: 37, preempted blk num: 12288
iter_num: 4376, on_card_num: 37, preempted blk num: 12288
iter_num: 4377, on_card_num: 37, preempted blk num: 12288
iter_num: 4378, on_card_num: 37, preempted blk num: 12288
iter_num: 4379, on_card_num: 37, preempted blk num: 12288
iter_num: 4380, on_card_num: 37, preempted blk num: 12288
iter_num: 4381, on_card_num: 35, preempted blk num: 12288
iter_num: 4382, on_card_num: 36, preempted blk num: 12288
iter_num: 4383, on_card_num: 38, preempted blk num: 12288
iter_num: 4384, on_card_num: 39, preempted blk num: 12288
iter_num: 4385, on_card_num: 40, preempted blk num: 12288
iter_num: 4386, on_card_num: 42, preempted blk num: 12288
iter_num: 4387, on_card_num: 39, preempted blk num: 12288
iter_num: 4388, on_card_num: 40, preempted blk num: 12288
iter_num: 4389, on_card_num: 41, preempted blk num: 12288
iter_num: 4390, on_card_num: 42, preempted blk num: 12288
iter_num: 4391, on_card_num: 44, preempted blk num: 12288
iter_num: 4392, on_card_num: 44, preempted blk num: 12288
iter_num: 4393, on_card_num: 44, preempted blk num: 12288
iter_num: 4394, on_card_num: 44, preempted blk num: 12288
iter_num: 4395, on_card_num: 44, preempted blk num: 12288
iter_num: 4396, on_card_num: 44, preempted blk num: 12288
iter_num: 4397, on_card_num: 42, preempted blk num: 12288
iter_num: 4398, on_card_num: 43, preempted blk num: 12288
iter_num: 4399, on_card_num: 44, preempted blk num: 12288
iter_num: 4400, on_card_num: 47, preempted blk num: 12288
iter_num: 4401, on_card_num: 48, preempted blk num: 12288
iter_num: 4402, on_card_num: 47, preempted blk num: 12288
iter_num: 4403, on_card_num: 47, preempted blk num: 12288
iter_num: 4404, on_card_num: 47, preempted blk num: 12288
iter_num: 4405, on_card_num: 46, preempted blk num: 12288
iter_num: 4406, on_card_num: 46, preempted blk num: 12288
iter_num: 4407, on_card_num: 46, preempted blk num: 12288
iter_num: 4408, on_card_num: 45, preempted blk num: 12288
iter_num: 4409, on_card_num: 46, preempted blk num: 12288
iter_num: 4410, on_card_num: 46, preempted blk num: 12288
iter_num: 4411, on_card_num: 46, preempted blk num: 12288
iter_num: 4412, on_card_num: 46, preempted blk num: 12288
iter_num: 4413, on_card_num: 45, preempted blk num: 12288
iter_num: 4414, on_card_num: 46, preempted blk num: 12288
iter_num: 4415, on_card_num: 48, preempted blk num: 12288
iter_num: 4416, on_card_num: 48, preempted blk num: 12288
iter_num: 4417, on_card_num: 48, preempted blk num: 12288
iter_num: 4418, on_card_num: 46, preempted blk num: 12288
iter_num: 4419, on_card_num: 47, preempted blk num: 12288
iter_num: 4420, on_card_num: 49, preempted blk num: 12288
iter_num: 4421, on_card_num: 50, preempted blk num: 12288
iter_num: 4422, on_card_num: 49, preempted blk num: 12288
iter_num: 4423, on_card_num: 50, preempted blk num: 12288
iter_num: 4424, on_card_num: 51, preempted blk num: 12288
iter_num: 4425, on_card_num: 51, preempted blk num: 12288
iter_num: 4426, on_card_num: 51, preempted blk num: 12288
iter_num: 4427, on_card_num: 51, preempted blk num: 12288
iter_num: 4428, on_card_num: 50, preempted blk num: 12288
iter_num: 4429, on_card_num: 51, preempted blk num: 12288
iter_num: 4430, on_card_num: 51, preempted blk num: 12288
iter_num: 4431, on_card_num: 49, preempted blk num: 12288
iter_num: 4432, on_card_num: 51, preempted blk num: 12288
iter_num: 4433, on_card_num: 52, preempted blk num: 12288
iter_num: 4434, on_card_num: 54, preempted blk num: 12288
iter_num: 4435, on_card_num: 55, preempted blk num: 12288
iter_num: 4436, on_card_num: 55, preempted blk num: 12288
iter_num: 4437, on_card_num: 53, preempted blk num: 12288
iter_num: 4438, on_card_num: 54, preempted blk num: 12288
iter_num: 4439, on_card_num: 55, preempted blk num: 12288
iter_num: 4440, on_card_num: 56, preempted blk num: 12288
iter_num: 4441, on_card_num: 57, preempted blk num: 12288
iter_num: 4442, on_card_num: 57, preempted blk num: 12288
iter_num: 4443, on_card_num: 57, preempted blk num: 12288
iter_num: 4444, on_card_num: 57, preempted blk num: 12288
iter_num: 4445, on_card_num: 56, preempted blk num: 12288
iter_num: 4446, on_card_num: 56, preempted blk num: 12288
iter_num: 4447, on_card_num: 56, preempted blk num: 12288
iter_num: 4448, on_card_num: 56, preempted blk num: 12288
iter_num: 4449, on_card_num: 56, preempted blk num: 12288
iter_num: 4450, on_card_num: 55, preempted blk num: 12288
iter_num: 4451, on_card_num: 56, preempted blk num: 12288
iter_num: 4452, on_card_num: 57, preempted blk num: 12288
iter_num: 4453, on_card_num: 56, preempted blk num: 12288
iter_num: 4454, on_card_num: 56, preempted blk num: 12288
iter_num: 4455, on_card_num: 56, preempted blk num: 12288
iter_num: 4456, on_card_num: 56, preempted blk num: 12288
iter_num: 4457, on_card_num: 54, preempted blk num: 12288
iter_num: 4458, on_card_num: 55, preempted blk num: 12288
iter_num: 4459, on_card_num: 58, preempted blk num: 12288
iter_num: 4460, on_card_num: 57, preempted blk num: 12288
iter_num: 4461, on_card_num: 60, preempted blk num: 12288
iter_num: 4462, on_card_num: 59, preempted blk num: 12288
iter_num: 4463, on_card_num: 60, preempted blk num: 12288
iter_num: 4464, on_card_num: 59, preempted blk num: 12288
iter_num: 4465, on_card_num: 60, preempted blk num: 12288
iter_num: 4466, on_card_num: 63, preempted blk num: 12288
iter_num: 4467, on_card_num: 64, preempted blk num: 12288
iter_num: 4468, on_card_num: 67, preempted blk num: 12288
iter_num: 4469, on_card_num: 66, preempted blk num: 12288
iter_num: 4470, on_card_num: 67, preempted blk num: 12288
iter_num: 4471, on_card_num: 67, preempted blk num: 12288
iter_num: 4472, on_card_num: 67, preempted blk num: 12288
iter_num: 4473, on_card_num: 67, preempted blk num: 12288
iter_num: 4474, on_card_num: 66, preempted blk num: 12288
iter_num: 4475, on_card_num: 66, preempted blk num: 12288
iter_num: 4476, on_card_num: 66, preempted blk num: 12288
to recompute 1: ('857', 317)
iter_num: 4477, on_card_num: 65, preempted blk num: 12328
iter_num: 4478, on_card_num: 65, preempted blk num: 12328
iter_num: 4479, on_card_num: 65, preempted blk num: 12328
iter_num: 4480, on_card_num: 65, preempted blk num: 12328
to recompute 1: ('856', 21)
to recompute 1: ('855', 20)
iter_num: 4481, on_card_num: 63, preempted blk num: 12336
to recompute 1: ('854', 87)
iter_num: 4482, on_card_num: 62, preempted blk num: 12348
iter_num: 4483, on_card_num: 62, preempted blk num: 12348
to recompute 1: ('853', 701)
iter_num: 4484, on_card_num: 61, preempted blk num: 12436
iter_num: 4485, on_card_num: 61, preempted blk num: 12436
iter_num: 4486, on_card_num: 61, preempted blk num: 12436
iter_num: 4487, on_card_num: 61, preempted blk num: 12436
iter_num: 4488, on_card_num: 61, preempted blk num: 12436
iter_num: 4489, on_card_num: 61, preempted blk num: 12436
iter_num: 4490, on_card_num: 60, preempted blk num: 12436
iter_num: 4491, on_card_num: 60, preempted blk num: 12436
iter_num: 4492, on_card_num: 60, preempted blk num: 12436
iter_num: 4493, on_card_num: 59, preempted blk num: 12436
iter_num: 4494, on_card_num: 59, preempted blk num: 12436
iter_num: 4495, on_card_num: 59, preempted blk num: 12436
iter_num: 4496, on_card_num: 58, preempted blk num: 12436
iter_num: 4497, on_card_num: 59, preempted blk num: 12436
iter_num: 4498, on_card_num: 62, preempted blk num: 12436
iter_num: 4499, on_card_num: 63, preempted blk num: 12436
iter_num: 4500, on_card_num: 63, preempted blk num: 12436
iter_num: 4501, on_card_num: 63, preempted blk num: 12436
iter_num: 4502, on_card_num: 63, preempted blk num: 12436
iter_num: 4503, on_card_num: 63, preempted blk num: 12436
iter_num: 4504, on_card_num: 63, preempted blk num: 12436
to recompute 1: ('857', 323)
iter_num: 4505, on_card_num: 62, preempted blk num: 12478
iter_num: 4506, on_card_num: 62, preempted blk num: 12478
iter_num: 4507, on_card_num: 62, preempted blk num: 12478
iter_num: 4508, on_card_num: 62, preempted blk num: 12478
iter_num: 4509, on_card_num: 62, preempted blk num: 12478
iter_num: 4510, on_card_num: 62, preempted blk num: 12478
to recompute 1: ('856', 33)
to recompute 1: ('855', 32)
iter_num: 4511, on_card_num: 60, preempted blk num: 12486
to recompute 1: ('854', 100)
iter_num: 4512, on_card_num: 59, preempted blk num: 12500
iter_num: 4513, on_card_num: 59, preempted blk num: 12500
to recompute 1: ('853', 716)
iter_num: 4514, on_card_num: 58, preempted blk num: 12590
iter_num: 4515, on_card_num: 58, preempted blk num: 12590
iter_num: 4516, on_card_num: 58, preempted blk num: 12590
iter_num: 4517, on_card_num: 57, preempted blk num: 12590
iter_num: 4518, on_card_num: 57, preempted blk num: 12590
iter_num: 4519, on_card_num: 57, preempted blk num: 12590
iter_num: 4520, on_card_num: 57, preempted blk num: 12590
iter_num: 4521, on_card_num: 57, preempted blk num: 12590
iter_num: 4522, on_card_num: 57, preempted blk num: 12590
iter_num: 4523, on_card_num: 57, preempted blk num: 12590
iter_num: 4524, on_card_num: 57, preempted blk num: 12590
iter_num: 4525, on_card_num: 56, preempted blk num: 12590
iter_num: 4526, on_card_num: 56, preempted blk num: 12590
iter_num: 4527, on_card_num: 56, preempted blk num: 12590
iter_num: 4528, on_card_num: 56, preempted blk num: 12590
to recompute 1: ('852', 68)
iter_num: 4529, on_card_num: 55, preempted blk num: 12600
iter_num: 4530, on_card_num: 55, preempted blk num: 12600
to recompute 1: ('850', 84)
iter_num: 4531, on_card_num: 54, preempted blk num: 12612
to recompute 1: ('849', 624)
iter_num: 4532, on_card_num: 53, preempted blk num: 12690
iter_num: 4533, on_card_num: 53, preempted blk num: 12690
iter_num: 4534, on_card_num: 52, preempted blk num: 12690
iter_num: 4535, on_card_num: 52, preempted blk num: 12690
iter_num: 4536, on_card_num: 52, preempted blk num: 12690
iter_num: 4537, on_card_num: 52, preempted blk num: 12690
iter_num: 4538, on_card_num: 52, preempted blk num: 12690
iter_num: 4539, on_card_num: 52, preempted blk num: 12690
iter_num: 4540, on_card_num: 52, preempted blk num: 12690
iter_num: 4541, on_card_num: 52, preempted blk num: 12690
iter_num: 4542, on_card_num: 52, preempted blk num: 12690
iter_num: 4543, on_card_num: 52, preempted blk num: 12690
iter_num: 4544, on_card_num: 51, preempted blk num: 12690
iter_num: 4545, on_card_num: 52, preempted blk num: 12690
iter_num: 4546, on_card_num: 54, preempted blk num: 12690
iter_num: 4547, on_card_num: 54, preempted blk num: 12690
iter_num: 4548, on_card_num: 54, preempted blk num: 12690
iter_num: 4549, on_card_num: 54, preempted blk num: 12690
iter_num: 4550, on_card_num: 54, preempted blk num: 12690
iter_num: 4551, on_card_num: 54, preempted blk num: 12690
iter_num: 4552, on_card_num: 53, preempted blk num: 12690
iter_num: 4553, on_card_num: 53, preempted blk num: 12690
iter_num: 4554, on_card_num: 53, preempted blk num: 12690
iter_num: 4555, on_card_num: 53, preempted blk num: 12690
iter_num: 4556, on_card_num: 52, preempted blk num: 12690
iter_num: 4557, on_card_num: 52, preempted blk num: 12690
iter_num: 4558, on_card_num: 52, preempted blk num: 12690
iter_num: 4559, on_card_num: 52, preempted blk num: 12690
iter_num: 4560, on_card_num: 51, preempted blk num: 12690
iter_num: 4561, on_card_num: 51, preempted blk num: 12690
iter_num: 4562, on_card_num: 51, preempted blk num: 12690
iter_num: 4563, on_card_num: 51, preempted blk num: 12690
iter_num: 4564, on_card_num: 50, preempted blk num: 12690
iter_num: 4565, on_card_num: 51, preempted blk num: 12690
iter_num: 4566, on_card_num: 51, preempted blk num: 12690
iter_num: 4567, on_card_num: 50, preempted blk num: 12690
iter_num: 4568, on_card_num: 50, preempted blk num: 12690
iter_num: 4569, on_card_num: 50, preempted blk num: 12690
iter_num: 4570, on_card_num: 50, preempted blk num: 12690
iter_num: 4571, on_card_num: 50, preempted blk num: 12690
iter_num: 4572, on_card_num: 50, preempted blk num: 12690
iter_num: 4573, on_card_num: 50, preempted blk num: 12690
to recompute 1: ('853', 725)
iter_num: 4574, on_card_num: 49, preempted blk num: 12782
iter_num: 4575, on_card_num: 49, preempted blk num: 12782
iter_num: 4576, on_card_num: 49, preempted blk num: 12782
iter_num: 4577, on_card_num: 49, preempted blk num: 12782
iter_num: 4578, on_card_num: 49, preempted blk num: 12782
iter_num: 4579, on_card_num: 49, preempted blk num: 12782
iter_num: 4580, on_card_num: 49, preempted blk num: 12782
iter_num: 4581, on_card_num: 48, preempted blk num: 12782
iter_num: 4582, on_card_num: 48, preempted blk num: 12782
iter_num: 4583, on_card_num: 48, preempted blk num: 12782
iter_num: 4584, on_card_num: 48, preempted blk num: 12782
iter_num: 4585, on_card_num: 48, preempted blk num: 12782
iter_num: 4586, on_card_num: 48, preempted blk num: 12782
iter_num: 4587, on_card_num: 48, preempted blk num: 12782
iter_num: 4588, on_card_num: 48, preempted blk num: 12782
iter_num: 4589, on_card_num: 48, preempted blk num: 12782
iter_num: 4590, on_card_num: 48, preempted blk num: 12782
iter_num: 4591, on_card_num: 48, preempted blk num: 12782
to recompute 1: ('852', 113)
iter_num: 4592, on_card_num: 47, preempted blk num: 12796
iter_num: 4593, on_card_num: 47, preempted blk num: 12796
to recompute 1: ('850', 131)
iter_num: 4594, on_card_num: 46, preempted blk num: 12814
iter_num: 4595, on_card_num: 46, preempted blk num: 12814
iter_num: 4596, on_card_num: 46, preempted blk num: 12814
to recompute 1: ('849', 674)
iter_num: 4597, on_card_num: 44, preempted blk num: 12900
iter_num: 4598, on_card_num: 43, preempted blk num: 12900
iter_num: 4599, on_card_num: 44, preempted blk num: 12900
iter_num: 4600, on_card_num: 46, preempted blk num: 12900
iter_num: 4601, on_card_num: 46, preempted blk num: 12900
iter_num: 4602, on_card_num: 46, preempted blk num: 12900
iter_num: 4603, on_card_num: 46, preempted blk num: 12900
iter_num: 4604, on_card_num: 46, preempted blk num: 12900
iter_num: 4605, on_card_num: 46, preempted blk num: 12900
to recompute 1: ('852', 119)
iter_num: 4606, on_card_num: 45, preempted blk num: 12916
iter_num: 4607, on_card_num: 45, preempted blk num: 12916
to recompute 1: ('850', 139)
iter_num: 4608, on_card_num: 44, preempted blk num: 12934
iter_num: 4609, on_card_num: 44, preempted blk num: 12934
iter_num: 4610, on_card_num: 44, preempted blk num: 12934
iter_num: 4611, on_card_num: 44, preempted blk num: 12934
iter_num: 4612, on_card_num: 44, preempted blk num: 12934
to recompute 1: ('849', 687)
iter_num: 4613, on_card_num: 43, preempted blk num: 13020
iter_num: 4614, on_card_num: 43, preempted blk num: 13020
iter_num: 4615, on_card_num: 43, preempted blk num: 13020
iter_num: 4616, on_card_num: 43, preempted blk num: 13020
iter_num: 4617, on_card_num: 42, preempted blk num: 13020
iter_num: 4618, on_card_num: 43, preempted blk num: 13020
iter_num: 4619, on_card_num: 44, preempted blk num: 13020
iter_num: 4620, on_card_num: 43, preempted blk num: 13020
iter_num: 4621, on_card_num: 44, preempted blk num: 13020
iter_num: 4622, on_card_num: 44, preempted blk num: 13020
iter_num: 4623, on_card_num: 44, preempted blk num: 13020
iter_num: 4624, on_card_num: 44, preempted blk num: 13020
iter_num: 4625, on_card_num: 44, preempted blk num: 13020
iter_num: 4626, on_card_num: 44, preempted blk num: 13020
iter_num: 4627, on_card_num: 44, preempted blk num: 13020
iter_num: 4628, on_card_num: 44, preempted blk num: 13020
iter_num: 4629, on_card_num: 43, preempted blk num: 13020
iter_num: 4630, on_card_num: 44, preempted blk num: 13020
iter_num: 4631, on_card_num: 44, preempted blk num: 13020
iter_num: 4632, on_card_num: 44, preempted blk num: 13020
iter_num: 4633, on_card_num: 44, preempted blk num: 13020
iter_num: 4634, on_card_num: 43, preempted blk num: 13020
iter_num: 4635, on_card_num: 43, preempted blk num: 13020
iter_num: 4636, on_card_num: 43, preempted blk num: 13020
iter_num: 4637, on_card_num: 43, preempted blk num: 13020
iter_num: 4638, on_card_num: 43, preempted blk num: 13020
iter_num: 4639, on_card_num: 43, preempted blk num: 13020
iter_num: 4640, on_card_num: 43, preempted blk num: 13020
iter_num: 4641, on_card_num: 41, preempted blk num: 13020
iter_num: 4642, on_card_num: 44, preempted blk num: 13020
iter_num: 4643, on_card_num: 44, preempted blk num: 13020
iter_num: 4644, on_card_num: 44, preempted blk num: 13020
iter_num: 4645, on_card_num: 43, preempted blk num: 13020
iter_num: 4646, on_card_num: 45, preempted blk num: 13020
iter_num: 4647, on_card_num: 44, preempted blk num: 13020
iter_num: 4648, on_card_num: 43, preempted blk num: 13020
iter_num: 4649, on_card_num: 44, preempted blk num: 13020
iter_num: 4650, on_card_num: 47, preempted blk num: 13020
iter_num: 4651, on_card_num: 47, preempted blk num: 13020
iter_num: 4652, on_card_num: 47, preempted blk num: 13020
iter_num: 4653, on_card_num: 47, preempted blk num: 13020
iter_num: 4654, on_card_num: 47, preempted blk num: 13020
iter_num: 4655, on_card_num: 47, preempted blk num: 13020
iter_num: 4656, on_card_num: 45, preempted blk num: 13020
iter_num: 4657, on_card_num: 45, preempted blk num: 13020
iter_num: 4658, on_card_num: 45, preempted blk num: 13020
iter_num: 4659, on_card_num: 45, preempted blk num: 13020
iter_num: 4660, on_card_num: 44, preempted blk num: 13020
iter_num: 4661, on_card_num: 43, preempted blk num: 13020
iter_num: 4662, on_card_num: 44, preempted blk num: 13020
iter_num: 4663, on_card_num: 47, preempted blk num: 13020
iter_num: 4664, on_card_num: 48, preempted blk num: 13020
iter_num: 4665, on_card_num: 48, preempted blk num: 13020
iter_num: 4666, on_card_num: 48, preempted blk num: 13020
to recompute 1: ('867', 17)
iter_num: 4667, on_card_num: 45, preempted blk num: 13022
iter_num: 4668, on_card_num: 46, preempted blk num: 13022
iter_num: 4669, on_card_num: 46, preempted blk num: 13022
iter_num: 4670, on_card_num: 46, preempted blk num: 13022
iter_num: 4671, on_card_num: 46, preempted blk num: 13022
iter_num: 4672, on_card_num: 46, preempted blk num: 13022
iter_num: 4673, on_card_num: 45, preempted blk num: 13022
iter_num: 4674, on_card_num: 46, preempted blk num: 13022
iter_num: 4675, on_card_num: 48, preempted blk num: 13022
iter_num: 4676, on_card_num: 48, preempted blk num: 13022
iter_num: 4677, on_card_num: 48, preempted blk num: 13022
iter_num: 4678, on_card_num: 48, preempted blk num: 13022
iter_num: 4679, on_card_num: 48, preempted blk num: 13022
iter_num: 4680, on_card_num: 48, preempted blk num: 13022
iter_num: 4681, on_card_num: 48, preempted blk num: 13022
iter_num: 4682, on_card_num: 47, preempted blk num: 13022
iter_num: 4683, on_card_num: 47, preempted blk num: 13022
iter_num: 4684, on_card_num: 47, preempted blk num: 13022
iter_num: 4685, on_card_num: 47, preempted blk num: 13022
iter_num: 4686, on_card_num: 47, preempted blk num: 13022
iter_num: 4687, on_card_num: 45, preempted blk num: 13022
iter_num: 4688, on_card_num: 46, preempted blk num: 13022
iter_num: 4689, on_card_num: 48, preempted blk num: 13022
iter_num: 4690, on_card_num: 45, preempted blk num: 13022
iter_num: 4691, on_card_num: 46, preempted blk num: 13022
iter_num: 4692, on_card_num: 49, preempted blk num: 13022
iter_num: 4693, on_card_num: 49, preempted blk num: 13022
iter_num: 4694, on_card_num: 48, preempted blk num: 13022
iter_num: 4695, on_card_num: 49, preempted blk num: 13022
iter_num: 4696, on_card_num: 49, preempted blk num: 13022
iter_num: 4697, on_card_num: 49, preempted blk num: 13022
iter_num: 4698, on_card_num: 49, preempted blk num: 13022
iter_num: 4699, on_card_num: 49, preempted blk num: 13022
iter_num: 4700, on_card_num: 49, preempted blk num: 13022
iter_num: 4701, on_card_num: 49, preempted blk num: 13022
iter_num: 4702, on_card_num: 49, preempted blk num: 13022
iter_num: 4703, on_card_num: 49, preempted blk num: 13022
iter_num: 4704, on_card_num: 49, preempted blk num: 13022
iter_num: 4705, on_card_num: 48, preempted blk num: 13022
iter_num: 4706, on_card_num: 48, preempted blk num: 13022
iter_num: 4707, on_card_num: 48, preempted blk num: 13022
iter_num: 4708, on_card_num: 48, preempted blk num: 13022
to recompute 1: ('878', 519)
iter_num: 4709, on_card_num: 47, preempted blk num: 13088
iter_num: 4710, on_card_num: 47, preempted blk num: 13088
iter_num: 4711, on_card_num: 47, preempted blk num: 13088
iter_num: 4712, on_card_num: 47, preempted blk num: 13088
iter_num: 4713, on_card_num: 47, preempted blk num: 13088
iter_num: 4714, on_card_num: 47, preempted blk num: 13088
iter_num: 4715, on_card_num: 47, preempted blk num: 13088
iter_num: 4716, on_card_num: 47, preempted blk num: 13088
iter_num: 4717, on_card_num: 46, preempted blk num: 13088
iter_num: 4718, on_card_num: 47, preempted blk num: 13088
iter_num: 4719, on_card_num: 47, preempted blk num: 13088
iter_num: 4720, on_card_num: 47, preempted blk num: 13088
iter_num: 4721, on_card_num: 47, preempted blk num: 13088
iter_num: 4722, on_card_num: 46, preempted blk num: 13088
iter_num: 4723, on_card_num: 46, preempted blk num: 13088
iter_num: 4724, on_card_num: 46, preempted blk num: 13088
iter_num: 4725, on_card_num: 46, preempted blk num: 13088
iter_num: 4726, on_card_num: 46, preempted blk num: 13088
iter_num: 4727, on_card_num: 46, preempted blk num: 13088
iter_num: 4728, on_card_num: 46, preempted blk num: 13088
iter_num: 4729, on_card_num: 46, preempted blk num: 13088
iter_num: 4730, on_card_num: 46, preempted blk num: 13088
iter_num: 4731, on_card_num: 46, preempted blk num: 13088
iter_num: 4732, on_card_num: 46, preempted blk num: 13088
iter_num: 4733, on_card_num: 46, preempted blk num: 13088
iter_num: 4734, on_card_num: 46, preempted blk num: 13088
iter_num: 4735, on_card_num: 45, preempted blk num: 13088
iter_num: 4736, on_card_num: 45, preempted blk num: 13088
iter_num: 4737, on_card_num: 45, preempted blk num: 13088
iter_num: 4738, on_card_num: 45, preempted blk num: 13088
iter_num: 4739, on_card_num: 45, preempted blk num: 13088
iter_num: 4740, on_card_num: 45, preempted blk num: 13088
iter_num: 4741, on_card_num: 45, preempted blk num: 13088
iter_num: 4742, on_card_num: 44, preempted blk num: 13088
iter_num: 4743, on_card_num: 44, preempted blk num: 13088
iter_num: 4744, on_card_num: 44, preempted blk num: 13088
iter_num: 4745, on_card_num: 43, preempted blk num: 13088
iter_num: 4746, on_card_num: 44, preempted blk num: 13088
iter_num: 4747, on_card_num: 46, preempted blk num: 13088
iter_num: 4748, on_card_num: 48, preempted blk num: 13088
iter_num: 4749, on_card_num: 49, preempted blk num: 13088
iter_num: 4750, on_card_num: 49, preempted blk num: 13088
iter_num: 4751, on_card_num: 49, preempted blk num: 13088
iter_num: 4752, on_card_num: 49, preempted blk num: 13088
iter_num: 4753, on_card_num: 49, preempted blk num: 13088
iter_num: 4754, on_card_num: 49, preempted blk num: 13088
iter_num: 4755, on_card_num: 49, preempted blk num: 13088
iter_num: 4756, on_card_num: 49, preempted blk num: 13088
iter_num: 4757, on_card_num: 49, preempted blk num: 13088
iter_num: 4758, on_card_num: 49, preempted blk num: 13088
iter_num: 4759, on_card_num: 49, preempted blk num: 13088
iter_num: 4760, on_card_num: 49, preempted blk num: 13088
iter_num: 4761, on_card_num: 49, preempted blk num: 13088
iter_num: 4762, on_card_num: 49, preempted blk num: 13088
iter_num: 4763, on_card_num: 49, preempted blk num: 13088
iter_num: 4764, on_card_num: 48, preempted blk num: 13088
iter_num: 4765, on_card_num: 47, preempted blk num: 13088
iter_num: 4766, on_card_num: 47, preempted blk num: 13088
iter_num: 4767, on_card_num: 47, preempted blk num: 13088
iter_num: 4768, on_card_num: 47, preempted blk num: 13088
iter_num: 4769, on_card_num: 46, preempted blk num: 13088
iter_num: 4770, on_card_num: 47, preempted blk num: 13088
iter_num: 4771, on_card_num: 47, preempted blk num: 13088
iter_num: 4772, on_card_num: 46, preempted blk num: 13088
iter_num: 4773, on_card_num: 46, preempted blk num: 13088
iter_num: 4774, on_card_num: 46, preempted blk num: 13088
iter_num: 4775, on_card_num: 46, preempted blk num: 13088
iter_num: 4776, on_card_num: 46, preempted blk num: 13088
to recompute 1: ('885', 920)
iter_num: 4777, on_card_num: 45, preempted blk num: 13204
iter_num: 4778, on_card_num: 45, preempted blk num: 13204
iter_num: 4779, on_card_num: 44, preempted blk num: 13204
iter_num: 4780, on_card_num: 44, preempted blk num: 13204
iter_num: 4781, on_card_num: 44, preempted blk num: 13204
iter_num: 4782, on_card_num: 44, preempted blk num: 13204
iter_num: 4783, on_card_num: 44, preempted blk num: 13204
iter_num: 4784, on_card_num: 44, preempted blk num: 13204
iter_num: 4785, on_card_num: 44, preempted blk num: 13204
iter_num: 4786, on_card_num: 43, preempted blk num: 13204
iter_num: 4787, on_card_num: 43, preempted blk num: 13204
iter_num: 4788, on_card_num: 43, preempted blk num: 13204
iter_num: 4789, on_card_num: 42, preempted blk num: 13204
iter_num: 4790, on_card_num: 42, preempted blk num: 13204
iter_num: 4791, on_card_num: 42, preempted blk num: 13204
iter_num: 4792, on_card_num: 42, preempted blk num: 13204
iter_num: 4793, on_card_num: 42, preempted blk num: 13204
iter_num: 4794, on_card_num: 42, preempted blk num: 13204
iter_num: 4795, on_card_num: 41, preempted blk num: 13204
iter_num: 4796, on_card_num: 42, preempted blk num: 13204
iter_num: 4797, on_card_num: 42, preempted blk num: 13204
iter_num: 4798, on_card_num: 41, preempted blk num: 13204
iter_num: 4799, on_card_num: 41, preempted blk num: 13204
iter_num: 4800, on_card_num: 41, preempted blk num: 13204
iter_num: 4801, on_card_num: 41, preempted blk num: 13204
iter_num: 4802, on_card_num: 41, preempted blk num: 13204
iter_num: 4803, on_card_num: 41, preempted blk num: 13204
iter_num: 4804, on_card_num: 40, preempted blk num: 13204
iter_num: 4805, on_card_num: 41, preempted blk num: 13204
iter_num: 4806, on_card_num: 42, preempted blk num: 13204
iter_num: 4807, on_card_num: 43, preempted blk num: 13204
iter_num: 4808, on_card_num: 43, preempted blk num: 13204
iter_num: 4809, on_card_num: 43, preempted blk num: 13204
iter_num: 4810, on_card_num: 43, preempted blk num: 13204
to recompute 1: ('888', 423)
iter_num: 4811, on_card_num: 42, preempted blk num: 13258
iter_num: 4812, on_card_num: 42, preempted blk num: 13258
iter_num: 4813, on_card_num: 42, preempted blk num: 13258
iter_num: 4814, on_card_num: 42, preempted blk num: 13258
iter_num: 4815, on_card_num: 42, preempted blk num: 13258
iter_num: 4816, on_card_num: 42, preempted blk num: 13258
iter_num: 4817, on_card_num: 42, preempted blk num: 13258
iter_num: 4818, on_card_num: 42, preempted blk num: 13258
iter_num: 4819, on_card_num: 41, preempted blk num: 13258
iter_num: 4820, on_card_num: 40, preempted blk num: 13258
iter_num: 4821, on_card_num: 41, preempted blk num: 13258
iter_num: 4822, on_card_num: 42, preempted blk num: 13258
iter_num: 4823, on_card_num: 43, preempted blk num: 13258
iter_num: 4824, on_card_num: 43, preempted blk num: 13258
iter_num: 4825, on_card_num: 43, preempted blk num: 13258
iter_num: 4826, on_card_num: 43, preempted blk num: 13258
iter_num: 4827, on_card_num: 43, preempted blk num: 13258
iter_num: 4828, on_card_num: 43, preempted blk num: 13258
to recompute 1: ('890', 441)
iter_num: 4829, on_card_num: 42, preempted blk num: 13314
iter_num: 4830, on_card_num: 41, preempted blk num: 13314
iter_num: 4831, on_card_num: 42, preempted blk num: 13314
iter_num: 4832, on_card_num: 45, preempted blk num: 13314
iter_num: 4833, on_card_num: 47, preempted blk num: 13314
iter_num: 4834, on_card_num: 47, preempted blk num: 13314
iter_num: 4835, on_card_num: 47, preempted blk num: 13314
iter_num: 4836, on_card_num: 47, preempted blk num: 13314
to recompute 1: ('895', 50)
iter_num: 4837, on_card_num: 46, preempted blk num: 13322
iter_num: 4838, on_card_num: 46, preempted blk num: 13322
to recompute 1: ('894', 41)
iter_num: 4839, on_card_num: 45, preempted blk num: 13328
iter_num: 4840, on_card_num: 45, preempted blk num: 13328
to recompute 1: ('893', 27)
to recompute 1: ('892', 123)
iter_num: 4841, on_card_num: 43, preempted blk num: 13348
iter_num: 4842, on_card_num: 43, preempted blk num: 13348
iter_num: 4843, on_card_num: 43, preempted blk num: 13348
iter_num: 4844, on_card_num: 42, preempted blk num: 13348
iter_num: 4845, on_card_num: 46, preempted blk num: 13348
iter_num: 4846, on_card_num: 49, preempted blk num: 13348
iter_num: 4847, on_card_num: 49, preempted blk num: 13348
iter_num: 4848, on_card_num: 49, preempted blk num: 13348
iter_num: 4849, on_card_num: 48, preempted blk num: 13348
iter_num: 4850, on_card_num: 49, preempted blk num: 13348
iter_num: 4851, on_card_num: 49, preempted blk num: 13348
iter_num: 4852, on_card_num: 49, preempted blk num: 13348
iter_num: 4853, on_card_num: 49, preempted blk num: 13348
iter_num: 4854, on_card_num: 49, preempted blk num: 13348
iter_num: 4855, on_card_num: 49, preempted blk num: 13348
iter_num: 4856, on_card_num: 48, preempted blk num: 13348
iter_num: 4857, on_card_num: 46, preempted blk num: 13348
iter_num: 4858, on_card_num: 47, preempted blk num: 13348
iter_num: 4859, on_card_num: 50, preempted blk num: 13348
iter_num: 4860, on_card_num: 53, preempted blk num: 13348
iter_num: 4861, on_card_num: 54, preempted blk num: 13348
iter_num: 4862, on_card_num: 54, preempted blk num: 13348
iter_num: 4863, on_card_num: 54, preempted blk num: 13348
iter_num: 4864, on_card_num: 54, preempted blk num: 13348
iter_num: 4865, on_card_num: 54, preempted blk num: 13348
iter_num: 4866, on_card_num: 54, preempted blk num: 13348
iter_num: 4867, on_card_num: 54, preempted blk num: 13348
iter_num: 4868, on_card_num: 54, preempted blk num: 13348
to recompute 1: ('907', 337)
iter_num: 4869, on_card_num: 53, preempted blk num: 13390
iter_num: 4870, on_card_num: 53, preempted blk num: 13390
iter_num: 4871, on_card_num: 53, preempted blk num: 13390
iter_num: 4872, on_card_num: 53, preempted blk num: 13390
to recompute 1: ('906', 49)
iter_num: 4873, on_card_num: 52, preempted blk num: 13396
to recompute 1: ('905', 32)
iter_num: 4874, on_card_num: 51, preempted blk num: 13400
to recompute 1: ('904', 135)
iter_num: 4875, on_card_num: 50, preempted blk num: 13418
iter_num: 4876, on_card_num: 50, preempted blk num: 13418
iter_num: 4877, on_card_num: 50, preempted blk num: 13418
to recompute 1: ('903', 25)
iter_num: 4878, on_card_num: 49, preempted blk num: 13422
iter_num: 4879, on_card_num: 49, preempted blk num: 13422
to recompute 1: ('902', 30)
to recompute 1: ('901', 28)
to recompute 1: ('900', 1029)
iter_num: 4880, on_card_num: 45, preempted blk num: 13560
iter_num: 4881, on_card_num: 46, preempted blk num: 13560
iter_num: 4882, on_card_num: 49, preempted blk num: 13560
iter_num: 4883, on_card_num: 51, preempted blk num: 13560
iter_num: 4884, on_card_num: 51, preempted blk num: 13560
iter_num: 4885, on_card_num: 50, preempted blk num: 13560
iter_num: 4886, on_card_num: 50, preempted blk num: 13560
iter_num: 4887, on_card_num: 50, preempted blk num: 13560
iter_num: 4888, on_card_num: 50, preempted blk num: 13560
to recompute 1: ('905', 38)
iter_num: 4889, on_card_num: 49, preempted blk num: 13566
to recompute 1: ('904', 142)
iter_num: 4890, on_card_num: 46, preempted blk num: 13584
iter_num: 4891, on_card_num: 49, preempted blk num: 13584
iter_num: 4892, on_card_num: 51, preempted blk num: 13584
iter_num: 4893, on_card_num: 53, preempted blk num: 13584
iter_num: 4894, on_card_num: 54, preempted blk num: 13584
iter_num: 4895, on_card_num: 54, preempted blk num: 13584
iter_num: 4896, on_card_num: 54, preempted blk num: 13584
iter_num: 4897, on_card_num: 54, preempted blk num: 13584
iter_num: 4898, on_card_num: 54, preempted blk num: 13584
iter_num: 4899, on_card_num: 54, preempted blk num: 13584
iter_num: 4900, on_card_num: 54, preempted blk num: 13584
to recompute 1: ('911', 151)
iter_num: 4901, on_card_num: 52, preempted blk num: 13604
iter_num: 4902, on_card_num: 53, preempted blk num: 13604
iter_num: 4903, on_card_num: 53, preempted blk num: 13604
iter_num: 4904, on_card_num: 53, preempted blk num: 13604
iter_num: 4905, on_card_num: 52, preempted blk num: 13604
iter_num: 4906, on_card_num: 52, preempted blk num: 13604
iter_num: 4907, on_card_num: 52, preempted blk num: 13604
iter_num: 4908, on_card_num: 52, preempted blk num: 13604
iter_num: 4909, on_card_num: 52, preempted blk num: 13604
iter_num: 4910, on_card_num: 51, preempted blk num: 13604
iter_num: 4911, on_card_num: 50, preempted blk num: 13604
iter_num: 4912, on_card_num: 51, preempted blk num: 13604
iter_num: 4913, on_card_num: 53, preempted blk num: 13604
iter_num: 4914, on_card_num: 52, preempted blk num: 13604
iter_num: 4915, on_card_num: 53, preempted blk num: 13604
iter_num: 4916, on_card_num: 57, preempted blk num: 13604
iter_num: 4917, on_card_num: 58, preempted blk num: 13604
iter_num: 4918, on_card_num: 57, preempted blk num: 13604
iter_num: 4919, on_card_num: 57, preempted blk num: 13604
iter_num: 4920, on_card_num: 57, preempted blk num: 13604
iter_num: 4921, on_card_num: 57, preempted blk num: 13604
iter_num: 4922, on_card_num: 57, preempted blk num: 13604
iter_num: 4923, on_card_num: 57, preempted blk num: 13604
iter_num: 4924, on_card_num: 57, preempted blk num: 13604
to recompute 1: ('920', 374)
iter_num: 4925, on_card_num: 56, preempted blk num: 13652
iter_num: 4926, on_card_num: 56, preempted blk num: 13652
iter_num: 4927, on_card_num: 56, preempted blk num: 13652
iter_num: 4928, on_card_num: 56, preempted blk num: 13652
iter_num: 4929, on_card_num: 56, preempted blk num: 13652
iter_num: 4930, on_card_num: 56, preempted blk num: 13652
iter_num: 4931, on_card_num: 56, preempted blk num: 13652
to recompute 1: ('919', 28)
iter_num: 4932, on_card_num: 55, preempted blk num: 13656
to recompute 1: ('918', 29)
to recompute 1: ('917', 48)
iter_num: 4933, on_card_num: 53, preempted blk num: 13666
to recompute 1: ('916', 32)
to recompute 1: ('915', 346)
iter_num: 4934, on_card_num: 51, preempted blk num: 13714
iter_num: 4935, on_card_num: 51, preempted blk num: 13714
iter_num: 4936, on_card_num: 51, preempted blk num: 13714
iter_num: 4937, on_card_num: 50, preempted blk num: 13714
iter_num: 4938, on_card_num: 51, preempted blk num: 13714
iter_num: 4939, on_card_num: 55, preempted blk num: 13714
iter_num: 4940, on_card_num: 55, preempted blk num: 13714
iter_num: 4941, on_card_num: 55, preempted blk num: 13714
iter_num: 4942, on_card_num: 55, preempted blk num: 13714
iter_num: 4943, on_card_num: 55, preempted blk num: 13714
to recompute 1: ('919', 33)
iter_num: 4944, on_card_num: 54, preempted blk num: 13718
to recompute 1: ('918', 35)
iter_num: 4945, on_card_num: 53, preempted blk num: 13724
to recompute 1: ('917', 55)
iter_num: 4946, on_card_num: 52, preempted blk num: 13732
to recompute 1: ('916', 40)
iter_num: 4947, on_card_num: 51, preempted blk num: 13738
to recompute 1: ('915', 355)
iter_num: 4948, on_card_num: 50, preempted blk num: 13784
iter_num: 4949, on_card_num: 50, preempted blk num: 13784
iter_num: 4950, on_card_num: 50, preempted blk num: 13784
iter_num: 4951, on_card_num: 50, preempted blk num: 13784
iter_num: 4952, on_card_num: 50, preempted blk num: 13784
iter_num: 4953, on_card_num: 49, preempted blk num: 13784
iter_num: 4954, on_card_num: 49, preempted blk num: 13784
iter_num: 4955, on_card_num: 49, preempted blk num: 13784
iter_num: 4956, on_card_num: 49, preempted blk num: 13784
iter_num: 4957, on_card_num: 49, preempted blk num: 13784
to recompute 1: ('914', 73)
iter_num: 4958, on_card_num: 48, preempted blk num: 13794
to recompute 1: ('913', 76)
iter_num: 4959, on_card_num: 47, preempted blk num: 13804
iter_num: 4960, on_card_num: 47, preempted blk num: 13804
iter_num: 4961, on_card_num: 47, preempted blk num: 13804
to recompute 1: ('911', 204)
iter_num: 4962, on_card_num: 46, preempted blk num: 13830
iter_num: 4963, on_card_num: 46, preempted blk num: 13830
iter_num: 4964, on_card_num: 45, preempted blk num: 13830
iter_num: 4965, on_card_num: 45, preempted blk num: 13830
iter_num: 4966, on_card_num: 45, preempted blk num: 13830
iter_num: 4967, on_card_num: 45, preempted blk num: 13830
to recompute 1: ('909', 302)
iter_num: 4968, on_card_num: 44, preempted blk num: 13868
iter_num: 4969, on_card_num: 43, preempted blk num: 13868
iter_num: 4970, on_card_num: 45, preempted blk num: 13868
iter_num: 4971, on_card_num: 47, preempted blk num: 13868
iter_num: 4972, on_card_num: 47, preempted blk num: 13868
iter_num: 4973, on_card_num: 47, preempted blk num: 13868
iter_num: 4974, on_card_num: 47, preempted blk num: 13868
iter_num: 4975, on_card_num: 45, preempted blk num: 13868
iter_num: 4976, on_card_num: 46, preempted blk num: 13868
iter_num: 4977, on_card_num: 50, preempted blk num: 13868
iter_num: 4978, on_card_num: 50, preempted blk num: 13868
iter_num: 4979, on_card_num: 50, preempted blk num: 13868
iter_num: 4980, on_card_num: 50, preempted blk num: 13868
iter_num: 4981, on_card_num: 50, preempted blk num: 13868
iter_num: 4982, on_card_num: 50, preempted blk num: 13868
iter_num: 4983, on_card_num: 50, preempted blk num: 13868
iter_num: 4984, on_card_num: 50, preempted blk num: 13868
iter_num: 4985, on_card_num: 49, preempted blk num: 13868
iter_num: 4986, on_card_num: 50, preempted blk num: 13868
iter_num: 4987, on_card_num: 50, preempted blk num: 13868
iter_num: 4988, on_card_num: 50, preempted blk num: 13868
iter_num: 4989, on_card_num: 50, preempted blk num: 13868
iter_num: 4990, on_card_num: 49, preempted blk num: 13868
iter_num: 4991, on_card_num: 49, preempted blk num: 13868
iter_num: 4992, on_card_num: 49, preempted blk num: 13868
iter_num: 4993, on_card_num: 49, preempted blk num: 13868
iter_num: 4994, on_card_num: 49, preempted blk num: 13868
to recompute 1: ('920', 383)
iter_num: 4995, on_card_num: 48, preempted blk num: 13916
iter_num: 4996, on_card_num: 48, preempted blk num: 13916
iter_num: 4997, on_card_num: 48, preempted blk num: 13916
iter_num: 4998, on_card_num: 48, preempted blk num: 13916
iter_num: 4999, on_card_num: 48, preempted blk num: 13916
iter_num: 5000, on_card_num: 48, preempted blk num: 13916
iter_num: 5001, on_card_num: 48, preempted blk num: 13916
iter_num: 5002, on_card_num: 48, preempted blk num: 13916
iter_num: 5003, on_card_num: 48, preempted blk num: 13916
to recompute 1: ('919', 59)
iter_num: 5004, on_card_num: 47, preempted blk num: 13924
to recompute 1: ('918', 62)
iter_num: 5005, on_card_num: 46, preempted blk num: 13932
to recompute 1: ('917', 83)
iter_num: 5006, on_card_num: 44, preempted blk num: 13944
iter_num: 5007, on_card_num: 47, preempted blk num: 13944
iter_num: 5008, on_card_num: 47, preempted blk num: 13944
iter_num: 5009, on_card_num: 47, preempted blk num: 13944
iter_num: 5010, on_card_num: 46, preempted blk num: 13944
iter_num: 5011, on_card_num: 46, preempted blk num: 13944
iter_num: 5012, on_card_num: 46, preempted blk num: 13944
iter_num: 5013, on_card_num: 46, preempted blk num: 13944
iter_num: 5014, on_card_num: 46, preempted blk num: 13944
iter_num: 5015, on_card_num: 45, preempted blk num: 13944
iter_num: 5016, on_card_num: 46, preempted blk num: 13944
iter_num: 5017, on_card_num: 45, preempted blk num: 13944
iter_num: 5018, on_card_num: 45, preempted blk num: 13944
iter_num: 5019, on_card_num: 45, preempted blk num: 13944
iter_num: 5020, on_card_num: 45, preempted blk num: 13944
iter_num: 5021, on_card_num: 45, preempted blk num: 13944
iter_num: 5022, on_card_num: 45, preempted blk num: 13944
iter_num: 5023, on_card_num: 45, preempted blk num: 13944
iter_num: 5024, on_card_num: 45, preempted blk num: 13944
iter_num: 5025, on_card_num: 45, preempted blk num: 13944
iter_num: 5026, on_card_num: 45, preempted blk num: 13944
iter_num: 5027, on_card_num: 45, preempted blk num: 13944
to recompute 1: ('920', 395)
iter_num: 5028, on_card_num: 44, preempted blk num: 13994
iter_num: 5029, on_card_num: 44, preempted blk num: 13994
iter_num: 5030, on_card_num: 44, preempted blk num: 13994
iter_num: 5031, on_card_num: 44, preempted blk num: 13994
iter_num: 5032, on_card_num: 44, preempted blk num: 13994
iter_num: 5033, on_card_num: 44, preempted blk num: 13994
iter_num: 5034, on_card_num: 44, preempted blk num: 13994
iter_num: 5035, on_card_num: 44, preempted blk num: 13994
iter_num: 5036, on_card_num: 44, preempted blk num: 13994
to recompute 1: ('919', 88)
iter_num: 5037, on_card_num: 43, preempted blk num: 14006
iter_num: 5038, on_card_num: 43, preempted blk num: 14006
to recompute 1: ('918', 93)
iter_num: 5039, on_card_num: 42, preempted blk num: 14018
iter_num: 5040, on_card_num: 42, preempted blk num: 14018
to recompute 1: ('917', 116)
iter_num: 5041, on_card_num: 41, preempted blk num: 14034
iter_num: 5042, on_card_num: 41, preempted blk num: 14034
iter_num: 5043, on_card_num: 41, preempted blk num: 14034
to recompute 1: ('916', 104)
iter_num: 5044, on_card_num: 40, preempted blk num: 14048
iter_num: 5045, on_card_num: 40, preempted blk num: 14048
to recompute 1: ('915', 421)
iter_num: 5046, on_card_num: 39, preempted blk num: 14102
iter_num: 5047, on_card_num: 39, preempted blk num: 14102
iter_num: 5048, on_card_num: 39, preempted blk num: 14102
iter_num: 5049, on_card_num: 39, preempted blk num: 14102
iter_num: 5050, on_card_num: 38, preempted blk num: 14102
iter_num: 5051, on_card_num: 39, preempted blk num: 14102
iter_num: 5052, on_card_num: 43, preempted blk num: 14102
iter_num: 5053, on_card_num: 43, preempted blk num: 14102
iter_num: 5054, on_card_num: 43, preempted blk num: 14102
iter_num: 5055, on_card_num: 42, preempted blk num: 14102
iter_num: 5056, on_card_num: 43, preempted blk num: 14102
iter_num: 5057, on_card_num: 42, preempted blk num: 14102
iter_num: 5058, on_card_num: 42, preempted blk num: 14102
iter_num: 5059, on_card_num: 42, preempted blk num: 14102
iter_num: 5060, on_card_num: 41, preempted blk num: 14102
iter_num: 5061, on_card_num: 40, preempted blk num: 14102
iter_num: 5062, on_card_num: 41, preempted blk num: 14102
iter_num: 5063, on_card_num: 41, preempted blk num: 14102
iter_num: 5064, on_card_num: 41, preempted blk num: 14102
iter_num: 5065, on_card_num: 41, preempted blk num: 14102
iter_num: 5066, on_card_num: 40, preempted blk num: 14102
iter_num: 5067, on_card_num: 41, preempted blk num: 14102
iter_num: 5068, on_card_num: 41, preempted blk num: 14102
iter_num: 5069, on_card_num: 40, preempted blk num: 14102
iter_num: 5070, on_card_num: 40, preempted blk num: 14102
iter_num: 5071, on_card_num: 40, preempted blk num: 14102
iter_num: 5072, on_card_num: 40, preempted blk num: 14102
iter_num: 5073, on_card_num: 40, preempted blk num: 14102
iter_num: 5074, on_card_num: 40, preempted blk num: 14102
iter_num: 5075, on_card_num: 40, preempted blk num: 14102
iter_num: 5076, on_card_num: 40, preempted blk num: 14102
iter_num: 5077, on_card_num: 40, preempted blk num: 14102
iter_num: 5078, on_card_num: 40, preempted blk num: 14102
iter_num: 5079, on_card_num: 40, preempted blk num: 14102
iter_num: 5080, on_card_num: 40, preempted blk num: 14102
iter_num: 5081, on_card_num: 40, preempted blk num: 14102
iter_num: 5082, on_card_num: 40, preempted blk num: 14102
to recompute 1: ('922', 461)
iter_num: 5083, on_card_num: 38, preempted blk num: 14160
iter_num: 5084, on_card_num: 40, preempted blk num: 14160
iter_num: 5085, on_card_num: 42, preempted blk num: 14160
iter_num: 5086, on_card_num: 45, preempted blk num: 14160
iter_num: 5087, on_card_num: 45, preempted blk num: 14160
iter_num: 5088, on_card_num: 45, preempted blk num: 14160
iter_num: 5089, on_card_num: 45, preempted blk num: 14160
iter_num: 5090, on_card_num: 45, preempted blk num: 14160
iter_num: 5091, on_card_num: 45, preempted blk num: 14160
iter_num: 5092, on_card_num: 45, preempted blk num: 14160
iter_num: 5093, on_card_num: 45, preempted blk num: 14160
to recompute 1: ('928', 21)
iter_num: 5094, on_card_num: 43, preempted blk num: 14164
iter_num: 5095, on_card_num: 44, preempted blk num: 14164
iter_num: 5096, on_card_num: 45, preempted blk num: 14164
iter_num: 5097, on_card_num: 45, preempted blk num: 14164
iter_num: 5098, on_card_num: 45, preempted blk num: 14164
iter_num: 5099, on_card_num: 45, preempted blk num: 14164
iter_num: 5100, on_card_num: 45, preempted blk num: 14164
iter_num: 5101, on_card_num: 45, preempted blk num: 14164
iter_num: 5102, on_card_num: 45, preempted blk num: 14164
iter_num: 5103, on_card_num: 45, preempted blk num: 14164
iter_num: 5104, on_card_num: 45, preempted blk num: 14164
iter_num: 5105, on_card_num: 45, preempted blk num: 14164
iter_num: 5106, on_card_num: 45, preempted blk num: 14164
iter_num: 5107, on_card_num: 45, preempted blk num: 14164
iter_num: 5108, on_card_num: 45, preempted blk num: 14164
iter_num: 5109, on_card_num: 45, preempted blk num: 14164
iter_num: 5110, on_card_num: 44, preempted blk num: 14164
iter_num: 5111, on_card_num: 45, preempted blk num: 14164
iter_num: 5112, on_card_num: 47, preempted blk num: 14164
iter_num: 5113, on_card_num: 46, preempted blk num: 14164
iter_num: 5114, on_card_num: 46, preempted blk num: 14164
iter_num: 5115, on_card_num: 46, preempted blk num: 14164
iter_num: 5116, on_card_num: 45, preempted blk num: 14164
iter_num: 5117, on_card_num: 45, preempted blk num: 14164
iter_num: 5118, on_card_num: 44, preempted blk num: 14164
iter_num: 5119, on_card_num: 45, preempted blk num: 14164
iter_num: 5120, on_card_num: 46, preempted blk num: 14164
iter_num: 5121, on_card_num: 47, preempted blk num: 14164
iter_num: 5122, on_card_num: 47, preempted blk num: 14164
iter_num: 5123, on_card_num: 46, preempted blk num: 14164
iter_num: 5124, on_card_num: 47, preempted blk num: 14164
iter_num: 5125, on_card_num: 47, preempted blk num: 14164
iter_num: 5126, on_card_num: 47, preempted blk num: 14164
iter_num: 5127, on_card_num: 46, preempted blk num: 14164
iter_num: 5128, on_card_num: 47, preempted blk num: 14164
iter_num: 5129, on_card_num: 48, preempted blk num: 14164
iter_num: 5130, on_card_num: 48, preempted blk num: 14164
iter_num: 5131, on_card_num: 48, preempted blk num: 14164
iter_num: 5132, on_card_num: 48, preempted blk num: 14164
iter_num: 5133, on_card_num: 47, preempted blk num: 14164
iter_num: 5134, on_card_num: 47, preempted blk num: 14164
iter_num: 5135, on_card_num: 47, preempted blk num: 14164
iter_num: 5136, on_card_num: 46, preempted blk num: 14164
iter_num: 5137, on_card_num: 46, preempted blk num: 14164
iter_num: 5138, on_card_num: 45, preempted blk num: 14164
iter_num: 5139, on_card_num: 46, preempted blk num: 14164
iter_num: 5140, on_card_num: 46, preempted blk num: 14164
iter_num: 5141, on_card_num: 45, preempted blk num: 14164
iter_num: 5142, on_card_num: 46, preempted blk num: 14164
iter_num: 5143, on_card_num: 46, preempted blk num: 14164
iter_num: 5144, on_card_num: 46, preempted blk num: 14164
iter_num: 5145, on_card_num: 46, preempted blk num: 14164
iter_num: 5146, on_card_num: 46, preempted blk num: 14164
iter_num: 5147, on_card_num: 46, preempted blk num: 14164
iter_num: 5148, on_card_num: 46, preempted blk num: 14164
iter_num: 5149, on_card_num: 46, preempted blk num: 14164
iter_num: 5150, on_card_num: 45, preempted blk num: 14164
iter_num: 5151, on_card_num: 46, preempted blk num: 14164
iter_num: 5152, on_card_num: 47, preempted blk num: 14164
iter_num: 5153, on_card_num: 47, preempted blk num: 14164
iter_num: 5154, on_card_num: 46, preempted blk num: 14164
iter_num: 5155, on_card_num: 47, preempted blk num: 14164
iter_num: 5156, on_card_num: 48, preempted blk num: 14164
iter_num: 5157, on_card_num: 49, preempted blk num: 14164
iter_num: 5158, on_card_num: 50, preempted blk num: 14164
iter_num: 5159, on_card_num: 51, preempted blk num: 14164
iter_num: 5160, on_card_num: 53, preempted blk num: 14164
iter_num: 5161, on_card_num: 53, preempted blk num: 14164
iter_num: 5162, on_card_num: 53, preempted blk num: 14164
iter_num: 5163, on_card_num: 52, preempted blk num: 14164
iter_num: 5164, on_card_num: 52, preempted blk num: 14164
iter_num: 5165, on_card_num: 52, preempted blk num: 14164
iter_num: 5166, on_card_num: 48, preempted blk num: 14164
iter_num: 5167, on_card_num: 49, preempted blk num: 14164
iter_num: 5168, on_card_num: 52, preempted blk num: 14164
iter_num: 5169, on_card_num: 54, preempted blk num: 14164
iter_num: 5170, on_card_num: 58, preempted blk num: 14164
iter_num: 5171, on_card_num: 59, preempted blk num: 14164
iter_num: 5172, on_card_num: 59, preempted blk num: 14164
iter_num: 5173, on_card_num: 59, preempted blk num: 14164
iter_num: 5174, on_card_num: 56, preempted blk num: 14164
iter_num: 5175, on_card_num: 57, preempted blk num: 14164
iter_num: 5176, on_card_num: 62, preempted blk num: 14164
iter_num: 5177, on_card_num: 64, preempted blk num: 14164
iter_num: 5178, on_card_num: 65, preempted blk num: 14164
iter_num: 5179, on_card_num: 65, preempted blk num: 14164
iter_num: 5180, on_card_num: 64, preempted blk num: 14164
iter_num: 5181, on_card_num: 65, preempted blk num: 14164
iter_num: 5182, on_card_num: 65, preempted blk num: 14164
iter_num: 5183, on_card_num: 65, preempted blk num: 14164
iter_num: 5184, on_card_num: 65, preempted blk num: 14164
iter_num: 5185, on_card_num: 65, preempted blk num: 14164
iter_num: 5186, on_card_num: 63, preempted blk num: 14164
iter_num: 5187, on_card_num: 64, preempted blk num: 14164
iter_num: 5188, on_card_num: 68, preempted blk num: 14164
iter_num: 5189, on_card_num: 67, preempted blk num: 14164
iter_num: 5190, on_card_num: 67, preempted blk num: 14164
iter_num: 5191, on_card_num: 67, preempted blk num: 14164
iter_num: 5192, on_card_num: 67, preempted blk num: 14164
iter_num: 5193, on_card_num: 67, preempted blk num: 14164
iter_num: 5194, on_card_num: 66, preempted blk num: 14164
iter_num: 5195, on_card_num: 67, preempted blk num: 14164
iter_num: 5196, on_card_num: 67, preempted blk num: 14164
iter_num: 5197, on_card_num: 66, preempted blk num: 14164
iter_num: 5198, on_card_num: 68, preempted blk num: 14164
iter_num: 5199, on_card_num: 68, preempted blk num: 14164
iter_num: 5200, on_card_num: 68, preempted blk num: 14164
iter_num: 5201, on_card_num: 68, preempted blk num: 14164
iter_num: 5202, on_card_num: 68, preempted blk num: 14164
to recompute 1: ('978', 260)
iter_num: 5203, on_card_num: 67, preempted blk num: 14198
iter_num: 5204, on_card_num: 67, preempted blk num: 14198
iter_num: 5205, on_card_num: 67, preempted blk num: 14198
iter_num: 5206, on_card_num: 66, preempted blk num: 14198
iter_num: 5207, on_card_num: 68, preempted blk num: 14198
iter_num: 5208, on_card_num: 68, preempted blk num: 14198
iter_num: 5209, on_card_num: 68, preempted blk num: 14198
iter_num: 5210, on_card_num: 67, preempted blk num: 14198
iter_num: 5211, on_card_num: 66, preempted blk num: 14198
iter_num: 5212, on_card_num: 67, preempted blk num: 14198
iter_num: 5213, on_card_num: 66, preempted blk num: 14198
iter_num: 5214, on_card_num: 67, preempted blk num: 14198
iter_num: 5215, on_card_num: 67, preempted blk num: 14198
iter_num: 5216, on_card_num: 66, preempted blk num: 14198
iter_num: 5217, on_card_num: 67, preempted blk num: 14198
iter_num: 5218, on_card_num: 67, preempted blk num: 14198
iter_num: 5219, on_card_num: 67, preempted blk num: 14198
iter_num: 5220, on_card_num: 67, preempted blk num: 14198
iter_num: 5221, on_card_num: 67, preempted blk num: 14198
to recompute 1: ('982', 68)
to recompute 1: ('981', 527)
iter_num: 5222, on_card_num: 65, preempted blk num: 14274
iter_num: 5223, on_card_num: 65, preempted blk num: 14274
iter_num: 5224, on_card_num: 65, preempted blk num: 14274
iter_num: 5225, on_card_num: 65, preempted blk num: 14274
iter_num: 5226, on_card_num: 65, preempted blk num: 14274
iter_num: 5227, on_card_num: 65, preempted blk num: 14274
iter_num: 5228, on_card_num: 65, preempted blk num: 14274
iter_num: 5229, on_card_num: 65, preempted blk num: 14274
iter_num: 5230, on_card_num: 64, preempted blk num: 14274
iter_num: 5231, on_card_num: 65, preempted blk num: 14274
iter_num: 5232, on_card_num: 66, preempted blk num: 14274
iter_num: 5233, on_card_num: 65, preempted blk num: 14274
iter_num: 5234, on_card_num: 65, preempted blk num: 14274
iter_num: 5235, on_card_num: 65, preempted blk num: 14274
iter_num: 5236, on_card_num: 65, preempted blk num: 14274
iter_num: 5237, on_card_num: 64, preempted blk num: 14274
iter_num: 5238, on_card_num: 63, preempted blk num: 14274
iter_num: 5239, on_card_num: 63, preempted blk num: 14274
iter_num: 5240, on_card_num: 62, preempted blk num: 14274
iter_num: 5241, on_card_num: 62, preempted blk num: 14274
iter_num: 5242, on_card_num: 62, preempted blk num: 14274
iter_num: 5243, on_card_num: 62, preempted blk num: 14274
iter_num: 5244, on_card_num: 62, preempted blk num: 14274
iter_num: 5245, on_card_num: 62, preempted blk num: 14274
iter_num: 5246, on_card_num: 62, preempted blk num: 14274
iter_num: 5247, on_card_num: 62, preempted blk num: 14274
iter_num: 5248, on_card_num: 62, preempted blk num: 14274
iter_num: 5249, on_card_num: 62, preempted blk num: 14274
iter_num: 5250, on_card_num: 62, preempted blk num: 14274
iter_num: 5251, on_card_num: 62, preempted blk num: 14274
iter_num: 5252, on_card_num: 62, preempted blk num: 14274
iter_num: 5253, on_card_num: 62, preempted blk num: 14274
iter_num: 5254, on_card_num: 62, preempted blk num: 14274
to recompute 1: ('982', 91)
iter_num: 5255, on_card_num: 60, preempted blk num: 14286
iter_num: 5256, on_card_num: 60, preempted blk num: 14286
iter_num: 5257, on_card_num: 60, preempted blk num: 14286
iter_num: 5258, on_card_num: 60, preempted blk num: 14286
to recompute 1: ('981', 554)
iter_num: 5259, on_card_num: 59, preempted blk num: 14356
iter_num: 5260, on_card_num: 59, preempted blk num: 14356
iter_num: 5261, on_card_num: 59, preempted blk num: 14356
iter_num: 5262, on_card_num: 59, preempted blk num: 14356
iter_num: 5263, on_card_num: 58, preempted blk num: 14356
iter_num: 5264, on_card_num: 58, preempted blk num: 14356
iter_num: 5265, on_card_num: 58, preempted blk num: 14356
iter_num: 5266, on_card_num: 58, preempted blk num: 14356
iter_num: 5267, on_card_num: 58, preempted blk num: 14356
iter_num: 5268, on_card_num: 58, preempted blk num: 14356
iter_num: 5269, on_card_num: 58, preempted blk num: 14356
iter_num: 5270, on_card_num: 58, preempted blk num: 14356
to recompute 1: ('979', 226)
iter_num: 5271, on_card_num: 57, preempted blk num: 14386
iter_num: 5272, on_card_num: 57, preempted blk num: 14386
iter_num: 5273, on_card_num: 57, preempted blk num: 14386
iter_num: 5274, on_card_num: 57, preempted blk num: 14386
to recompute 1: ('977', 202)
iter_num: 5275, on_card_num: 56, preempted blk num: 14412
iter_num: 5276, on_card_num: 56, preempted blk num: 14412
iter_num: 5277, on_card_num: 56, preempted blk num: 14412
to recompute 1: ('975', 169)
iter_num: 5278, on_card_num: 55, preempted blk num: 14434
iter_num: 5279, on_card_num: 55, preempted blk num: 14434
iter_num: 5280, on_card_num: 55, preempted blk num: 14434
iter_num: 5281, on_card_num: 54, preempted blk num: 14434
iter_num: 5282, on_card_num: 55, preempted blk num: 14434
iter_num: 5283, on_card_num: 55, preempted blk num: 14434
iter_num: 5284, on_card_num: 55, preempted blk num: 14434
iter_num: 5285, on_card_num: 53, preempted blk num: 14434
iter_num: 5286, on_card_num: 55, preempted blk num: 14434
iter_num: 5287, on_card_num: 55, preempted blk num: 14434
iter_num: 5288, on_card_num: 55, preempted blk num: 14434
iter_num: 5289, on_card_num: 55, preempted blk num: 14434
to recompute 1: ('979', 230)
iter_num: 5290, on_card_num: 54, preempted blk num: 14464
iter_num: 5291, on_card_num: 54, preempted blk num: 14464
iter_num: 5292, on_card_num: 54, preempted blk num: 14464
iter_num: 5293, on_card_num: 54, preempted blk num: 14464
to recompute 1: ('977', 210)
iter_num: 5294, on_card_num: 52, preempted blk num: 14492
iter_num: 5295, on_card_num: 52, preempted blk num: 14492
iter_num: 5296, on_card_num: 52, preempted blk num: 14492
iter_num: 5297, on_card_num: 52, preempted blk num: 14492
iter_num: 5298, on_card_num: 52, preempted blk num: 14492
iter_num: 5299, on_card_num: 52, preempted blk num: 14492
iter_num: 5300, on_card_num: 51, preempted blk num: 14492
iter_num: 5301, on_card_num: 52, preempted blk num: 14492
iter_num: 5302, on_card_num: 52, preempted blk num: 14492
iter_num: 5303, on_card_num: 52, preempted blk num: 14492
iter_num: 5304, on_card_num: 52, preempted blk num: 14492
iter_num: 5305, on_card_num: 52, preempted blk num: 14492
iter_num: 5306, on_card_num: 52, preempted blk num: 14492
iter_num: 5307, on_card_num: 52, preempted blk num: 14492
iter_num: 5308, on_card_num: 52, preempted blk num: 14492
iter_num: 5309, on_card_num: 52, preempted blk num: 14492
to recompute 1: ('977', 219)
iter_num: 5310, on_card_num: 51, preempted blk num: 14520
iter_num: 5311, on_card_num: 51, preempted blk num: 14520
iter_num: 5312, on_card_num: 51, preempted blk num: 14520
to recompute 1: ('975', 198)
iter_num: 5313, on_card_num: 50, preempted blk num: 14546
iter_num: 5314, on_card_num: 49, preempted blk num: 14546
iter_num: 5315, on_card_num: 52, preempted blk num: 14546
iter_num: 5316, on_card_num: 53, preempted blk num: 14546
iter_num: 5317, on_card_num: 53, preempted blk num: 14546
iter_num: 5318, on_card_num: 53, preempted blk num: 14546
iter_num: 5319, on_card_num: 53, preempted blk num: 14546
iter_num: 5320, on_card_num: 52, preempted blk num: 14546
iter_num: 5321, on_card_num: 52, preempted blk num: 14546
iter_num: 5322, on_card_num: 52, preempted blk num: 14546
iter_num: 5323, on_card_num: 51, preempted blk num: 14546
iter_num: 5324, on_card_num: 52, preempted blk num: 14546
iter_num: 5325, on_card_num: 52, preempted blk num: 14546
iter_num: 5326, on_card_num: 52, preempted blk num: 14546
iter_num: 5327, on_card_num: 52, preempted blk num: 14546
iter_num: 5328, on_card_num: 52, preempted blk num: 14546
iter_num: 5329, on_card_num: 51, preempted blk num: 14546
iter_num: 5330, on_card_num: 51, preempted blk num: 14546
iter_num: 5331, on_card_num: 51, preempted blk num: 14546
iter_num: 5332, on_card_num: 51, preempted blk num: 14546
iter_num: 5333, on_card_num: 51, preempted blk num: 14546
iter_num: 5334, on_card_num: 50, preempted blk num: 14546
iter_num: 5335, on_card_num: 50, preempted blk num: 14546
iter_num: 5336, on_card_num: 50, preempted blk num: 14546
iter_num: 5337, on_card_num: 50, preempted blk num: 14546
iter_num: 5338, on_card_num: 50, preempted blk num: 14546
iter_num: 5339, on_card_num: 49, preempted blk num: 14546
iter_num: 5340, on_card_num: 49, preempted blk num: 14546
iter_num: 5341, on_card_num: 49, preempted blk num: 14546
iter_num: 5342, on_card_num: 49, preempted blk num: 14546
iter_num: 5343, on_card_num: 48, preempted blk num: 14546
iter_num: 5344, on_card_num: 47, preempted blk num: 14546
iter_num: 5345, on_card_num: 48, preempted blk num: 14546
iter_num: 5346, on_card_num: 47, preempted blk num: 14546
iter_num: 5347, on_card_num: 48, preempted blk num: 14546
iter_num: 5348, on_card_num: 47, preempted blk num: 14546
iter_num: 5349, on_card_num: 48, preempted blk num: 14546
iter_num: 5350, on_card_num: 47, preempted blk num: 14546
iter_num: 5351, on_card_num: 48, preempted blk num: 14546
iter_num: 5352, on_card_num: 48, preempted blk num: 14546
iter_num: 5353, on_card_num: 47, preempted blk num: 14546
iter_num: 5354, on_card_num: 48, preempted blk num: 14546
iter_num: 5355, on_card_num: 49, preempted blk num: 14546
iter_num: 5356, on_card_num: 49, preempted blk num: 14546
iter_num: 5357, on_card_num: 49, preempted blk num: 14546
iter_num: 5358, on_card_num: 48, preempted blk num: 14546
iter_num: 5359, on_card_num: 48, preempted blk num: 14546
iter_num: 5360, on_card_num: 48, preempted blk num: 14546
iter_num: 5361, on_card_num: 48, preempted blk num: 14546
iter_num: 5362, on_card_num: 48, preempted blk num: 14546
iter_num: 5363, on_card_num: 48, preempted blk num: 14546
iter_num: 5364, on_card_num: 47, preempted blk num: 14546
iter_num: 5365, on_card_num: 48, preempted blk num: 14546
iter_num: 5366, on_card_num: 49, preempted blk num: 14546
iter_num: 5367, on_card_num: 50, preempted blk num: 14546
iter_num: 5368, on_card_num: 50, preempted blk num: 14546
iter_num: 5369, on_card_num: 49, preempted blk num: 14546
iter_num: 5370, on_card_num: 50, preempted blk num: 14546
iter_num: 5371, on_card_num: 50, preempted blk num: 14546
iter_num: 5372, on_card_num: 50, preempted blk num: 14546
iter_num: 5373, on_card_num: 49, preempted blk num: 14546
iter_num: 5374, on_card_num: 51, preempted blk num: 14546
iter_num: 5375, on_card_num: 51, preempted blk num: 14546
iter_num: 5376, on_card_num: 50, preempted blk num: 14546
iter_num: 5377, on_card_num: 50, preempted blk num: 14546
iter_num: 5378, on_card_num: 50, preempted blk num: 14546
iter_num: 5379, on_card_num: 50, preempted blk num: 14546
iter_num: 5380, on_card_num: 49, preempted blk num: 14546
iter_num: 5381, on_card_num: 50, preempted blk num: 14546
iter_num: 5382, on_card_num: 50, preempted blk num: 14546
iter_num: 5383, on_card_num: 49, preempted blk num: 14546
iter_num: 5384, on_card_num: 52, preempted blk num: 14546
iter_num: 5385, on_card_num: 52, preempted blk num: 14546
iter_num: 5386, on_card_num: 52, preempted blk num: 14546
to recompute 1: ('998', 162)
iter_num: 5387, on_card_num: 51, preempted blk num: 14568
iter_num: 5388, on_card_num: 51, preempted blk num: 14568
iter_num: 5389, on_card_num: 51, preempted blk num: 14568
to recompute 1: ('997', 362)
iter_num: 5390, on_card_num: 49, preempted blk num: 14614
iter_num: 5391, on_card_num: 50, preempted blk num: 14614
iter_num: 5392, on_card_num: 50, preempted blk num: 14614
iter_num: 5393, on_card_num: 50, preempted blk num: 14614
iter_num: 5394, on_card_num: 49, preempted blk num: 14614
iter_num: 5395, on_card_num: 49, preempted blk num: 14614
iter_num: 5396, on_card_num: 49, preempted blk num: 14614
iter_num: 5397, on_card_num: 48, preempted blk num: 14614
iter_num: 5398, on_card_num: 50, preempted blk num: 14614
iter_num: 5399, on_card_num: 50, preempted blk num: 14614
iter_num: 5400, on_card_num: 50, preempted blk num: 14614
iter_num: 5401, on_card_num: 50, preempted blk num: 14614
iter_num: 5402, on_card_num: 50, preempted blk num: 14614
iter_num: 5403, on_card_num: 50, preempted blk num: 14614
iter_num: 5404, on_card_num: 50, preempted blk num: 14614
iter_num: 5405, on_card_num: 50, preempted blk num: 14614
iter_num: 5406, on_card_num: 50, preempted blk num: 14614
to recompute 1: ('999', 18)
iter_num: 5407, on_card_num: 49, preempted blk num: 14618
to recompute 1: ('998', 172)
iter_num: 5408, on_card_num: 48, preempted blk num: 14640
iter_num: 5409, on_card_num: 48, preempted blk num: 14640
iter_num: 5410, on_card_num: 48, preempted blk num: 14640
to recompute 1: ('995', 491)
iter_num: 5411, on_card_num: 46, preempted blk num: 14702
iter_num: 5412, on_card_num: 47, preempted blk num: 14702
iter_num: 5413, on_card_num: 48, preempted blk num: 14702
iter_num: 5414, on_card_num: 48, preempted blk num: 14702
iter_num: 5415, on_card_num: 48, preempted blk num: 14702
iter_num: 5416, on_card_num: 48, preempted blk num: 14702
iter_num: 5417, on_card_num: 48, preempted blk num: 14702
iter_num: 5418, on_card_num: 48, preempted blk num: 14702
to recompute 1: ('998', 178)
iter_num: 5419, on_card_num: 47, preempted blk num: 14726
iter_num: 5420, on_card_num: 47, preempted blk num: 14726
iter_num: 5421, on_card_num: 47, preempted blk num: 14726
iter_num: 5422, on_card_num: 47, preempted blk num: 14726
to recompute 1: ('995', 501)
iter_num: 5423, on_card_num: 46, preempted blk num: 14790
iter_num: 5424, on_card_num: 44, preempted blk num: 14790
iter_num: 5425, on_card_num: 45, preempted blk num: 14790
iter_num: 5426, on_card_num: 47, preempted blk num: 14790
iter_num: 5427, on_card_num: 47, preempted blk num: 14790
iter_num: 5428, on_card_num: 46, preempted blk num: 14790
iter_num: 5429, on_card_num: 46, preempted blk num: 14790
iter_num: 5430, on_card_num: 46, preempted blk num: 14790
iter_num: 5431, on_card_num: 46, preempted blk num: 14790
iter_num: 5432, on_card_num: 46, preempted blk num: 14790
iter_num: 5433, on_card_num: 46, preempted blk num: 14790
iter_num: 5434, on_card_num: 46, preempted blk num: 14790
iter_num: 5435, on_card_num: 46, preempted blk num: 14790
iter_num: 5436, on_card_num: 46, preempted blk num: 14790
iter_num: 5437, on_card_num: 46, preempted blk num: 14790
iter_num: 5438, on_card_num: 46, preempted blk num: 14790
iter_num: 5439, on_card_num: 46, preempted blk num: 14790
iter_num: 5440, on_card_num: 45, preempted blk num: 14790
iter_num: 5441, on_card_num: 45, preempted blk num: 14790
iter_num: 5442, on_card_num: 45, preempted blk num: 14790
iter_num: 5443, on_card_num: 45, preempted blk num: 14790
iter_num: 5444, on_card_num: 45, preempted blk num: 14790
iter_num: 5445, on_card_num: 45, preempted blk num: 14790
iter_num: 5446, on_card_num: 45, preempted blk num: 14790
iter_num: 5447, on_card_num: 45, preempted blk num: 14790
iter_num: 5448, on_card_num: 45, preempted blk num: 14790
iter_num: 5449, on_card_num: 45, preempted blk num: 14790
iter_num: 5450, on_card_num: 45, preempted blk num: 14790
iter_num: 5451, on_card_num: 45, preempted blk num: 14790
iter_num: 5452, on_card_num: 45, preempted blk num: 14790
iter_num: 5453, on_card_num: 45, preempted blk num: 14790
iter_num: 5454, on_card_num: 44, preempted blk num: 14790
iter_num: 5455, on_card_num: 44, preempted blk num: 14790
iter_num: 5456, on_card_num: 44, preempted blk num: 14790
iter_num: 5457, on_card_num: 44, preempted blk num: 14790
iter_num: 5458, on_card_num: 44, preempted blk num: 14790
iter_num: 5459, on_card_num: 44, preempted blk num: 14790
iter_num: 5460, on_card_num: 44, preempted blk num: 14790
iter_num: 5461, on_card_num: 44, preempted blk num: 14790
iter_num: 5462, on_card_num: 43, preempted blk num: 14790
iter_num: 5463, on_card_num: 43, preempted blk num: 14790
iter_num: 5464, on_card_num: 43, preempted blk num: 14790
iter_num: 5465, on_card_num: 43, preempted blk num: 14790
iter_num: 5466, on_card_num: 43, preempted blk num: 14790
iter_num: 5467, on_card_num: 43, preempted blk num: 14790
iter_num: 5468, on_card_num: 42, preempted blk num: 14790
iter_num: 5469, on_card_num: 42, preempted blk num: 14790
iter_num: 5470, on_card_num: 41, preempted blk num: 14790
iter_num: 5471, on_card_num: 40, preempted blk num: 14790
iter_num: 5472, on_card_num: 40, preempted blk num: 14790
iter_num: 5473, on_card_num: 40, preempted blk num: 14790
iter_num: 5474, on_card_num: 40, preempted blk num: 14790
iter_num: 5475, on_card_num: 39, preempted blk num: 14790
iter_num: 5476, on_card_num: 39, preempted blk num: 14790
iter_num: 5477, on_card_num: 39, preempted blk num: 14790
iter_num: 5478, on_card_num: 39, preempted blk num: 14790
iter_num: 5479, on_card_num: 39, preempted blk num: 14790
iter_num: 5480, on_card_num: 38, preempted blk num: 14790
iter_num: 5481, on_card_num: 38, preempted blk num: 14790
iter_num: 5482, on_card_num: 38, preempted blk num: 14790
iter_num: 5483, on_card_num: 38, preempted blk num: 14790
iter_num: 5484, on_card_num: 38, preempted blk num: 14790
iter_num: 5485, on_card_num: 37, preempted blk num: 14790
iter_num: 5486, on_card_num: 37, preempted blk num: 14790
iter_num: 5487, on_card_num: 37, preempted blk num: 14790
iter_num: 5488, on_card_num: 37, preempted blk num: 14790
iter_num: 5489, on_card_num: 37, preempted blk num: 14790
iter_num: 5490, on_card_num: 37, preempted blk num: 14790
iter_num: 5491, on_card_num: 37, preempted blk num: 14790
iter_num: 5492, on_card_num: 37, preempted blk num: 14790
iter_num: 5493, on_card_num: 37, preempted blk num: 14790
iter_num: 5494, on_card_num: 37, preempted blk num: 14790
iter_num: 5495, on_card_num: 37, preempted blk num: 14790
iter_num: 5496, on_card_num: 37, preempted blk num: 14790
iter_num: 5497, on_card_num: 37, preempted blk num: 14790
iter_num: 5498, on_card_num: 37, preempted blk num: 14790
iter_num: 5499, on_card_num: 37, preempted blk num: 14790
iter_num: 5500, on_card_num: 37, preempted blk num: 14790
iter_num: 5501, on_card_num: 37, preempted blk num: 14790
iter_num: 5502, on_card_num: 37, preempted blk num: 14790
iter_num: 5503, on_card_num: 37, preempted blk num: 14790
iter_num: 5504, on_card_num: 36, preempted blk num: 14790
iter_num: 5505, on_card_num: 36, preempted blk num: 14790
iter_num: 5506, on_card_num: 36, preempted blk num: 14790
iter_num: 5507, on_card_num: 35, preempted blk num: 14790
iter_num: 5508, on_card_num: 35, preempted blk num: 14790
iter_num: 5509, on_card_num: 35, preempted blk num: 14790
iter_num: 5510, on_card_num: 35, preempted blk num: 14790
iter_num: 5511, on_card_num: 35, preempted blk num: 14790
iter_num: 5512, on_card_num: 35, preempted blk num: 14790
iter_num: 5513, on_card_num: 35, preempted blk num: 14790
iter_num: 5514, on_card_num: 35, preempted blk num: 14790
iter_num: 5515, on_card_num: 34, preempted blk num: 14790
iter_num: 5516, on_card_num: 34, preempted blk num: 14790
iter_num: 5517, on_card_num: 34, preempted blk num: 14790
iter_num: 5518, on_card_num: 34, preempted blk num: 14790
iter_num: 5519, on_card_num: 34, preempted blk num: 14790
iter_num: 5520, on_card_num: 34, preempted blk num: 14790
iter_num: 5521, on_card_num: 33, preempted blk num: 14790
iter_num: 5522, on_card_num: 33, preempted blk num: 14790
iter_num: 5523, on_card_num: 33, preempted blk num: 14790
iter_num: 5524, on_card_num: 33, preempted blk num: 14790
iter_num: 5525, on_card_num: 32, preempted blk num: 14790
iter_num: 5526, on_card_num: 32, preempted blk num: 14790
iter_num: 5527, on_card_num: 32, preempted blk num: 14790
iter_num: 5528, on_card_num: 32, preempted blk num: 14790
iter_num: 5529, on_card_num: 32, preempted blk num: 14790
iter_num: 5530, on_card_num: 32, preempted blk num: 14790
iter_num: 5531, on_card_num: 32, preempted blk num: 14790
iter_num: 5532, on_card_num: 32, preempted blk num: 14790
iter_num: 5533, on_card_num: 31, preempted blk num: 14790
iter_num: 5534, on_card_num: 31, preempted blk num: 14790
iter_num: 5535, on_card_num: 31, preempted blk num: 14790
iter_num: 5536, on_card_num: 31, preempted blk num: 14790
iter_num: 5537, on_card_num: 31, preempted blk num: 14790
iter_num: 5538, on_card_num: 31, preempted blk num: 14790
iter_num: 5539, on_card_num: 31, preempted blk num: 14790
iter_num: 5540, on_card_num: 31, preempted blk num: 14790
iter_num: 5541, on_card_num: 31, preempted blk num: 14790
iter_num: 5542, on_card_num: 31, preempted blk num: 14790
iter_num: 5543, on_card_num: 31, preempted blk num: 14790
iter_num: 5544, on_card_num: 31, preempted blk num: 14790
iter_num: 5545, on_card_num: 31, preempted blk num: 14790
iter_num: 5546, on_card_num: 31, preempted blk num: 14790
iter_num: 5547, on_card_num: 30, preempted blk num: 14790
iter_num: 5548, on_card_num: 30, preempted blk num: 14790
iter_num: 5549, on_card_num: 30, preempted blk num: 14790
iter_num: 5550, on_card_num: 30, preempted blk num: 14790
iter_num: 5551, on_card_num: 30, preempted blk num: 14790
iter_num: 5552, on_card_num: 30, preempted blk num: 14790
iter_num: 5553, on_card_num: 30, preempted blk num: 14790
iter_num: 5554, on_card_num: 29, preempted blk num: 14790
iter_num: 5555, on_card_num: 29, preempted blk num: 14790
iter_num: 5556, on_card_num: 29, preempted blk num: 14790
iter_num: 5557, on_card_num: 29, preempted blk num: 14790
iter_num: 5558, on_card_num: 29, preempted blk num: 14790
iter_num: 5559, on_card_num: 29, preempted blk num: 14790
iter_num: 5560, on_card_num: 29, preempted blk num: 14790
iter_num: 5561, on_card_num: 29, preempted blk num: 14790
iter_num: 5562, on_card_num: 29, preempted blk num: 14790
iter_num: 5563, on_card_num: 29, preempted blk num: 14790
iter_num: 5564, on_card_num: 29, preempted blk num: 14790
iter_num: 5565, on_card_num: 29, preempted blk num: 14790
iter_num: 5566, on_card_num: 29, preempted blk num: 14790
iter_num: 5567, on_card_num: 29, preempted blk num: 14790
iter_num: 5568, on_card_num: 29, preempted blk num: 14790
iter_num: 5569, on_card_num: 29, preempted blk num: 14790
iter_num: 5570, on_card_num: 28, preempted blk num: 14790
iter_num: 5571, on_card_num: 28, preempted blk num: 14790
iter_num: 5572, on_card_num: 28, preempted blk num: 14790
iter_num: 5573, on_card_num: 28, preempted blk num: 14790
iter_num: 5574, on_card_num: 28, preempted blk num: 14790
iter_num: 5575, on_card_num: 28, preempted blk num: 14790
iter_num: 5576, on_card_num: 28, preempted blk num: 14790
iter_num: 5577, on_card_num: 28, preempted blk num: 14790
iter_num: 5578, on_card_num: 28, preempted blk num: 14790
iter_num: 5579, on_card_num: 28, preempted blk num: 14790
iter_num: 5580, on_card_num: 28, preempted blk num: 14790
iter_num: 5581, on_card_num: 28, preempted blk num: 14790
iter_num: 5582, on_card_num: 28, preempted blk num: 14790
iter_num: 5583, on_card_num: 28, preempted blk num: 14790
iter_num: 5584, on_card_num: 28, preempted blk num: 14790
iter_num: 5585, on_card_num: 28, preempted blk num: 14790
iter_num: 5586, on_card_num: 26, preempted blk num: 14790
iter_num: 5587, on_card_num: 26, preempted blk num: 14790
iter_num: 5588, on_card_num: 26, preempted blk num: 14790
iter_num: 5589, on_card_num: 25, preempted blk num: 14790
iter_num: 5590, on_card_num: 25, preempted blk num: 14790
iter_num: 5591, on_card_num: 25, preempted blk num: 14790
iter_num: 5592, on_card_num: 25, preempted blk num: 14790
iter_num: 5593, on_card_num: 25, preempted blk num: 14790
iter_num: 5594, on_card_num: 25, preempted blk num: 14790
iter_num: 5595, on_card_num: 25, preempted blk num: 14790
iter_num: 5596, on_card_num: 25, preempted blk num: 14790
iter_num: 5597, on_card_num: 25, preempted blk num: 14790
iter_num: 5598, on_card_num: 25, preempted blk num: 14790
iter_num: 5599, on_card_num: 25, preempted blk num: 14790
iter_num: 5600, on_card_num: 25, preempted blk num: 14790
iter_num: 5601, on_card_num: 25, preempted blk num: 14790
iter_num: 5602, on_card_num: 25, preempted blk num: 14790
iter_num: 5603, on_card_num: 25, preempted blk num: 14790
iter_num: 5604, on_card_num: 25, preempted blk num: 14790
iter_num: 5605, on_card_num: 25, preempted blk num: 14790
iter_num: 5606, on_card_num: 25, preempted blk num: 14790
iter_num: 5607, on_card_num: 25, preempted blk num: 14790
iter_num: 5608, on_card_num: 25, preempted blk num: 14790
iter_num: 5609, on_card_num: 25, preempted blk num: 14790
iter_num: 5610, on_card_num: 25, preempted blk num: 14790
iter_num: 5611, on_card_num: 25, preempted blk num: 14790
iter_num: 5612, on_card_num: 25, preempted blk num: 14790
iter_num: 5613, on_card_num: 25, preempted blk num: 14790
iter_num: 5614, on_card_num: 25, preempted blk num: 14790
iter_num: 5615, on_card_num: 25, preempted blk num: 14790
iter_num: 5616, on_card_num: 25, preempted blk num: 14790
iter_num: 5617, on_card_num: 25, preempted blk num: 14790
iter_num: 5618, on_card_num: 25, preempted blk num: 14790
iter_num: 5619, on_card_num: 24, preempted blk num: 14790
iter_num: 5620, on_card_num: 24, preempted blk num: 14790
iter_num: 5621, on_card_num: 24, preempted blk num: 14790
iter_num: 5622, on_card_num: 24, preempted blk num: 14790
iter_num: 5623, on_card_num: 24, preempted blk num: 14790
iter_num: 5624, on_card_num: 24, preempted blk num: 14790
iter_num: 5625, on_card_num: 24, preempted blk num: 14790
iter_num: 5626, on_card_num: 23, preempted blk num: 14790
iter_num: 5627, on_card_num: 23, preempted blk num: 14790
iter_num: 5628, on_card_num: 22, preempted blk num: 14790
iter_num: 5629, on_card_num: 21, preempted blk num: 14790
iter_num: 5630, on_card_num: 21, preempted blk num: 14790
iter_num: 5631, on_card_num: 21, preempted blk num: 14790
iter_num: 5632, on_card_num: 21, preempted blk num: 14790
iter_num: 5633, on_card_num: 21, preempted blk num: 14790
iter_num: 5634, on_card_num: 21, preempted blk num: 14790
iter_num: 5635, on_card_num: 21, preempted blk num: 14790
iter_num: 5636, on_card_num: 21, preempted blk num: 14790
iter_num: 5637, on_card_num: 21, preempted blk num: 14790
iter_num: 5638, on_card_num: 21, preempted blk num: 14790
iter_num: 5639, on_card_num: 21, preempted blk num: 14790
iter_num: 5640, on_card_num: 21, preempted blk num: 14790
iter_num: 5641, on_card_num: 21, preempted blk num: 14790
iter_num: 5642, on_card_num: 20, preempted blk num: 14790
iter_num: 5643, on_card_num: 19, preempted blk num: 14790
iter_num: 5644, on_card_num: 19, preempted blk num: 14790
iter_num: 5645, on_card_num: 19, preempted blk num: 14790
iter_num: 5646, on_card_num: 19, preempted blk num: 14790
iter_num: 5647, on_card_num: 19, preempted blk num: 14790
iter_num: 5648, on_card_num: 18, preempted blk num: 14790
iter_num: 5649, on_card_num: 18, preempted blk num: 14790
iter_num: 5650, on_card_num: 18, preempted blk num: 14790
iter_num: 5651, on_card_num: 18, preempted blk num: 14790
iter_num: 5652, on_card_num: 17, preempted blk num: 14790
iter_num: 5653, on_card_num: 17, preempted blk num: 14790
iter_num: 5654, on_card_num: 17, preempted blk num: 14790
iter_num: 5655, on_card_num: 17, preempted blk num: 14790
iter_num: 5656, on_card_num: 17, preempted blk num: 14790
iter_num: 5657, on_card_num: 17, preempted blk num: 14790
iter_num: 5658, on_card_num: 17, preempted blk num: 14790
iter_num: 5659, on_card_num: 17, preempted blk num: 14790
iter_num: 5660, on_card_num: 17, preempted blk num: 14790
iter_num: 5661, on_card_num: 17, preempted blk num: 14790
iter_num: 5662, on_card_num: 17, preempted blk num: 14790
iter_num: 5663, on_card_num: 17, preempted blk num: 14790
iter_num: 5664, on_card_num: 17, preempted blk num: 14790
iter_num: 5665, on_card_num: 17, preempted blk num: 14790
iter_num: 5666, on_card_num: 17, preempted blk num: 14790
iter_num: 5667, on_card_num: 17, preempted blk num: 14790
iter_num: 5668, on_card_num: 17, preempted blk num: 14790
iter_num: 5669, on_card_num: 17, preempted blk num: 14790
iter_num: 5670, on_card_num: 17, preempted blk num: 14790
iter_num: 5671, on_card_num: 17, preempted blk num: 14790
iter_num: 5672, on_card_num: 17, preempted blk num: 14790
iter_num: 5673, on_card_num: 17, preempted blk num: 14790
iter_num: 5674, on_card_num: 17, preempted blk num: 14790
iter_num: 5675, on_card_num: 17, preempted blk num: 14790
iter_num: 5676, on_card_num: 17, preempted blk num: 14790
iter_num: 5677, on_card_num: 17, preempted blk num: 14790
iter_num: 5678, on_card_num: 17, preempted blk num: 14790
iter_num: 5679, on_card_num: 17, preempted blk num: 14790
iter_num: 5680, on_card_num: 17, preempted blk num: 14790
iter_num: 5681, on_card_num: 17, preempted blk num: 14790
iter_num: 5682, on_card_num: 17, preempted blk num: 14790
iter_num: 5683, on_card_num: 17, preempted blk num: 14790
iter_num: 5684, on_card_num: 17, preempted blk num: 14790
iter_num: 5685, on_card_num: 17, preempted blk num: 14790
iter_num: 5686, on_card_num: 17, preempted blk num: 14790
iter_num: 5687, on_card_num: 17, preempted blk num: 14790
iter_num: 5688, on_card_num: 17, preempted blk num: 14790
iter_num: 5689, on_card_num: 17, preempted blk num: 14790
iter_num: 5690, on_card_num: 17, preempted blk num: 14790
iter_num: 5691, on_card_num: 17, preempted blk num: 14790
iter_num: 5692, on_card_num: 17, preempted blk num: 14790
iter_num: 5693, on_card_num: 17, preempted blk num: 14790
iter_num: 5694, on_card_num: 17, preempted blk num: 14790
iter_num: 5695, on_card_num: 17, preempted blk num: 14790
iter_num: 5696, on_card_num: 17, preempted blk num: 14790
iter_num: 5697, on_card_num: 17, preempted blk num: 14790
iter_num: 5698, on_card_num: 17, preempted blk num: 14790
iter_num: 5699, on_card_num: 17, preempted blk num: 14790
iter_num: 5700, on_card_num: 17, preempted blk num: 14790
iter_num: 5701, on_card_num: 17, preempted blk num: 14790
iter_num: 5702, on_card_num: 17, preempted blk num: 14790
iter_num: 5703, on_card_num: 17, preempted blk num: 14790
iter_num: 5704, on_card_num: 17, preempted blk num: 14790
iter_num: 5705, on_card_num: 17, preempted blk num: 14790
iter_num: 5706, on_card_num: 17, preempted blk num: 14790
iter_num: 5707, on_card_num: 17, preempted blk num: 14790
iter_num: 5708, on_card_num: 17, preempted blk num: 14790
iter_num: 5709, on_card_num: 17, preempted blk num: 14790
iter_num: 5710, on_card_num: 17, preempted blk num: 14790
iter_num: 5711, on_card_num: 17, preempted blk num: 14790
iter_num: 5712, on_card_num: 17, preempted blk num: 14790
iter_num: 5713, on_card_num: 17, preempted blk num: 14790
iter_num: 5714, on_card_num: 17, preempted blk num: 14790
iter_num: 5715, on_card_num: 17, preempted blk num: 14790
iter_num: 5716, on_card_num: 17, preempted blk num: 14790
iter_num: 5717, on_card_num: 17, preempted blk num: 14790
iter_num: 5718, on_card_num: 17, preempted blk num: 14790
iter_num: 5719, on_card_num: 17, preempted blk num: 14790
iter_num: 5720, on_card_num: 16, preempted blk num: 14790
iter_num: 5721, on_card_num: 16, preempted blk num: 14790
iter_num: 5722, on_card_num: 16, preempted blk num: 14790
iter_num: 5723, on_card_num: 16, preempted blk num: 14790
iter_num: 5724, on_card_num: 16, preempted blk num: 14790
iter_num: 5725, on_card_num: 16, preempted blk num: 14790
iter_num: 5726, on_card_num: 16, preempted blk num: 14790
iter_num: 5727, on_card_num: 16, preempted blk num: 14790
iter_num: 5728, on_card_num: 16, preempted blk num: 14790
iter_num: 5729, on_card_num: 16, preempted blk num: 14790
iter_num: 5730, on_card_num: 16, preempted blk num: 14790
iter_num: 5731, on_card_num: 16, preempted blk num: 14790
iter_num: 5732, on_card_num: 16, preempted blk num: 14790
iter_num: 5733, on_card_num: 16, preempted blk num: 14790
iter_num: 5734, on_card_num: 16, preempted blk num: 14790
iter_num: 5735, on_card_num: 16, preempted blk num: 14790
iter_num: 5736, on_card_num: 16, preempted blk num: 14790
iter_num: 5737, on_card_num: 16, preempted blk num: 14790
iter_num: 5738, on_card_num: 16, preempted blk num: 14790
iter_num: 5739, on_card_num: 15, preempted blk num: 14790
iter_num: 5740, on_card_num: 15, preempted blk num: 14790
iter_num: 5741, on_card_num: 15, preempted blk num: 14790
iter_num: 5742, on_card_num: 15, preempted blk num: 14790
iter_num: 5743, on_card_num: 15, preempted blk num: 14790
iter_num: 5744, on_card_num: 14, preempted blk num: 14790
iter_num: 5745, on_card_num: 14, preempted blk num: 14790
iter_num: 5746, on_card_num: 14, preempted blk num: 14790
iter_num: 5747, on_card_num: 14, preempted blk num: 14790
iter_num: 5748, on_card_num: 14, preempted blk num: 14790
iter_num: 5749, on_card_num: 14, preempted blk num: 14790
iter_num: 5750, on_card_num: 14, preempted blk num: 14790
iter_num: 5751, on_card_num: 14, preempted blk num: 14790
iter_num: 5752, on_card_num: 14, preempted blk num: 14790
iter_num: 5753, on_card_num: 14, preempted blk num: 14790
iter_num: 5754, on_card_num: 13, preempted blk num: 14790
iter_num: 5755, on_card_num: 13, preempted blk num: 14790
iter_num: 5756, on_card_num: 12, preempted blk num: 14790
iter_num: 5757, on_card_num: 12, preempted blk num: 14790
iter_num: 5758, on_card_num: 12, preempted blk num: 14790
iter_num: 5759, on_card_num: 12, preempted blk num: 14790
iter_num: 5760, on_card_num: 12, preempted blk num: 14790
iter_num: 5761, on_card_num: 12, preempted blk num: 14790
iter_num: 5762, on_card_num: 12, preempted blk num: 14790
iter_num: 5763, on_card_num: 12, preempted blk num: 14790
iter_num: 5764, on_card_num: 12, preempted blk num: 14790
iter_num: 5765, on_card_num: 12, preempted blk num: 14790
iter_num: 5766, on_card_num: 12, preempted blk num: 14790
iter_num: 5767, on_card_num: 12, preempted blk num: 14790
iter_num: 5768, on_card_num: 12, preempted blk num: 14790
iter_num: 5769, on_card_num: 12, preempted blk num: 14790
iter_num: 5770, on_card_num: 12, preempted blk num: 14790
iter_num: 5771, on_card_num: 12, preempted blk num: 14790
iter_num: 5772, on_card_num: 12, preempted blk num: 14790
iter_num: 5773, on_card_num: 12, preempted blk num: 14790
iter_num: 5774, on_card_num: 12, preempted blk num: 14790
iter_num: 5775, on_card_num: 12, preempted blk num: 14790
iter_num: 5776, on_card_num: 12, preempted blk num: 14790
iter_num: 5777, on_card_num: 12, preempted blk num: 14790
iter_num: 5778, on_card_num: 12, preempted blk num: 14790
iter_num: 5779, on_card_num: 12, preempted blk num: 14790
iter_num: 5780, on_card_num: 12, preempted blk num: 14790
iter_num: 5781, on_card_num: 12, preempted blk num: 14790
iter_num: 5782, on_card_num: 12, preempted blk num: 14790
iter_num: 5783, on_card_num: 12, preempted blk num: 14790
iter_num: 5784, on_card_num: 12, preempted blk num: 14790
iter_num: 5785, on_card_num: 12, preempted blk num: 14790
iter_num: 5786, on_card_num: 12, preempted blk num: 14790
iter_num: 5787, on_card_num: 12, preempted blk num: 14790
iter_num: 5788, on_card_num: 12, preempted blk num: 14790
iter_num: 5789, on_card_num: 12, preempted blk num: 14790
iter_num: 5790, on_card_num: 11, preempted blk num: 14790
iter_num: 5791, on_card_num: 11, preempted blk num: 14790
iter_num: 5792, on_card_num: 11, preempted blk num: 14790
iter_num: 5793, on_card_num: 11, preempted blk num: 14790
iter_num: 5794, on_card_num: 11, preempted blk num: 14790
iter_num: 5795, on_card_num: 11, preempted blk num: 14790
iter_num: 5796, on_card_num: 11, preempted blk num: 14790
iter_num: 5797, on_card_num: 11, preempted blk num: 14790
iter_num: 5798, on_card_num: 11, preempted blk num: 14790
iter_num: 5799, on_card_num: 11, preempted blk num: 14790
iter_num: 5800, on_card_num: 11, preempted blk num: 14790
iter_num: 5801, on_card_num: 11, preempted blk num: 14790
iter_num: 5802, on_card_num: 11, preempted blk num: 14790
iter_num: 5803, on_card_num: 11, preempted blk num: 14790
iter_num: 5804, on_card_num: 11, preempted blk num: 14790
iter_num: 5805, on_card_num: 11, preempted blk num: 14790
iter_num: 5806, on_card_num: 11, preempted blk num: 14790
iter_num: 5807, on_card_num: 11, preempted blk num: 14790
iter_num: 5808, on_card_num: 11, preempted blk num: 14790
iter_num: 5809, on_card_num: 11, preempted blk num: 14790
iter_num: 5810, on_card_num: 11, preempted blk num: 14790
iter_num: 5811, on_card_num: 11, preempted blk num: 14790
iter_num: 5812, on_card_num: 11, preempted blk num: 14790
iter_num: 5813, on_card_num: 11, preempted blk num: 14790
iter_num: 5814, on_card_num: 11, preempted blk num: 14790
iter_num: 5815, on_card_num: 11, preempted blk num: 14790
iter_num: 5816, on_card_num: 11, preempted blk num: 14790
iter_num: 5817, on_card_num: 11, preempted blk num: 14790
iter_num: 5818, on_card_num: 11, preempted blk num: 14790
iter_num: 5819, on_card_num: 11, preempted blk num: 14790
iter_num: 5820, on_card_num: 11, preempted blk num: 14790
iter_num: 5821, on_card_num: 11, preempted blk num: 14790
iter_num: 5822, on_card_num: 11, preempted blk num: 14790
iter_num: 5823, on_card_num: 11, preempted blk num: 14790
iter_num: 5824, on_card_num: 11, preempted blk num: 14790
iter_num: 5825, on_card_num: 11, preempted blk num: 14790
iter_num: 5826, on_card_num: 11, preempted blk num: 14790
iter_num: 5827, on_card_num: 11, preempted blk num: 14790
iter_num: 5828, on_card_num: 11, preempted blk num: 14790
iter_num: 5829, on_card_num: 11, preempted blk num: 14790
iter_num: 5830, on_card_num: 10, preempted blk num: 14790
iter_num: 5831, on_card_num: 10, preempted blk num: 14790
iter_num: 5832, on_card_num: 10, preempted blk num: 14790
iter_num: 5833, on_card_num: 10, preempted blk num: 14790
iter_num: 5834, on_card_num: 10, preempted blk num: 14790
iter_num: 5835, on_card_num: 10, preempted blk num: 14790
iter_num: 5836, on_card_num: 10, preempted blk num: 14790
iter_num: 5837, on_card_num: 10, preempted blk num: 14790
iter_num: 5838, on_card_num: 10, preempted blk num: 14790
iter_num: 5839, on_card_num: 10, preempted blk num: 14790
iter_num: 5840, on_card_num: 10, preempted blk num: 14790
iter_num: 5841, on_card_num: 10, preempted blk num: 14790
iter_num: 5842, on_card_num: 10, preempted blk num: 14790
iter_num: 5843, on_card_num: 10, preempted blk num: 14790
iter_num: 5844, on_card_num: 10, preempted blk num: 14790
iter_num: 5845, on_card_num: 9, preempted blk num: 14790
iter_num: 5846, on_card_num: 9, preempted blk num: 14790
iter_num: 5847, on_card_num: 9, preempted blk num: 14790
iter_num: 5848, on_card_num: 9, preempted blk num: 14790
iter_num: 5849, on_card_num: 9, preempted blk num: 14790
iter_num: 5850, on_card_num: 9, preempted blk num: 14790
iter_num: 5851, on_card_num: 9, preempted blk num: 14790
iter_num: 5852, on_card_num: 9, preempted blk num: 14790
iter_num: 5853, on_card_num: 9, preempted blk num: 14790
iter_num: 5854, on_card_num: 9, preempted blk num: 14790
iter_num: 5855, on_card_num: 9, preempted blk num: 14790
iter_num: 5856, on_card_num: 9, preempted blk num: 14790
iter_num: 5857, on_card_num: 9, preempted blk num: 14790
iter_num: 5858, on_card_num: 9, preempted blk num: 14790
iter_num: 5859, on_card_num: 9, preempted blk num: 14790
iter_num: 5860, on_card_num: 9, preempted blk num: 14790
iter_num: 5861, on_card_num: 9, preempted blk num: 14790
iter_num: 5862, on_card_num: 9, preempted blk num: 14790
iter_num: 5863, on_card_num: 9, preempted blk num: 14790
iter_num: 5864, on_card_num: 9, preempted blk num: 14790
iter_num: 5865, on_card_num: 9, preempted blk num: 14790
iter_num: 5866, on_card_num: 9, preempted blk num: 14790
iter_num: 5867, on_card_num: 9, preempted blk num: 14790
iter_num: 5868, on_card_num: 9, preempted blk num: 14790
iter_num: 5869, on_card_num: 9, preempted blk num: 14790
iter_num: 5870, on_card_num: 9, preempted blk num: 14790
iter_num: 5871, on_card_num: 9, preempted blk num: 14790
iter_num: 5872, on_card_num: 9, preempted blk num: 14790
iter_num: 5873, on_card_num: 9, preempted blk num: 14790
iter_num: 5874, on_card_num: 9, preempted blk num: 14790
iter_num: 5875, on_card_num: 9, preempted blk num: 14790
iter_num: 5876, on_card_num: 9, preempted blk num: 14790
iter_num: 5877, on_card_num: 9, preempted blk num: 14790
iter_num: 5878, on_card_num: 9, preempted blk num: 14790
iter_num: 5879, on_card_num: 9, preempted blk num: 14790
iter_num: 5880, on_card_num: 9, preempted blk num: 14790
iter_num: 5881, on_card_num: 9, preempted blk num: 14790
iter_num: 5882, on_card_num: 9, preempted blk num: 14790
iter_num: 5883, on_card_num: 9, preempted blk num: 14790
iter_num: 5884, on_card_num: 9, preempted blk num: 14790
iter_num: 5885, on_card_num: 9, preempted blk num: 14790
iter_num: 5886, on_card_num: 9, preempted blk num: 14790
iter_num: 5887, on_card_num: 9, preempted blk num: 14790
iter_num: 5888, on_card_num: 9, preempted blk num: 14790
iter_num: 5889, on_card_num: 9, preempted blk num: 14790
iter_num: 5890, on_card_num: 9, preempted blk num: 14790
iter_num: 5891, on_card_num: 9, preempted blk num: 14790
iter_num: 5892, on_card_num: 9, preempted blk num: 14790
iter_num: 5893, on_card_num: 9, preempted blk num: 14790
iter_num: 5894, on_card_num: 9, preempted blk num: 14790
iter_num: 5895, on_card_num: 9, preempted blk num: 14790
iter_num: 5896, on_card_num: 9, preempted blk num: 14790
iter_num: 5897, on_card_num: 9, preempted blk num: 14790
iter_num: 5898, on_card_num: 9, preempted blk num: 14790
iter_num: 5899, on_card_num: 8, preempted blk num: 14790
iter_num: 5900, on_card_num: 8, preempted blk num: 14790
iter_num: 5901, on_card_num: 8, preempted blk num: 14790
iter_num: 5902, on_card_num: 8, preempted blk num: 14790
iter_num: 5903, on_card_num: 8, preempted blk num: 14790
iter_num: 5904, on_card_num: 8, preempted blk num: 14790
iter_num: 5905, on_card_num: 8, preempted blk num: 14790
iter_num: 5906, on_card_num: 8, preempted blk num: 14790
iter_num: 5907, on_card_num: 8, preempted blk num: 14790
iter_num: 5908, on_card_num: 8, preempted blk num: 14790
iter_num: 5909, on_card_num: 8, preempted blk num: 14790
iter_num: 5910, on_card_num: 8, preempted blk num: 14790
iter_num: 5911, on_card_num: 8, preempted blk num: 14790
iter_num: 5912, on_card_num: 8, preempted blk num: 14790
iter_num: 5913, on_card_num: 8, preempted blk num: 14790
iter_num: 5914, on_card_num: 8, preempted blk num: 14790
iter_num: 5915, on_card_num: 8, preempted blk num: 14790
iter_num: 5916, on_card_num: 8, preempted blk num: 14790
iter_num: 5917, on_card_num: 8, preempted blk num: 14790
iter_num: 5918, on_card_num: 8, preempted blk num: 14790
iter_num: 5919, on_card_num: 8, preempted blk num: 14790
iter_num: 5920, on_card_num: 8, preempted blk num: 14790
iter_num: 5921, on_card_num: 8, preempted blk num: 14790
iter_num: 5922, on_card_num: 8, preempted blk num: 14790
iter_num: 5923, on_card_num: 8, preempted blk num: 14790
iter_num: 5924, on_card_num: 8, preempted blk num: 14790
iter_num: 5925, on_card_num: 8, preempted blk num: 14790
iter_num: 5926, on_card_num: 8, preempted blk num: 14790
iter_num: 5927, on_card_num: 8, preempted blk num: 14790
iter_num: 5928, on_card_num: 8, preempted blk num: 14790
iter_num: 5929, on_card_num: 8, preempted blk num: 14790
iter_num: 5930, on_card_num: 8, preempted blk num: 14790
iter_num: 5931, on_card_num: 8, preempted blk num: 14790
iter_num: 5932, on_card_num: 8, preempted blk num: 14790
iter_num: 5933, on_card_num: 8, preempted blk num: 14790
iter_num: 5934, on_card_num: 8, preempted blk num: 14790
iter_num: 5935, on_card_num: 8, preempted blk num: 14790
iter_num: 5936, on_card_num: 8, preempted blk num: 14790
iter_num: 5937, on_card_num: 8, preempted blk num: 14790
iter_num: 5938, on_card_num: 8, preempted blk num: 14790
iter_num: 5939, on_card_num: 8, preempted blk num: 14790
iter_num: 5940, on_card_num: 8, preempted blk num: 14790
iter_num: 5941, on_card_num: 8, preempted blk num: 14790
iter_num: 5942, on_card_num: 8, preempted blk num: 14790
iter_num: 5943, on_card_num: 7, preempted blk num: 14790
iter_num: 5944, on_card_num: 7, preempted blk num: 14790
iter_num: 5945, on_card_num: 7, preempted blk num: 14790
iter_num: 5946, on_card_num: 7, preempted blk num: 14790
iter_num: 5947, on_card_num: 7, preempted blk num: 14790
iter_num: 5948, on_card_num: 7, preempted blk num: 14790
iter_num: 5949, on_card_num: 7, preempted blk num: 14790
iter_num: 5950, on_card_num: 7, preempted blk num: 14790
iter_num: 5951, on_card_num: 7, preempted blk num: 14790
iter_num: 5952, on_card_num: 7, preempted blk num: 14790
iter_num: 5953, on_card_num: 7, preempted blk num: 14790
iter_num: 5954, on_card_num: 7, preempted blk num: 14790
iter_num: 5955, on_card_num: 7, preempted blk num: 14790
iter_num: 5956, on_card_num: 7, preempted blk num: 14790
iter_num: 5957, on_card_num: 7, preempted blk num: 14790
iter_num: 5958, on_card_num: 7, preempted blk num: 14790
iter_num: 5959, on_card_num: 7, preempted blk num: 14790
iter_num: 5960, on_card_num: 7, preempted blk num: 14790
iter_num: 5961, on_card_num: 7, preempted blk num: 14790
iter_num: 5962, on_card_num: 7, preempted blk num: 14790
iter_num: 5963, on_card_num: 7, preempted blk num: 14790
iter_num: 5964, on_card_num: 7, preempted blk num: 14790
iter_num: 5965, on_card_num: 7, preempted blk num: 14790
iter_num: 5966, on_card_num: 7, preempted blk num: 14790
iter_num: 5967, on_card_num: 7, preempted blk num: 14790
iter_num: 5968, on_card_num: 7, preempted blk num: 14790
iter_num: 5969, on_card_num: 7, preempted blk num: 14790
iter_num: 5970, on_card_num: 7, preempted blk num: 14790
iter_num: 5971, on_card_num: 7, preempted blk num: 14790
iter_num: 5972, on_card_num: 7, preempted blk num: 14790
iter_num: 5973, on_card_num: 7, preempted blk num: 14790
iter_num: 5974, on_card_num: 7, preempted blk num: 14790
iter_num: 5975, on_card_num: 7, preempted blk num: 14790
iter_num: 5976, on_card_num: 7, preempted blk num: 14790
iter_num: 5977, on_card_num: 7, preempted blk num: 14790
iter_num: 5978, on_card_num: 7, preempted blk num: 14790
iter_num: 5979, on_card_num: 7, preempted blk num: 14790
iter_num: 5980, on_card_num: 7, preempted blk num: 14790
iter_num: 5981, on_card_num: 7, preempted blk num: 14790
iter_num: 5982, on_card_num: 7, preempted blk num: 14790
iter_num: 5983, on_card_num: 7, preempted blk num: 14790
iter_num: 5984, on_card_num: 7, preempted blk num: 14790
iter_num: 5985, on_card_num: 7, preempted blk num: 14790
iter_num: 5986, on_card_num: 7, preempted blk num: 14790
iter_num: 5987, on_card_num: 7, preempted blk num: 14790
iter_num: 5988, on_card_num: 7, preempted blk num: 14790
iter_num: 5989, on_card_num: 7, preempted blk num: 14790
iter_num: 5990, on_card_num: 7, preempted blk num: 14790
iter_num: 5991, on_card_num: 7, preempted blk num: 14790
iter_num: 5992, on_card_num: 7, preempted blk num: 14790
iter_num: 5993, on_card_num: 7, preempted blk num: 14790
iter_num: 5994, on_card_num: 7, preempted blk num: 14790
iter_num: 5995, on_card_num: 7, preempted blk num: 14790
iter_num: 5996, on_card_num: 7, preempted blk num: 14790
iter_num: 5997, on_card_num: 7, preempted blk num: 14790
iter_num: 5998, on_card_num: 7, preempted blk num: 14790
iter_num: 5999, on_card_num: 7, preempted blk num: 14790
iter_num: 6000, on_card_num: 7, preempted blk num: 14790
iter_num: 6001, on_card_num: 7, preempted blk num: 14790
iter_num: 6002, on_card_num: 7, preempted blk num: 14790
iter_num: 6003, on_card_num: 7, preempted blk num: 14790
iter_num: 6004, on_card_num: 7, preempted blk num: 14790
iter_num: 6005, on_card_num: 7, preempted blk num: 14790
iter_num: 6006, on_card_num: 7, preempted blk num: 14790
iter_num: 6007, on_card_num: 7, preempted blk num: 14790
iter_num: 6008, on_card_num: 7, preempted blk num: 14790
iter_num: 6009, on_card_num: 7, preempted blk num: 14790
iter_num: 6010, on_card_num: 7, preempted blk num: 14790
iter_num: 6011, on_card_num: 7, preempted blk num: 14790
iter_num: 6012, on_card_num: 7, preempted blk num: 14790
iter_num: 6013, on_card_num: 7, preempted blk num: 14790
iter_num: 6014, on_card_num: 7, preempted blk num: 14790
iter_num: 6015, on_card_num: 7, preempted blk num: 14790
iter_num: 6016, on_card_num: 7, preempted blk num: 14790
iter_num: 6017, on_card_num: 7, preempted blk num: 14790
iter_num: 6018, on_card_num: 7, preempted blk num: 14790
iter_num: 6019, on_card_num: 7, preempted blk num: 14790
iter_num: 6020, on_card_num: 7, preempted blk num: 14790
iter_num: 6021, on_card_num: 7, preempted blk num: 14790
iter_num: 6022, on_card_num: 7, preempted blk num: 14790
iter_num: 6023, on_card_num: 7, preempted blk num: 14790
iter_num: 6024, on_card_num: 7, preempted blk num: 14790
iter_num: 6025, on_card_num: 7, preempted blk num: 14790
iter_num: 6026, on_card_num: 7, preempted blk num: 14790
iter_num: 6027, on_card_num: 7, preempted blk num: 14790
iter_num: 6028, on_card_num: 7, preempted blk num: 14790
iter_num: 6029, on_card_num: 7, preempted blk num: 14790
iter_num: 6030, on_card_num: 7, preempted blk num: 14790
iter_num: 6031, on_card_num: 7, preempted blk num: 14790
iter_num: 6032, on_card_num: 7, preempted blk num: 14790
iter_num: 6033, on_card_num: 7, preempted blk num: 14790
iter_num: 6034, on_card_num: 7, preempted blk num: 14790
iter_num: 6035, on_card_num: 7, preempted blk num: 14790
iter_num: 6036, on_card_num: 7, preempted blk num: 14790
iter_num: 6037, on_card_num: 7, preempted blk num: 14790
iter_num: 6038, on_card_num: 7, preempted blk num: 14790
iter_num: 6039, on_card_num: 6, preempted blk num: 14790
iter_num: 6040, on_card_num: 6, preempted blk num: 14790
iter_num: 6041, on_card_num: 6, preempted blk num: 14790
iter_num: 6042, on_card_num: 6, preempted blk num: 14790
iter_num: 6043, on_card_num: 6, preempted blk num: 14790
iter_num: 6044, on_card_num: 6, preempted blk num: 14790
iter_num: 6045, on_card_num: 6, preempted blk num: 14790
iter_num: 6046, on_card_num: 6, preempted blk num: 14790
iter_num: 6047, on_card_num: 6, preempted blk num: 14790
iter_num: 6048, on_card_num: 6, preempted blk num: 14790
iter_num: 6049, on_card_num: 6, preempted blk num: 14790
iter_num: 6050, on_card_num: 6, preempted blk num: 14790
iter_num: 6051, on_card_num: 6, preempted blk num: 14790
iter_num: 6052, on_card_num: 6, preempted blk num: 14790
iter_num: 6053, on_card_num: 6, preempted blk num: 14790
iter_num: 6054, on_card_num: 6, preempted blk num: 14790
iter_num: 6055, on_card_num: 6, preempted blk num: 14790
iter_num: 6056, on_card_num: 6, preempted blk num: 14790
iter_num: 6057, on_card_num: 6, preempted blk num: 14790
iter_num: 6058, on_card_num: 6, preempted blk num: 14790
iter_num: 6059, on_card_num: 6, preempted blk num: 14790
iter_num: 6060, on_card_num: 6, preempted blk num: 14790
iter_num: 6061, on_card_num: 6, preempted blk num: 14790
iter_num: 6062, on_card_num: 6, preempted blk num: 14790
iter_num: 6063, on_card_num: 6, preempted blk num: 14790
iter_num: 6064, on_card_num: 6, preempted blk num: 14790
iter_num: 6065, on_card_num: 6, preempted blk num: 14790
iter_num: 6066, on_card_num: 6, preempted blk num: 14790
iter_num: 6067, on_card_num: 6, preempted blk num: 14790
iter_num: 6068, on_card_num: 6, preempted blk num: 14790
iter_num: 6069, on_card_num: 6, preempted blk num: 14790
iter_num: 6070, on_card_num: 6, preempted blk num: 14790
iter_num: 6071, on_card_num: 6, preempted blk num: 14790
iter_num: 6072, on_card_num: 6, preempted blk num: 14790
iter_num: 6073, on_card_num: 5, preempted blk num: 14790
iter_num: 6074, on_card_num: 5, preempted blk num: 14790
iter_num: 6075, on_card_num: 5, preempted blk num: 14790
iter_num: 6076, on_card_num: 5, preempted blk num: 14790
iter_num: 6077, on_card_num: 5, preempted blk num: 14790
iter_num: 6078, on_card_num: 5, preempted blk num: 14790
iter_num: 6079, on_card_num: 5, preempted blk num: 14790
iter_num: 6080, on_card_num: 5, preempted blk num: 14790
iter_num: 6081, on_card_num: 5, preempted blk num: 14790
iter_num: 6082, on_card_num: 5, preempted blk num: 14790
iter_num: 6083, on_card_num: 5, preempted blk num: 14790
iter_num: 6084, on_card_num: 5, preempted blk num: 14790
iter_num: 6085, on_card_num: 5, preempted blk num: 14790
iter_num: 6086, on_card_num: 5, preempted blk num: 14790
iter_num: 6087, on_card_num: 5, preempted blk num: 14790
iter_num: 6088, on_card_num: 5, preempted blk num: 14790
iter_num: 6089, on_card_num: 5, preempted blk num: 14790
iter_num: 6090, on_card_num: 5, preempted blk num: 14790
iter_num: 6091, on_card_num: 5, preempted blk num: 14790
iter_num: 6092, on_card_num: 5, preempted blk num: 14790
iter_num: 6093, on_card_num: 5, preempted blk num: 14790
iter_num: 6094, on_card_num: 5, preempted blk num: 14790
iter_num: 6095, on_card_num: 5, preempted blk num: 14790
iter_num: 6096, on_card_num: 5, preempted blk num: 14790
iter_num: 6097, on_card_num: 5, preempted blk num: 14790
iter_num: 6098, on_card_num: 5, preempted blk num: 14790
iter_num: 6099, on_card_num: 5, preempted blk num: 14790
iter_num: 6100, on_card_num: 5, preempted blk num: 14790
iter_num: 6101, on_card_num: 4, preempted blk num: 14790
iter_num: 6102, on_card_num: 4, preempted blk num: 14790
iter_num: 6103, on_card_num: 4, preempted blk num: 14790
iter_num: 6104, on_card_num: 4, preempted blk num: 14790
iter_num: 6105, on_card_num: 3, preempted blk num: 14790
iter_num: 6106, on_card_num: 3, preempted blk num: 14790
iter_num: 6107, on_card_num: 3, preempted blk num: 14790
iter_num: 6108, on_card_num: 3, preempted blk num: 14790
iter_num: 6109, on_card_num: 3, preempted blk num: 14790
iter_num: 6110, on_card_num: 3, preempted blk num: 14790
iter_num: 6111, on_card_num: 3, preempted blk num: 14790
iter_num: 6112, on_card_num: 2, preempted blk num: 14790
iter_num: 6113, on_card_num: 2, preempted blk num: 14790
iter_num: 6114, on_card_num: 2, preempted blk num: 14790
iter_num: 6115, on_card_num: 2, preempted blk num: 14790
iter_num: 6116, on_card_num: 2, preempted blk num: 14790
iter_num: 6117, on_card_num: 2, preempted blk num: 14790
iter_num: 6118, on_card_num: 2, preempted blk num: 14790
iter_num: 6119, on_card_num: 2, preempted blk num: 14790
iter_num: 6120, on_card_num: 2, preempted blk num: 14790
iter_num: 6121, on_card_num: 2, preempted blk num: 14790
iter_num: 6122, on_card_num: 2, preempted blk num: 14790
iter_num: 6123, on_card_num: 2, preempted blk num: 14790
iter_num: 6124, on_card_num: 2, preempted blk num: 14790
iter_num: 6125, on_card_num: 2, preempted blk num: 14790
iter_num: 6126, on_card_num: 2, preempted blk num: 14790
iter_num: 6127, on_card_num: 2, preempted blk num: 14790
iter_num: 6128, on_card_num: 2, preempted blk num: 14790
iter_num: 6129, on_card_num: 2, preempted blk num: 14790
iter_num: 6130, on_card_num: 2, preempted blk num: 14790
iter_num: 6131, on_card_num: 2, preempted blk num: 14790
iter_num: 6132, on_card_num: 2, preempted blk num: 14790
iter_num: 6133, on_card_num: 2, preempted blk num: 14790
iter_num: 6134, on_card_num: 2, preempted blk num: 14790
iter_num: 6135, on_card_num: 2, preempted blk num: 14790
iter_num: 6136, on_card_num: 2, preempted blk num: 14790
iter_num: 6137, on_card_num: 2, preempted blk num: 14790
iter_num: 6138, on_card_num: 2, preempted blk num: 14790
iter_num: 6139, on_card_num: 2, preempted blk num: 14790
iter_num: 6140, on_card_num: 2, preempted blk num: 14790
iter_num: 6141, on_card_num: 2, preempted blk num: 14790
iter_num: 6142, on_card_num: 2, preempted blk num: 14790
iter_num: 6143, on_card_num: 2, preempted blk num: 14790
iter_num: 6144, on_card_num: 2, preempted blk num: 14790
iter_num: 6145, on_card_num: 2, preempted blk num: 14790
iter_num: 6146, on_card_num: 2, preempted blk num: 14790
iter_num: 6147, on_card_num: 2, preempted blk num: 14790
iter_num: 6148, on_card_num: 2, preempted blk num: 14790
iter_num: 6149, on_card_num: 2, preempted blk num: 14790
iter_num: 6150, on_card_num: 2, preempted blk num: 14790
iter_num: 6151, on_card_num: 2, preempted blk num: 14790
iter_num: 6152, on_card_num: 2, preempted blk num: 14790
iter_num: 6153, on_card_num: 2, preempted blk num: 14790
iter_num: 6154, on_card_num: 2, preempted blk num: 14790
iter_num: 6155, on_card_num: 2, preempted blk num: 14790
iter_num: 6156, on_card_num: 2, preempted blk num: 14790
iter_num: 6157, on_card_num: 2, preempted blk num: 14790
iter_num: 6158, on_card_num: 2, preempted blk num: 14790
iter_num: 6159, on_card_num: 2, preempted blk num: 14790
iter_num: 6160, on_card_num: 2, preempted blk num: 14790
iter_num: 6161, on_card_num: 2, preempted blk num: 14790
iter_num: 6162, on_card_num: 2, preempted blk num: 14790
iter_num: 6163, on_card_num: 2, preempted blk num: 14790
iter_num: 6164, on_card_num: 2, preempted blk num: 14790
iter_num: 6165, on_card_num: 2, preempted blk num: 14790
iter_num: 6166, on_card_num: 2, preempted blk num: 14790
iter_num: 6167, on_card_num: 2, preempted blk num: 14790
iter_num: 6168, on_card_num: 2, preempted blk num: 14790
iter_num: 6169, on_card_num: 2, preempted blk num: 14790
iter_num: 6170, on_card_num: 1, preempted blk num: 14790
iter_num: 6171, on_card_num: 1, preempted blk num: 14790
iter_num: 6172, on_card_num: 1, preempted blk num: 14790
iter_num: 6173, on_card_num: 1, preempted blk num: 14790
iter_num: 6174, on_card_num: 1, preempted blk num: 14790
iter_num: 6175, on_card_num: 1, preempted blk num: 14790
iter_num: 6176, on_card_num: 1, preempted blk num: 14790
iter_num: 6177, on_card_num: 1, preempted blk num: 14790
iter_num: 6178, on_card_num: 1, preempted blk num: 14790
iter_num: 6179, on_card_num: 1, preempted blk num: 14790
iter_num: 6180, on_card_num: 1, preempted blk num: 14790
iter_num: 6181, on_card_num: 1, preempted blk num: 14790
iter_num: 6182, on_card_num: 1, preempted blk num: 14790
iter_num: 6183, on_card_num: 1, preempted blk num: 14790
iter_num: 6184, on_card_num: 1, preempted blk num: 14790
iter_num: 6185, on_card_num: 1, preempted blk num: 14790
iter_num: 6186, on_card_num: 1, preempted blk num: 14790
iter_num: 6187, on_card_num: 1, preempted blk num: 14790
iter_num: 6188, on_card_num: 1, preempted blk num: 14790
iter_num: 6189, on_card_num: 1, preempted blk num: 14790
iter_num: 6190, on_card_num: 1, preempted blk num: 14790
iter_num: 6191, on_card_num: 1, preempted blk num: 14790
iter_num: 6192, on_card_num: 1, preempted blk num: 14790
iter_num: 6193, on_card_num: 1, preempted blk num: 14790
iter_num: 6194, on_card_num: 1, preempted blk num: 14790
iter_num: 6195, on_card_num: 1, preempted blk num: 14790
iter_num: 6196, on_card_num: 1, preempted blk num: 14790
iter_num: 6197, on_card_num: 1, preempted blk num: 14790
iter_num: 6198, on_card_num: 1, preempted blk num: 14790
iter_num: 6199, on_card_num: 1, preempted blk num: 14790
iter_num: 6200, on_card_num: 1, preempted blk num: 14790
iter_num: 6201, on_card_num: 1, preempted blk num: 14790
iter_num: 6202, on_card_num: 1, preempted blk num: 14790
iter_num: 6203, on_card_num: 1, preempted blk num: 14790
iter_num: 6204, on_card_num: 1, preempted blk num: 14790
iter_num: 6205, on_card_num: 1, preempted blk num: 14790
iter_num: 6206, on_card_num: 1, preempted blk num: 14790
iter_num: 6207, on_card_num: 1, preempted blk num: 14790
iter_num: 6208, on_card_num: 1, preempted blk num: 14790
iter_num: 6209, on_card_num: 1, preempted blk num: 14790
iter_num: 6210, on_card_num: 1, preempted blk num: 14790
iter_num: 6211, on_card_num: 1, preempted blk num: 14790
iter_num: 6212, on_card_num: 1, preempted blk num: 14790
iter_num: 6213, on_card_num: 1, preempted blk num: 14790
iter_num: 6214, on_card_num: 1, preempted blk num: 14790
iter_num: 6215, on_card_num: 1, preempted blk num: 14790
iter_num: 6216, on_card_num: 1, preempted blk num: 14790
iter_num: 6217, on_card_num: 1, preempted blk num: 14790
iter_num: 6218, on_card_num: 1, preempted blk num: 14790
iter_num: 6219, on_card_num: 1, preempted blk num: 14790
iter_num: 6220, on_card_num: 1, preempted blk num: 14790
iter_num: 6221, on_card_num: 1, preempted blk num: 14790
iter_num: 6222, on_card_num: 1, preempted blk num: 14790
iter_num: 6223, on_card_num: 1, preempted blk num: 14790
iter_num: 6224, on_card_num: 1, preempted blk num: 14790
iter_num: 6225, on_card_num: 1, preempted blk num: 14790
iter_num: 6226, on_card_num: 1, preempted blk num: 14790
iter_num: 6227, on_card_num: 1, preempted blk num: 14790
iter_num: 6228, on_card_num: 1, preempted blk num: 14790
iter_num: 6229, on_card_num: 0, preempted blk num: 14790
Total iteration number: 6229, preempted blk num: 14790
Throughput: 6.92 requests/s, 3310.50 tokens/s
